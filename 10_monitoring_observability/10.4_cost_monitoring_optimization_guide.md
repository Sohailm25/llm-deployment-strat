> **Navigation** | [← 10.3 Model Quality](10.3_model_quality_monitoring_guide.md) | [11.1 Security →](../11_security_governance/11.1_llm_security_guide.md)
>
> | | |
> |---|---|
> | **Prerequisites** | Cloud pricing &#124; GPU instance types &#124; LLM inference costs |
> | **Related** | [14.1 TCO](../14_cost_capacity_management/14.1_total_cost_ownership_guide.md) &#124; [13.3 Capacity Planning](../13_operations_reliability/13.3_capacity_planning_guide.md) |
> | **Next** | [11.1 LLM Security](../11_security_governance/11.1_llm_security_guide.md) |

# Document 10.4: Cost Monitoring & Optimization Guide

## Purpose

This guide provides comprehensive strategies for tracking and optimizing costs in LLM infrastructure and operations. It covers cost components, attribution models, metrics, optimization strategies, and dashboards for FinOps practices.

## Prerequisites

- Understanding of cloud pricing models (compute, storage, network)
- Familiarity with GPU instance types and pricing
- Knowledge of LLM inference costs (tokens, API calls)
- Experience with cloud billing and cost management tools

## 10.4.1 Cost Components

### LLM Infrastructure Cost Breakdown

```python
"""
Cost modeling and tracking for LLM systems.
"""

from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from enum import Enum
import numpy as np


class CostCategory(Enum):
    """Categories of costs in LLM systems."""
    GPU_COMPUTE = "gpu_compute"
    CPU_COMPUTE = "cpu_compute"
    MEMORY = "memory"
    STORAGE = "storage"
    NETWORK = "network"
    API_EXTERNAL = "api_external"
    DATA_ANNOTATION = "data_annotation"
    SOFTWARE_LICENSE = "software_license"
    SUPPORT = "support"


@dataclass
class CostComponent:
    """Individual cost component definition."""
    name: str
    category: CostCategory
    unit: str  # e.g., "per-hour", "per-GB", "per-1k-tokens"
    unit_cost: float
    currency: str = "USD"
    description: str = ""


@dataclass
class CostRecord:
    """Record of a cost event."""
    timestamp: datetime
    component: str
    category: CostCategory
    quantity: float
    unit_cost: float
    total_cost: float
    metadata: Dict[str, Any] = field(default_factory=dict)


class LLMCostModel:
    """
    Cost model for LLM infrastructure.
    """

    # Standard GPU costs per hour (on-demand, as of 2024)
    GPU_COSTS = {
        # NVIDIA A100 instances
        "a100-40gb": {"aws": 4.096, "gcp": 3.67, "azure": 3.40},
        "a100-80gb": {"aws": 5.12, "gcp": 4.59, "azure": 4.25},
        # NVIDIA H100 instances
        "h100-80gb": {"aws": 12.00, "gcp": 11.50, "azure": 10.80},
        # NVIDIA A10G
        "a10g-24gb": {"aws": 1.212, "gcp": 1.10, "azure": 1.15},
        # NVIDIA T4
        "t4-16gb": {"aws": 0.526, "gcp": 0.35, "azure": 0.40},
        # NVIDIA L4
        "l4-24gb": {"aws": 0.81, "gcp": 0.70, "azure": 0.75},
    }

    # Storage costs per GB per month
    STORAGE_COSTS = {
        "ssd": {"aws": 0.08, "gcp": 0.17, "azure": 0.12},
        "hdd": {"aws": 0.045, "gcp": 0.04, "azure": 0.04},
        "object_storage": {"aws": 0.023, "gcp": 0.02, "azure": 0.018},
        "archive": {"aws": 0.004, "gcp": 0.0012, "azure": 0.002},
    }

    # Network costs per GB
    NETWORK_COSTS = {
        "egress_internet": {"aws": 0.09, "gcp": 0.12, "azure": 0.087},
        "egress_region": {"aws": 0.02, "gcp": 0.01, "azure": 0.02},
        "ingress": {"aws": 0.0, "gcp": 0.0, "azure": 0.0},  # Usually free
    }

    # External API costs per 1K tokens (input/output)
    API_COSTS = {
        "gpt-4-turbo": {"input": 0.01, "output": 0.03},
        "gpt-4": {"input": 0.03, "output": 0.06},
        "gpt-3.5-turbo": {"input": 0.0005, "output": 0.0015},
        "claude-3-opus": {"input": 0.015, "output": 0.075},
        "claude-3-sonnet": {"input": 0.003, "output": 0.015},
        "claude-3-haiku": {"input": 0.00025, "output": 0.00125},
    }

    def __init__(self, cloud_provider: str = "aws"):
        self.cloud_provider = cloud_provider
        self.components: Dict[str, CostComponent] = {}
        self._register_default_components()

    def _register_default_components(self):
        """Register default cost components."""
        provider = self.cloud_provider

        # GPU costs
        for gpu_type, costs in self.GPU_COSTS.items():
            self.components[f"gpu_{gpu_type}"] = CostComponent(
                name=f"GPU {gpu_type.upper()}",
                category=CostCategory.GPU_COMPUTE,
                unit="per-hour",
                unit_cost=costs.get(provider, costs["aws"]),
                description=f"{gpu_type} GPU instance"
            )

        # Storage costs
        for storage_type, costs in self.STORAGE_COSTS.items():
            self.components[f"storage_{storage_type}"] = CostComponent(
                name=f"Storage {storage_type.upper()}",
                category=CostCategory.STORAGE,
                unit="per-GB-month",
                unit_cost=costs.get(provider, costs["aws"]),
                description=f"{storage_type} storage"
            )

        # Network costs
        for network_type, costs in self.NETWORK_COSTS.items():
            self.components[f"network_{network_type}"] = CostComponent(
                name=f"Network {network_type}",
                category=CostCategory.NETWORK,
                unit="per-GB",
                unit_cost=costs.get(provider, costs["aws"]),
                description=f"{network_type} data transfer"
            )

    def calculate_gpu_cost(
        self,
        gpu_type: str,
        hours: float,
        num_gpus: int = 1,
        spot_discount: float = 0.0
    ) -> float:
        """Calculate GPU compute cost."""
        component = self.components.get(f"gpu_{gpu_type}")
        if not component:
            raise ValueError(f"Unknown GPU type: {gpu_type}")

        base_cost = component.unit_cost * hours * num_gpus
        return base_cost * (1 - spot_discount)

    def calculate_storage_cost(
        self,
        storage_type: str,
        gb: float,
        months: float = 1.0
    ) -> float:
        """Calculate storage cost."""
        component = self.components.get(f"storage_{storage_type}")
        if not component:
            raise ValueError(f"Unknown storage type: {storage_type}")

        return component.unit_cost * gb * months

    def calculate_network_cost(
        self,
        transfer_type: str,
        gb: float
    ) -> float:
        """Calculate network transfer cost."""
        component = self.components.get(f"network_{transfer_type}")
        if not component:
            raise ValueError(f"Unknown transfer type: {transfer_type}")

        return component.unit_cost * gb

    def calculate_api_cost(
        self,
        model: str,
        input_tokens: int,
        output_tokens: int
    ) -> float:
        """Calculate external API cost."""
        if model not in self.API_COSTS:
            raise ValueError(f"Unknown API model: {model}")

        costs = self.API_COSTS[model]
        input_cost = (input_tokens / 1000) * costs["input"]
        output_cost = (output_tokens / 1000) * costs["output"]

        return input_cost + output_cost

    def estimate_monthly_cost(
        self,
        config: 'InfrastructureConfig'
    ) -> Dict[str, float]:
        """Estimate monthly cost for a given infrastructure configuration."""
        costs = {}

        # GPU costs (assuming 24/7 operation)
        gpu_hours = 24 * 30  # hours per month
        gpu_cost = self.calculate_gpu_cost(
            config.gpu_type,
            gpu_hours,
            config.num_gpus,
            config.spot_discount
        )
        costs["gpu_compute"] = gpu_cost

        # Storage costs
        storage_cost = self.calculate_storage_cost(
            "ssd",
            config.storage_gb
        )
        costs["storage"] = storage_cost

        # Network costs (estimate based on traffic)
        network_cost = self.calculate_network_cost(
            "egress_internet",
            config.monthly_egress_gb
        )
        costs["network"] = network_cost

        # API costs if using external APIs
        if config.external_api_tokens_monthly > 0:
            api_cost = self.calculate_api_cost(
                config.external_api_model,
                config.external_api_tokens_monthly * 0.5,  # Assume 50% input
                config.external_api_tokens_monthly * 0.5   # 50% output
            )
            costs["external_api"] = api_cost

        costs["total"] = sum(costs.values())
        return costs


@dataclass
class InfrastructureConfig:
    """Configuration for infrastructure cost estimation."""
    gpu_type: str = "a100-40gb"
    num_gpus: int = 4
    spot_discount: float = 0.6
    storage_gb: float = 1000
    monthly_egress_gb: float = 500
    external_api_model: str = "gpt-4-turbo"
    external_api_tokens_monthly: int = 0
```

## 10.4.2 Cost Attribution

### Per-Tenant and Per-Model Attribution

```python
"""
Cost attribution system for multi-tenant LLM platforms.
"""

from dataclasses import dataclass, field
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
from collections import defaultdict
import json


@dataclass
class CostAttributionTag:
    """Tag for cost attribution."""
    key: str
    value: str


@dataclass
class AttributedCost:
    """Cost attributed to a specific entity."""
    entity_type: str  # tenant, model, feature, team
    entity_id: str
    cost_category: str
    amount: float
    currency: str = "USD"
    period_start: datetime = None
    period_end: datetime = None
    metadata: Dict[str, Any] = field(default_factory=dict)


class CostAttributionEngine:
    """
    Engine for attributing costs to various dimensions.
    """

    def __init__(self):
        self.attribution_rules: Dict[str, Dict] = {}
        self.cost_records: List[CostRecord] = []

    def add_attribution_rule(
        self,
        entity_type: str,
        entity_id: str,
        allocation_method: str,  # "direct", "proportional", "fixed"
        allocation_config: Dict[str, Any] = None
    ):
        """Add cost attribution rule."""
        key = f"{entity_type}:{entity_id}"
        self.attribution_rules[key] = {
            "entity_type": entity_type,
            "entity_id": entity_id,
            "method": allocation_method,
            "config": allocation_config or {}
        }

    def record_usage(
        self,
        timestamp: datetime,
        tenant_id: str,
        model_id: str,
        feature_id: str,
        usage_metrics: Dict[str, float],
        tags: List[CostAttributionTag] = None
    ):
        """Record usage for cost attribution."""
        record = {
            "timestamp": timestamp,
            "tenant_id": tenant_id,
            "model_id": model_id,
            "feature_id": feature_id,
            "metrics": usage_metrics,
            "tags": {t.key: t.value for t in (tags or [])}
        }
        self.cost_records.append(record)

    def calculate_tenant_costs(
        self,
        period_start: datetime,
        period_end: datetime
    ) -> Dict[str, AttributedCost]:
        """Calculate costs attributed to each tenant."""
        tenant_costs = defaultdict(float)
        tenant_usage = defaultdict(lambda: defaultdict(float))

        # Filter records for period
        period_records = [
            r for r in self.cost_records
            if period_start <= r["timestamp"] <= period_end
        ]

        # Aggregate usage by tenant
        for record in period_records:
            tenant_id = record["tenant_id"]
            for metric, value in record["metrics"].items():
                tenant_usage[tenant_id][metric] += value

        # Calculate costs based on usage
        total_usage = defaultdict(float)
        for tenant_id, metrics in tenant_usage.items():
            for metric, value in metrics.items():
                total_usage[metric] += value

        # Attribute costs proportionally
        result = {}
        for tenant_id, metrics in tenant_usage.items():
            # Calculate proportional share
            tenant_share = 0
            for metric, value in metrics.items():
                if total_usage[metric] > 0:
                    proportion = value / total_usage[metric]
                    # Assume we have total infrastructure cost
                    # This would come from actual billing data
                    tenant_share += proportion

            result[tenant_id] = AttributedCost(
                entity_type="tenant",
                entity_id=tenant_id,
                cost_category="total",
                amount=tenant_share,  # Would be multiplied by total cost
                period_start=period_start,
                period_end=period_end,
                metadata={"usage": dict(tenant_usage[tenant_id])}
            )

        return result

    def calculate_model_costs(
        self,
        period_start: datetime,
        period_end: datetime
    ) -> Dict[str, AttributedCost]:
        """Calculate costs attributed to each model."""
        model_usage = defaultdict(lambda: {
            "requests": 0,
            "tokens": 0,
            "gpu_seconds": 0
        })

        period_records = [
            r for r in self.cost_records
            if period_start <= r["timestamp"] <= period_end
        ]

        for record in period_records:
            model_id = record["model_id"]
            model_usage[model_id]["requests"] += record["metrics"].get("requests", 0)
            model_usage[model_id]["tokens"] += record["metrics"].get("tokens", 0)
            model_usage[model_id]["gpu_seconds"] += record["metrics"].get("gpu_seconds", 0)

        result = {}
        for model_id, usage in model_usage.items():
            result[model_id] = AttributedCost(
                entity_type="model",
                entity_id=model_id,
                cost_category="total",
                amount=0,  # Would be calculated from actual costs
                period_start=period_start,
                period_end=period_end,
                metadata={"usage": usage}
            )

        return result


class CostAllocationReport:
    """
    Generate cost allocation reports.
    """

    def __init__(self, attribution_engine: CostAttributionEngine):
        self.engine = attribution_engine

    def generate_tenant_report(
        self,
        tenant_id: str,
        period_start: datetime,
        period_end: datetime
    ) -> Dict[str, Any]:
        """Generate detailed cost report for a tenant."""
        tenant_costs = self.engine.calculate_tenant_costs(period_start, period_end)

        if tenant_id not in tenant_costs:
            return {"tenant_id": tenant_id, "total_cost": 0, "breakdown": {}}

        cost = tenant_costs[tenant_id]

        return {
            "tenant_id": tenant_id,
            "period": {
                "start": period_start.isoformat(),
                "end": period_end.isoformat()
            },
            "total_cost": cost.amount,
            "breakdown": {
                "by_model": self._breakdown_by_model(tenant_id, period_start, period_end),
                "by_feature": self._breakdown_by_feature(tenant_id, period_start, period_end),
                "by_day": self._breakdown_by_day(tenant_id, period_start, period_end)
            },
            "usage_metrics": cost.metadata.get("usage", {})
        }

    def _breakdown_by_model(
        self,
        tenant_id: str,
        period_start: datetime,
        period_end: datetime
    ) -> Dict[str, float]:
        """Break down tenant costs by model."""
        model_costs = defaultdict(float)

        period_records = [
            r for r in self.engine.cost_records
            if period_start <= r["timestamp"] <= period_end
            and r["tenant_id"] == tenant_id
        ]

        for record in period_records:
            model_id = record["model_id"]
            # Simplified cost calculation
            model_costs[model_id] += record["metrics"].get("tokens", 0) * 0.00001

        return dict(model_costs)

    def _breakdown_by_feature(
        self,
        tenant_id: str,
        period_start: datetime,
        period_end: datetime
    ) -> Dict[str, float]:
        """Break down tenant costs by feature."""
        feature_costs = defaultdict(float)

        period_records = [
            r for r in self.engine.cost_records
            if period_start <= r["timestamp"] <= period_end
            and r["tenant_id"] == tenant_id
        ]

        for record in period_records:
            feature_id = record["feature_id"]
            feature_costs[feature_id] += record["metrics"].get("requests", 0) * 0.001

        return dict(feature_costs)

    def _breakdown_by_day(
        self,
        tenant_id: str,
        period_start: datetime,
        period_end: datetime
    ) -> Dict[str, float]:
        """Break down tenant costs by day."""
        daily_costs = defaultdict(float)

        period_records = [
            r for r in self.engine.cost_records
            if period_start <= r["timestamp"] <= period_end
            and r["tenant_id"] == tenant_id
        ]

        for record in period_records:
            day = record["timestamp"].strftime("%Y-%m-%d")
            daily_costs[day] += record["metrics"].get("tokens", 0) * 0.00001

        return dict(daily_costs)
```

## 10.4.3 Cost Metrics

### Key Cost Performance Indicators

```python
"""
Cost metrics and KPIs for LLM systems.
"""

from dataclasses import dataclass
from typing import Dict, Any, List, Optional
from datetime import datetime, timedelta
import numpy as np


@dataclass
class CostMetric:
    """Definition of a cost metric."""
    name: str
    unit: str
    description: str
    target: Optional[float] = None
    warning_threshold: Optional[float] = None


class CostMetricsCalculator:
    """
    Calculate cost-related metrics for LLM operations.
    """

    # Standard cost metrics
    METRICS = {
        "cost_per_request": CostMetric(
            name="Cost per Request",
            unit="USD",
            description="Average cost to serve a single request",
            target=0.01,
            warning_threshold=0.05
        ),
        "cost_per_1k_tokens": CostMetric(
            name="Cost per 1K Tokens",
            unit="USD",
            description="Cost to process 1000 tokens",
            target=0.005,
            warning_threshold=0.02
        ),
        "cost_per_user_action": CostMetric(
            name="Cost per User Action",
            unit="USD",
            description="Cost attributed to each user action",
            target=0.001,
            warning_threshold=0.01
        ),
        "gpu_utilization_efficiency": CostMetric(
            name="GPU Utilization Efficiency",
            unit="percent",
            description="Effective GPU utilization vs paid capacity",
            target=80,
            warning_threshold=50
        ),
        "cost_per_active_user": CostMetric(
            name="Cost per Active User",
            unit="USD/month",
            description="Monthly cost per active user",
            target=5.0,
            warning_threshold=20.0
        ),
        "infrastructure_unit_cost": CostMetric(
            name="Infrastructure Unit Cost",
            unit="USD/GPU-hour",
            description="Effective cost per GPU hour including all overhead",
            target=3.0,
            warning_threshold=5.0
        )
    }

    def __init__(self):
        self.metrics_history: Dict[str, List[Dict]] = {
            name: [] for name in self.METRICS
        }

    def calculate_cost_per_request(
        self,
        total_cost: float,
        total_requests: int
    ) -> float:
        """Calculate cost per request."""
        if total_requests == 0:
            return 0
        return total_cost / total_requests

    def calculate_cost_per_1k_tokens(
        self,
        total_cost: float,
        total_tokens: int
    ) -> float:
        """Calculate cost per 1K tokens."""
        if total_tokens == 0:
            return 0
        return (total_cost / total_tokens) * 1000

    def calculate_gpu_utilization_efficiency(
        self,
        actual_gpu_hours: float,
        paid_gpu_hours: float,
        effective_utilization: float
    ) -> float:
        """
        Calculate GPU utilization efficiency.

        This combines:
        - How much of paid time was actually used
        - How efficiently that time was utilized (e.g., batch efficiency)
        """
        if paid_gpu_hours == 0:
            return 0

        time_efficiency = actual_gpu_hours / paid_gpu_hours
        overall_efficiency = time_efficiency * effective_utilization

        return overall_efficiency * 100  # As percentage

    def calculate_cost_efficiency_score(
        self,
        metrics: Dict[str, float]
    ) -> float:
        """
        Calculate overall cost efficiency score (0-100).
        """
        scores = []

        for metric_name, value in metrics.items():
            if metric_name not in self.METRICS:
                continue

            metric = self.METRICS[metric_name]
            if metric.target is None:
                continue

            # Calculate score relative to target
            if metric.unit == "percent":
                # Higher is better
                score = min(100, (value / metric.target) * 100)
            else:
                # Lower is better
                score = min(100, (metric.target / max(value, 0.0001)) * 100)

            scores.append(score)

        return np.mean(scores) if scores else 0

    def record_metrics(
        self,
        timestamp: datetime,
        metrics: Dict[str, float]
    ):
        """Record metrics for trend analysis."""
        for name, value in metrics.items():
            if name in self.metrics_history:
                self.metrics_history[name].append({
                    "timestamp": timestamp,
                    "value": value
                })

    def get_metric_trend(
        self,
        metric_name: str,
        period_days: int = 30
    ) -> Dict[str, Any]:
        """Get trend analysis for a metric."""
        if metric_name not in self.metrics_history:
            return {}

        history = self.metrics_history[metric_name]
        cutoff = datetime.utcnow() - timedelta(days=period_days)

        recent = [h for h in history if h["timestamp"] > cutoff]
        if len(recent) < 2:
            return {"trend": "insufficient_data"}

        values = [h["value"] for h in recent]

        # Calculate trend
        x = np.arange(len(values))
        slope, _ = np.polyfit(x, values, 1)

        return {
            "current": values[-1],
            "average": np.mean(values),
            "min": np.min(values),
            "max": np.max(values),
            "trend_direction": "increasing" if slope > 0 else "decreasing",
            "trend_magnitude": abs(slope),
            "samples": len(values)
        }


class TokenEconomicsCalculator:
    """
    Calculate token-based economics for LLM operations.
    """

    def __init__(self, cost_model: LLMCostModel):
        self.cost_model = cost_model

    def calculate_request_cost(
        self,
        model: str,
        input_tokens: int,
        output_tokens: int,
        is_cached: bool = False,
        cache_hit_discount: float = 0.9
    ) -> Dict[str, float]:
        """Calculate detailed cost for a single request."""
        # Base costs
        if hasattr(self.cost_model, 'API_COSTS') and model in self.cost_model.API_COSTS:
            costs = self.cost_model.API_COSTS[model]
            input_cost = (input_tokens / 1000) * costs["input"]
            output_cost = (output_tokens / 1000) * costs["output"]
        else:
            # Default self-hosted costs
            input_cost = (input_tokens / 1000) * 0.001
            output_cost = (output_tokens / 1000) * 0.002

        # Apply cache discount
        if is_cached:
            input_cost *= (1 - cache_hit_discount)

        total_cost = input_cost + output_cost

        return {
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
            "input_cost": input_cost,
            "output_cost": output_cost,
            "total_cost": total_cost,
            "cost_per_token": total_cost / (input_tokens + output_tokens) if (input_tokens + output_tokens) > 0 else 0,
            "cache_savings": input_cost * cache_hit_discount / (1 - cache_hit_discount) if is_cached else 0
        }

    def estimate_conversation_cost(
        self,
        model: str,
        turns: int,
        avg_user_tokens: int = 50,
        avg_assistant_tokens: int = 200,
        context_growth_factor: float = 0.3
    ) -> Dict[str, float]:
        """
        Estimate cost for a multi-turn conversation.

        Context grows with each turn, affecting input costs.
        """
        total_cost = 0
        accumulated_context = 0

        turn_costs = []
        for turn in range(turns):
            # Input includes context + new user message
            input_tokens = accumulated_context + avg_user_tokens
            output_tokens = avg_assistant_tokens

            turn_cost = self.calculate_request_cost(
                model, input_tokens, output_tokens
            )
            turn_costs.append(turn_cost["total_cost"])
            total_cost += turn_cost["total_cost"]

            # Context grows
            accumulated_context += int(
                (avg_user_tokens + avg_assistant_tokens) * context_growth_factor
            )

        return {
            "total_cost": total_cost,
            "avg_cost_per_turn": total_cost / turns,
            "first_turn_cost": turn_costs[0] if turn_costs else 0,
            "last_turn_cost": turn_costs[-1] if turn_costs else 0,
            "cost_growth_ratio": turn_costs[-1] / turn_costs[0] if turn_costs and turn_costs[0] > 0 else 1,
            "turn_costs": turn_costs
        }

    def compare_model_costs(
        self,
        models: List[str],
        workload: Dict[str, int]  # input_tokens, output_tokens, requests
    ) -> Dict[str, Dict[str, float]]:
        """Compare costs across different models for a workload."""
        comparison = {}

        for model in models:
            request_cost = self.calculate_request_cost(
                model,
                workload.get("input_tokens", 100),
                workload.get("output_tokens", 500)
            )

            total_requests = workload.get("requests", 1000)
            total_cost = request_cost["total_cost"] * total_requests

            comparison[model] = {
                "cost_per_request": request_cost["total_cost"],
                "total_cost": total_cost,
                "input_cost_ratio": request_cost["input_cost"] / request_cost["total_cost"] if request_cost["total_cost"] > 0 else 0,
                "output_cost_ratio": request_cost["output_cost"] / request_cost["total_cost"] if request_cost["total_cost"] > 0 else 0
            }

        # Add ranking
        sorted_models = sorted(comparison.items(), key=lambda x: x[1]["total_cost"])
        for rank, (model, _) in enumerate(sorted_models, 1):
            comparison[model]["cost_rank"] = rank

        return comparison
```

## 10.4.4 Optimization Strategies

### Infrastructure Optimization

```python
"""
Cost optimization strategies for LLM infrastructure.
"""

from dataclasses import dataclass
from typing import Dict, Any, List, Optional, Tuple
from datetime import datetime, timedelta
from enum import Enum
import numpy as np


class OptimizationStrategy(Enum):
    """Types of cost optimization strategies."""
    RIGHT_SIZING = "right_sizing"
    SPOT_INSTANCES = "spot_instances"
    RESERVED_CAPACITY = "reserved_capacity"
    AUTO_SCALING = "auto_scaling"
    MULTI_CLOUD = "multi_cloud"
    CACHING = "caching"
    MODEL_CASCADE = "model_cascade"
    QUANTIZATION = "quantization"
    BATCH_OPTIMIZATION = "batch_optimization"


@dataclass
class OptimizationRecommendation:
    """Cost optimization recommendation."""
    strategy: OptimizationStrategy
    title: str
    description: str
    estimated_savings_pct: float
    implementation_effort: str  # "low", "medium", "high"
    risk_level: str  # "low", "medium", "high"
    details: Dict[str, Any] = None


class InfrastructureOptimizer:
    """
    Infrastructure cost optimization for LLM systems.
    """

    def __init__(self, cost_model: LLMCostModel):
        self.cost_model = cost_model

    def analyze_right_sizing(
        self,
        current_config: InfrastructureConfig,
        utilization_data: Dict[str, float]
    ) -> OptimizationRecommendation:
        """
        Analyze if current GPU instances are right-sized.
        """
        gpu_util = utilization_data.get("gpu_utilization", 100)
        memory_util = utilization_data.get("gpu_memory_utilization", 100)

        recommendations = []

        # Under-utilized
        if gpu_util < 50 and memory_util < 60:
            recommendations.append({
                "action": "downgrade",
                "reason": f"GPU utilization ({gpu_util}%) and memory ({memory_util}%) are low",
                "suggested_gpu": self._suggest_smaller_gpu(current_config.gpu_type)
            })

        # Over-utilized
        if gpu_util > 90 or memory_util > 85:
            recommendations.append({
                "action": "upgrade",
                "reason": f"High utilization - GPU: {gpu_util}%, Memory: {memory_util}%",
                "suggested_gpu": self._suggest_larger_gpu(current_config.gpu_type)
            })

        # Calculate potential savings
        if recommendations:
            rec = recommendations[0]
            if rec["action"] == "downgrade":
                current_cost = self.cost_model.GPU_COSTS.get(
                    current_config.gpu_type, {}
                ).get(self.cost_model.cloud_provider, 5)
                new_cost = self.cost_model.GPU_COSTS.get(
                    rec["suggested_gpu"], {}
                ).get(self.cost_model.cloud_provider, current_cost)
                savings_pct = ((current_cost - new_cost) / current_cost) * 100
            else:
                savings_pct = 0  # Upgrade doesn't save money but improves performance

            return OptimizationRecommendation(
                strategy=OptimizationStrategy.RIGHT_SIZING,
                title="Right-size GPU instances",
                description=rec["reason"],
                estimated_savings_pct=savings_pct,
                implementation_effort="medium",
                risk_level="low",
                details={"recommendations": recommendations}
            )

        return None

    def analyze_spot_opportunity(
        self,
        current_config: InfrastructureConfig,
        workload_pattern: Dict[str, Any]
    ) -> OptimizationRecommendation:
        """
        Analyze opportunity for spot/preemptible instances.
        """
        # Check if workload is interruptible
        fault_tolerance = workload_pattern.get("fault_tolerance", "low")
        can_checkpoint = workload_pattern.get("can_checkpoint", False)
        latency_sensitive = workload_pattern.get("latency_sensitive", True)

        if fault_tolerance == "high" or (can_checkpoint and not latency_sensitive):
            spot_discount = 0.6 to 0.7  # Typical spot savings

            return OptimizationRecommendation(
                strategy=OptimizationStrategy.SPOT_INSTANCES,
                title="Use spot/preemptible instances",
                description="Workload characteristics support using spot instances",
                estimated_savings_pct=60,
                implementation_effort="medium",
                risk_level="medium",
                details={
                    "recommended_spot_percentage": 70 if fault_tolerance == "high" else 30,
                    "fallback_strategy": "on-demand",
                    "checkpointing_required": not can_checkpoint
                }
            )

        return None

    def analyze_reserved_capacity(
        self,
        usage_history: List[Dict[str, float]],
        forecast_horizon_months: int = 12
    ) -> OptimizationRecommendation:
        """
        Analyze opportunity for reserved capacity commitments.
        """
        if len(usage_history) < 30:
            return None

        # Calculate baseline usage
        daily_usage = [h.get("gpu_hours", 0) for h in usage_history[-30:]]
        baseline = np.percentile(daily_usage, 25)  # 25th percentile as baseline

        # Reserved capacity typically saves 30-60% for 1-3 year commitments
        if baseline > 0:
            monthly_baseline_hours = baseline * 30
            on_demand_cost = monthly_baseline_hours * 4  # Example hourly rate

            reserved_savings = {
                "1_year_no_upfront": 0.30,
                "1_year_partial_upfront": 0.40,
                "1_year_all_upfront": 0.45,
                "3_year_no_upfront": 0.40,
                "3_year_partial_upfront": 0.55,
                "3_year_all_upfront": 0.60
            }

            return OptimizationRecommendation(
                strategy=OptimizationStrategy.RESERVED_CAPACITY,
                title="Purchase reserved capacity",
                description=f"Baseline usage of {baseline:.0f} GPU-hours/day supports reservations",
                estimated_savings_pct=40,  # Conservative estimate
                implementation_effort="low",
                risk_level="medium",  # Commitment risk
                details={
                    "baseline_hours_daily": baseline,
                    "recommended_reserved_hours": monthly_baseline_hours,
                    "savings_options": reserved_savings
                }
            )

        return None

    def analyze_auto_scaling(
        self,
        usage_pattern: List[Dict[str, float]],
        current_scaling_config: Dict[str, Any]
    ) -> OptimizationRecommendation:
        """
        Analyze auto-scaling configuration optimization.
        """
        # Analyze usage patterns
        hourly_usage = self._aggregate_hourly(usage_pattern)

        peak_hour = max(hourly_usage, key=hourly_usage.get)
        trough_hour = min(hourly_usage, key=hourly_usage.get)

        peak_usage = hourly_usage[peak_hour]
        trough_usage = hourly_usage[trough_hour]

        # Calculate potential savings from better scaling
        usage_variance = (peak_usage - trough_usage) / peak_usage if peak_usage > 0 else 0

        if usage_variance > 0.3:  # Significant variance
            return OptimizationRecommendation(
                strategy=OptimizationStrategy.AUTO_SCALING,
                title="Optimize auto-scaling configuration",
                description=f"Usage varies by {usage_variance*100:.0f}% between peak and trough",
                estimated_savings_pct=usage_variance * 50,  # Conservative estimate
                implementation_effort="medium",
                risk_level="low",
                details={
                    "peak_hour": peak_hour,
                    "trough_hour": trough_hour,
                    "peak_usage": peak_usage,
                    "trough_usage": trough_usage,
                    "recommended_min_instances": int(trough_usage * 1.1),
                    "recommended_max_instances": int(peak_usage * 1.2)
                }
            )

        return None

    def _suggest_smaller_gpu(self, current_gpu: str) -> str:
        """Suggest a smaller GPU type."""
        gpu_hierarchy = ["t4-16gb", "a10g-24gb", "l4-24gb", "a100-40gb", "a100-80gb", "h100-80gb"]
        current_idx = gpu_hierarchy.index(current_gpu) if current_gpu in gpu_hierarchy else 0
        return gpu_hierarchy[max(0, current_idx - 1)]

    def _suggest_larger_gpu(self, current_gpu: str) -> str:
        """Suggest a larger GPU type."""
        gpu_hierarchy = ["t4-16gb", "a10g-24gb", "l4-24gb", "a100-40gb", "a100-80gb", "h100-80gb"]
        current_idx = gpu_hierarchy.index(current_gpu) if current_gpu in gpu_hierarchy else len(gpu_hierarchy) - 1
        return gpu_hierarchy[min(len(gpu_hierarchy) - 1, current_idx + 1)]

    def _aggregate_hourly(self, usage_pattern: List[Dict[str, float]]) -> Dict[int, float]:
        """Aggregate usage by hour of day."""
        hourly = {h: [] for h in range(24)}
        for record in usage_pattern:
            hour = record.get("timestamp", datetime.utcnow()).hour
            hourly[hour].append(record.get("usage", 0))
        return {h: np.mean(v) if v else 0 for h, v in hourly.items()}


class ModelOptimizer:
    """
    Model-level cost optimization strategies.
    """

    def analyze_caching_opportunity(
        self,
        request_data: List[Dict[str, Any]]
    ) -> OptimizationRecommendation:
        """
        Analyze caching opportunities for repeated queries.
        """
        # Analyze prompt similarity/repetition
        prompt_hashes = [r.get("prompt_hash") for r in request_data]
        unique_prompts = len(set(prompt_hashes))
        total_prompts = len(prompt_hashes)

        cache_hit_potential = 1 - (unique_prompts / total_prompts) if total_prompts > 0 else 0

        if cache_hit_potential > 0.1:  # More than 10% repeats
            return OptimizationRecommendation(
                strategy=OptimizationStrategy.CACHING,
                title="Implement semantic caching",
                description=f"{cache_hit_potential*100:.0f}% of requests could be cache hits",
                estimated_savings_pct=cache_hit_potential * 80,  # Cache hits save ~80%
                implementation_effort="medium",
                risk_level="low",
                details={
                    "unique_prompts": unique_prompts,
                    "total_prompts": total_prompts,
                    "estimated_cache_hit_rate": cache_hit_potential,
                    "recommended_cache_type": "semantic" if cache_hit_potential < 0.3 else "exact"
                }
            )

        return None

    def analyze_model_cascade(
        self,
        request_data: List[Dict[str, Any]],
        model_capabilities: Dict[str, Dict[str, float]]
    ) -> OptimizationRecommendation:
        """
        Analyze opportunity for model cascading.
        """
        # Analyze request complexity distribution
        complexities = [r.get("complexity_score", 0.5) for r in request_data]

        simple_requests = sum(1 for c in complexities if c < 0.3)
        medium_requests = sum(1 for c in complexities if 0.3 <= c < 0.7)
        complex_requests = sum(1 for c in complexities if c >= 0.7)

        total = len(complexities)
        simple_ratio = simple_requests / total if total > 0 else 0

        if simple_ratio > 0.3:  # 30%+ simple requests
            # Calculate savings from using smaller model for simple requests
            return OptimizationRecommendation(
                strategy=OptimizationStrategy.MODEL_CASCADE,
                title="Implement model cascade",
                description=f"{simple_ratio*100:.0f}% of requests could use smaller/cheaper models",
                estimated_savings_pct=simple_ratio * 60,  # Smaller models ~60% cheaper
                implementation_effort="high",
                risk_level="medium",
                details={
                    "request_distribution": {
                        "simple": simple_requests,
                        "medium": medium_requests,
                        "complex": complex_requests
                    },
                    "recommended_cascade": [
                        {"tier": 1, "model": "small", "complexity_threshold": 0.3},
                        {"tier": 2, "model": "medium", "complexity_threshold": 0.7},
                        {"tier": 3, "model": "large", "complexity_threshold": 1.0}
                    ]
                }
            )

        return None

    def analyze_quantization_opportunity(
        self,
        current_model_config: Dict[str, Any],
        quality_requirements: Dict[str, float]
    ) -> OptimizationRecommendation:
        """
        Analyze opportunity for model quantization.
        """
        current_precision = current_model_config.get("precision", "fp16")
        current_quality = current_model_config.get("quality_score", 1.0)
        min_quality = quality_requirements.get("min_quality", 0.95)

        # Quantization savings estimates
        quantization_options = {
            "fp16": {"memory_reduction": 0, "speed_improvement": 0, "quality_loss": 0},
            "int8": {"memory_reduction": 0.5, "speed_improvement": 0.3, "quality_loss": 0.02},
            "int4": {"memory_reduction": 0.75, "speed_improvement": 0.5, "quality_loss": 0.05},
            "int4_awq": {"memory_reduction": 0.75, "speed_improvement": 0.45, "quality_loss": 0.03},
        }

        if current_precision == "fp16":
            # Check if we can quantize while meeting quality requirements
            for quant_type, specs in quantization_options.items():
                if quant_type == "fp16":
                    continue

                projected_quality = current_quality * (1 - specs["quality_loss"])
                if projected_quality >= min_quality:
                    return OptimizationRecommendation(
                        strategy=OptimizationStrategy.QUANTIZATION,
                        title=f"Apply {quant_type} quantization",
                        description=f"Reduce memory by {specs['memory_reduction']*100:.0f}% with minimal quality loss",
                        estimated_savings_pct=specs["memory_reduction"] * 40,  # Memory savings translate to cost
                        implementation_effort="medium",
                        risk_level="medium",
                        details={
                            "current_precision": current_precision,
                            "recommended_precision": quant_type,
                            "memory_reduction": specs["memory_reduction"],
                            "speed_improvement": specs["speed_improvement"],
                            "projected_quality": projected_quality
                        }
                    )

        return None

    def analyze_batch_optimization(
        self,
        request_pattern: List[Dict[str, Any]],
        current_batch_config: Dict[str, Any]
    ) -> OptimizationRecommendation:
        """
        Analyze batch processing optimization opportunities.
        """
        # Analyze request arrival patterns
        inter_arrival_times = []
        for i in range(1, len(request_pattern)):
            t1 = request_pattern[i-1].get("timestamp")
            t2 = request_pattern[i].get("timestamp")
            if t1 and t2:
                inter_arrival_times.append((t2 - t1).total_seconds())

        if not inter_arrival_times:
            return None

        avg_inter_arrival = np.mean(inter_arrival_times)
        current_batch_size = current_batch_config.get("batch_size", 1)
        current_batch_timeout = current_batch_config.get("timeout_ms", 100)

        # Calculate optimal batch parameters
        optimal_batch_size = min(32, int(1000 / avg_inter_arrival) + 1)
        optimal_timeout = avg_inter_arrival * 1000 * 2  # 2x average arrival time

        if optimal_batch_size > current_batch_size * 1.5:
            return OptimizationRecommendation(
                strategy=OptimizationStrategy.BATCH_OPTIMIZATION,
                title="Increase batch size",
                description=f"Request pattern supports batch size of {optimal_batch_size}",
                estimated_savings_pct=min(50, (optimal_batch_size - current_batch_size) * 5),
                implementation_effort="low",
                risk_level="low",
                details={
                    "current_batch_size": current_batch_size,
                    "recommended_batch_size": optimal_batch_size,
                    "current_timeout_ms": current_batch_timeout,
                    "recommended_timeout_ms": optimal_timeout,
                    "avg_inter_arrival_ms": avg_inter_arrival * 1000
                }
            )

        return None
```

## 10.4.5 Cost Dashboards & Alerts

### Dashboard Configuration

```python
"""
Cost monitoring dashboards and alerting.
"""

from dataclasses import dataclass
from typing import Dict, Any, List
import json


class CostDashboardBuilder:
    """
    Build cost monitoring dashboards for Grafana.
    """

    def generate_grafana_dashboard(self) -> Dict[str, Any]:
        """Generate comprehensive cost monitoring dashboard."""
        return {
            "title": "LLM Cost Monitoring",
            "refresh": "5m",
            "panels": self._generate_panels(),
            "templating": self._generate_variables()
        }

    def _generate_panels(self) -> List[Dict[str, Any]]:
        """Generate dashboard panels."""
        panels = []
        panel_id = 1

        # Total Cost Gauge
        panels.append({
            "id": panel_id,
            "title": "Current Month Cost",
            "type": "stat",
            "gridPos": {"x": 0, "y": 0, "w": 6, "h": 4},
            "targets": [{
                "expr": 'sum(llm_cost_total{period="mtd"})',
                "legendFormat": "MTD Cost"
            }],
            "fieldConfig": {
                "defaults": {
                    "unit": "currencyUSD",
                    "thresholds": {
                        "steps": [
                            {"value": 0, "color": "green"},
                            {"value": 10000, "color": "yellow"},
                            {"value": 50000, "color": "red"}
                        ]
                    }
                }
            }
        })
        panel_id += 1

        # Cost vs Budget
        panels.append({
            "id": panel_id,
            "title": "Cost vs Budget",
            "type": "gauge",
            "gridPos": {"x": 6, "y": 0, "w": 6, "h": 4},
            "targets": [{
                "expr": 'sum(llm_cost_total{period="mtd"}) / llm_budget_monthly * 100',
                "legendFormat": "Budget Utilization"
            }],
            "fieldConfig": {
                "defaults": {
                    "unit": "percent",
                    "min": 0,
                    "max": 150,
                    "thresholds": {
                        "steps": [
                            {"value": 0, "color": "green"},
                            {"value": 80, "color": "yellow"},
                            {"value": 100, "color": "red"}
                        ]
                    }
                }
            }
        })
        panel_id += 1

        # Cost Trend
        panels.append({
            "id": panel_id,
            "title": "Daily Cost Trend",
            "type": "timeseries",
            "gridPos": {"x": 12, "y": 0, "w": 12, "h": 8},
            "targets": [
                {
                    "expr": 'sum(increase(llm_cost_total[1d])) by (category)',
                    "legendFormat": "{{category}}"
                }
            ],
            "fieldConfig": {
                "defaults": {"unit": "currencyUSD"}
            }
        })
        panel_id += 1

        # Cost by Model
        panels.append({
            "id": panel_id,
            "title": "Cost by Model",
            "type": "piechart",
            "gridPos": {"x": 0, "y": 4, "w": 6, "h": 6},
            "targets": [{
                "expr": 'sum(llm_cost_total{period="mtd"}) by (model)',
                "legendFormat": "{{model}}"
            }]
        })
        panel_id += 1

        # Cost by Tenant
        panels.append({
            "id": panel_id,
            "title": "Cost by Tenant (Top 10)",
            "type": "bargauge",
            "gridPos": {"x": 6, "y": 4, "w": 6, "h": 6},
            "targets": [{
                "expr": 'topk(10, sum(llm_cost_total{period="mtd"}) by (tenant_id))',
                "legendFormat": "{{tenant_id}}"
            }],
            "fieldConfig": {
                "defaults": {"unit": "currencyUSD"}
            }
        })
        panel_id += 1

        # Cost per Request
        panels.append({
            "id": panel_id,
            "title": "Cost per Request",
            "type": "timeseries",
            "gridPos": {"x": 0, "y": 10, "w": 12, "h": 6},
            "targets": [
                {
                    "expr": '''
                        sum(rate(llm_cost_total[5m]))
                        / sum(rate(llm_requests_total[5m]))
                    ''',
                    "legendFormat": "Avg Cost per Request"
                }
            ],
            "fieldConfig": {
                "defaults": {"unit": "currencyUSD", "decimals": 4}
            }
        })
        panel_id += 1

        # GPU Utilization vs Cost
        panels.append({
            "id": panel_id,
            "title": "GPU Cost Efficiency",
            "type": "timeseries",
            "gridPos": {"x": 12, "y": 10, "w": 12, "h": 6},
            "targets": [
                {
                    "expr": 'avg(gpu_utilization_percent)',
                    "legendFormat": "GPU Utilization %"
                },
                {
                    "expr": '''
                        sum(rate(llm_requests_total[5m])) * 3600
                        / sum(gpu_instance_count)
                    ''',
                    "legendFormat": "Requests per GPU-hour"
                }
            ]
        })
        panel_id += 1

        # Cost Forecast
        panels.append({
            "id": panel_id,
            "title": "Monthly Cost Forecast",
            "type": "stat",
            "gridPos": {"x": 0, "y": 16, "w": 8, "h": 4},
            "targets": [{
                "expr": '''
                    sum(llm_cost_total{period="mtd"})
                    / (day_of_month() / days_in_month())
                ''',
                "legendFormat": "Projected Monthly Cost"
            }],
            "fieldConfig": {
                "defaults": {
                    "unit": "currencyUSD",
                    "color": {"mode": "thresholds"}
                }
            }
        })
        panel_id += 1

        # Optimization Opportunities
        panels.append({
            "id": panel_id,
            "title": "Optimization Opportunities",
            "type": "table",
            "gridPos": {"x": 8, "y": 16, "w": 16, "h": 6},
            "targets": [{
                "expr": 'llm_optimization_opportunity',
                "format": "table"
            }],
            "transformations": [
                {"id": "organize", "options": {
                    "renameByName": {
                        "strategy": "Strategy",
                        "estimated_savings": "Est. Savings",
                        "effort": "Effort"
                    }
                }}
            ]
        })

        return panels

    def _generate_variables(self) -> Dict[str, Any]:
        """Generate dashboard template variables."""
        return {
            "list": [
                {
                    "name": "tenant_id",
                    "type": "query",
                    "query": 'label_values(llm_cost_total, tenant_id)',
                    "multi": True,
                    "includeAll": True
                },
                {
                    "name": "model",
                    "type": "query",
                    "query": 'label_values(llm_cost_total, model)',
                    "multi": True,
                    "includeAll": True
                },
                {
                    "name": "environment",
                    "type": "custom",
                    "options": [
                        {"text": "Production", "value": "prod"},
                        {"text": "Staging", "value": "staging"}
                    ]
                }
            ]
        }


def generate_cost_alert_rules() -> str:
    """Generate Prometheus alerting rules for cost monitoring."""
    return """
groups:
  - name: llm_cost_alerts
    rules:
      - alert: BudgetExceeded
        expr: |
          sum(llm_cost_total{period="mtd"})
          / llm_budget_monthly > 1.0
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "Monthly budget exceeded"
          description: "Current spend is {{ $value | humanizePercentage }} of budget"

      - alert: BudgetWarning
        expr: |
          sum(llm_cost_total{period="mtd"})
          / llm_budget_monthly > 0.8
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "Approaching monthly budget"
          description: "Current spend is {{ $value | humanizePercentage }} of budget"

      - alert: CostSpike
        expr: |
          sum(increase(llm_cost_total[1h]))
          > 2 * avg_over_time(sum(increase(llm_cost_total[1h]))[24h:1h])
        for: 30m
        labels:
          severity: warning
        annotations:
          summary: "Unusual cost spike detected"
          description: "Hourly cost is 2x higher than 24h average"

      - alert: HighCostPerRequest
        expr: |
          sum(rate(llm_cost_total[5m]))
          / sum(rate(llm_requests_total[5m]))
          > 0.10
        for: 15m
        labels:
          severity: warning
        annotations:
          summary: "High cost per request"
          description: "Average cost per request is ${{ $value }}"

      - alert: LowGPUEfficiency
        expr: |
          avg(gpu_utilization_percent) < 30
          and sum(llm_cost_total{category="gpu_compute"}) > 1000
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "Low GPU utilization efficiency"
          description: "GPU utilization is {{ $value }}% with significant spend"

      - alert: UnexpectedTenantCost
        expr: |
          sum(increase(llm_cost_total[1d])) by (tenant_id)
          > 3 * avg_over_time(sum(increase(llm_cost_total[1d])) by (tenant_id)[7d:1d])
        for: 2h
        labels:
          severity: warning
        annotations:
          summary: "Unexpected tenant cost increase"
          description: "Tenant {{ $labels.tenant_id }} cost is 3x higher than average"

      - alert: ForecastOverBudget
        expr: |
          sum(llm_cost_total{period="mtd"})
          / (day_of_month() / days_in_month())
          > llm_budget_monthly * 1.1
        for: 1h
        labels:
          severity: warning
        annotations:
          summary: "Cost forecast exceeds budget"
          description: "Projected monthly cost is {{ $value | humanize }} (budget: {{ llm_budget_monthly }})"
"""


class CostAnomalyDetector:
    """
    Detect cost anomalies for alerting.
    """

    def __init__(self, lookback_days: int = 30):
        self.lookback_days = lookback_days
        self.baseline: Dict[str, Dict[str, float]] = {}

    def update_baseline(self, historical_costs: List[Dict[str, Any]]):
        """Update baseline statistics from historical data."""
        # Group by category
        by_category = {}
        for record in historical_costs:
            category = record.get("category", "total")
            if category not in by_category:
                by_category[category] = []
            by_category[category].append(record.get("amount", 0))

        # Calculate statistics
        for category, values in by_category.items():
            self.baseline[category] = {
                "mean": np.mean(values),
                "std": np.std(values),
                "p95": np.percentile(values, 95),
                "p99": np.percentile(values, 99)
            }

    def detect_anomaly(
        self,
        category: str,
        current_value: float,
        sensitivity: float = 2.0
    ) -> Dict[str, Any]:
        """Detect if current value is anomalous."""
        if category not in self.baseline:
            return {"is_anomaly": False, "reason": "no_baseline"}

        baseline = self.baseline[category]
        z_score = (current_value - baseline["mean"]) / baseline["std"] if baseline["std"] > 0 else 0

        is_anomaly = abs(z_score) > sensitivity

        return {
            "is_anomaly": is_anomaly,
            "z_score": z_score,
            "current_value": current_value,
            "baseline_mean": baseline["mean"],
            "baseline_std": baseline["std"],
            "threshold_used": sensitivity
        }


## Summary

This guide covered comprehensive cost monitoring and optimization for LLM systems:

1. **Cost Components**: GPU compute, storage, network, external APIs, and data annotation costs
2. **Cost Attribution**: Per-tenant, per-model, and per-feature cost allocation
3. **Cost Metrics**: Cost per request, cost per token, GPU efficiency, and unit economics
4. **Optimization Strategies**: Right-sizing, spot instances, caching, model cascades, quantization
5. **Dashboards & Alerts**: Real-time cost tracking, budget alerts, anomaly detection

Key takeaways:
- Track costs at multiple granularities (tenant, model, feature)
- Implement multi-dimensional cost attribution for chargeback
- Use spot instances and reserved capacity strategically
- Optimize through caching, model cascades, and quantization
- Set up proactive alerts before budget overruns
- Continuously analyze optimization opportunities

---

> **Navigation**
> [← 10.3 Model Quality](10.3_model_quality_monitoring_guide.md) | **[Index](../README.md#15-repository-structure)** | [11.1 LLM Security →](../11_security_governance/11.1_llm_security_guide.md)
