> **Navigation** | [← 15.2 Data Migration](15.2_data_migration_guide.md) | [README →](../README.md)
>
> | | |
> |---|---|
> | **Prerequisites** | [15.1-15.2 Migration](15.1_model_migration_guide.md) &#124; API design &#124; Enterprise systems |
> | **Related** | [9.3 API Design](../09_inference_serving/9.3_api_design_llm_services_guide.md) &#124; [12.2 SDK Design](../12_user_developer_experience/12.2_sdk_client_library_guide.md) |
> | **Next** | [README - Document Index](../README.md) |

# 15.3 System Integration Guide

## Document Information
- **Version**: 1.0
- **Last Updated**: 2024-01-15
- **Owner**: Platform Integration Team
- **Classification**: Internal

## Table of Contents
1. [Overview](#1-overview)
2. [Integration Architecture](#2-integration-architecture)
3. [API Integration Patterns](#3-api-integration-patterns)
4. [Enterprise System Connectivity](#4-enterprise-system-connectivity)
5. [Event-Driven Integration](#5-event-driven-integration)
6. [Third-Party Service Integration](#6-third-party-service-integration)
7. [Integration Testing](#7-integration-testing)
8. [Monitoring and Operations](#8-monitoring-and-operations)

---

## 1. Overview

### 1.1 Purpose
This guide provides comprehensive patterns and implementations for integrating the Multi-Cloud RAG Platform with enterprise systems, third-party services, and internal applications.

### 1.2 Integration Principles
- **Loose Coupling**: Systems communicate through well-defined interfaces
- **Resilience**: Failures in one system don't cascade to others
- **Observability**: All integrations are monitored and traced
- **Security**: Zero-trust approach with authentication at every boundary

---

## 2. Integration Architecture

### 2.1 Core Integration Framework

```python
"""
Core integration framework providing base classes and utilities.
"""
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Generic, TypeVar
from enum import Enum
import asyncio
import aiohttp
import time
import json
import hashlib
import logging
from datetime import datetime, timedelta
from functools import wraps
import backoff

logger = logging.getLogger(__name__)

T = TypeVar('T')

class IntegrationType(Enum):
    REST_API = "rest_api"
    GRAPHQL = "graphql"
    GRPC = "grpc"
    WEBHOOK = "webhook"
    MESSAGE_QUEUE = "message_queue"
    DATABASE = "database"
    FILE_TRANSFER = "file_transfer"

class IntegrationStatus(Enum):
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"

@dataclass
class IntegrationConfig:
    """Configuration for an integration endpoint."""
    name: str
    integration_type: IntegrationType
    base_url: str
    auth_type: str  # api_key, oauth2, basic, mtls
    timeout_seconds: float = 30.0
    retry_attempts: int = 3
    retry_backoff_base: float = 2.0
    circuit_breaker_threshold: int = 5
    circuit_breaker_timeout: int = 60
    rate_limit_requests: int = 100
    rate_limit_window: int = 60
    headers: Dict[str, str] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class IntegrationResult(Generic[T]):
    """Result of an integration call."""
    success: bool
    data: Optional[T] = None
    error: Optional[str] = None
    status_code: Optional[int] = None
    latency_ms: float = 0.0
    retry_count: int = 0
    trace_id: Optional[str] = None

class CircuitBreaker:
    """Circuit breaker pattern implementation."""

    def __init__(
        self,
        failure_threshold: int = 5,
        recovery_timeout: int = 60,
        half_open_requests: int = 3
    ):
        self.failure_threshold = failure_threshold
        self.recovery_timeout = recovery_timeout
        self.half_open_requests = half_open_requests
        self.failures = 0
        self.last_failure_time: Optional[float] = None
        self.state = "closed"  # closed, open, half_open
        self.half_open_successes = 0
        self._lock = asyncio.Lock()

    async def call(self, func, *args, **kwargs):
        """Execute function with circuit breaker protection."""
        async with self._lock:
            if self.state == "open":
                if time.time() - self.last_failure_time > self.recovery_timeout:
                    self.state = "half_open"
                    self.half_open_successes = 0
                    logger.info("Circuit breaker transitioning to half-open")
                else:
                    raise CircuitOpenError(
                        f"Circuit is open, retry after "
                        f"{self.recovery_timeout - (time.time() - self.last_failure_time):.0f}s"
                    )

        try:
            result = await func(*args, **kwargs)
            await self._on_success()
            return result
        except Exception as e:
            await self._on_failure()
            raise

    async def _on_success(self):
        async with self._lock:
            if self.state == "half_open":
                self.half_open_successes += 1
                if self.half_open_successes >= self.half_open_requests:
                    self.state = "closed"
                    self.failures = 0
                    logger.info("Circuit breaker closed")
            else:
                self.failures = 0

    async def _on_failure(self):
        async with self._lock:
            self.failures += 1
            self.last_failure_time = time.time()
            if self.state == "half_open" or self.failures >= self.failure_threshold:
                self.state = "open"
                logger.warning(f"Circuit breaker opened after {self.failures} failures")

class CircuitOpenError(Exception):
    pass

class RateLimiter:
    """Token bucket rate limiter."""

    def __init__(self, requests_per_window: int, window_seconds: int):
        self.requests_per_window = requests_per_window
        self.window_seconds = window_seconds
        self.tokens = requests_per_window
        self.last_refill = time.time()
        self._lock = asyncio.Lock()

    async def acquire(self, tokens: int = 1) -> bool:
        """Acquire tokens, waiting if necessary."""
        async with self._lock:
            self._refill()
            if self.tokens >= tokens:
                self.tokens -= tokens
                return True
            wait_time = (tokens - self.tokens) / (
                self.requests_per_window / self.window_seconds
            )
            await asyncio.sleep(wait_time)
            self._refill()
            self.tokens -= tokens
            return True

    def _refill(self):
        now = time.time()
        elapsed = now - self.last_refill
        refill_amount = elapsed * (self.requests_per_window / self.window_seconds)
        self.tokens = min(self.requests_per_window, self.tokens + refill_amount)
        self.last_refill = now


class BaseIntegration(ABC):
    """Base class for all integrations."""

    def __init__(self, config: IntegrationConfig):
        self.config = config
        self.circuit_breaker = CircuitBreaker(
            failure_threshold=config.circuit_breaker_threshold,
            recovery_timeout=config.circuit_breaker_timeout
        )
        self.rate_limiter = RateLimiter(
            config.rate_limit_requests,
            config.rate_limit_window
        )
        self._session: Optional[aiohttp.ClientSession] = None

    async def get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            timeout = aiohttp.ClientTimeout(total=self.config.timeout_seconds)
            self._session = aiohttp.ClientSession(
                headers=self.config.headers,
                timeout=timeout
            )
        return self._session

    async def close(self):
        if self._session and not self._session.closed:
            await self._session.close()

    @abstractmethod
    async def health_check(self) -> IntegrationStatus:
        """Check health of the integration."""
        pass

    @abstractmethod
    async def authenticate(self) -> bool:
        """Authenticate with the integration."""
        pass

    async def execute_with_resilience(
        self,
        operation: str,
        func,
        *args,
        **kwargs
    ) -> IntegrationResult:
        """Execute operation with circuit breaker and rate limiting."""
        start_time = time.time()
        trace_id = hashlib.md5(
            f"{operation}-{time.time()}".encode()
        ).hexdigest()[:16]

        try:
            await self.rate_limiter.acquire()
            result = await self.circuit_breaker.call(func, *args, **kwargs)
            latency_ms = (time.time() - start_time) * 1000

            return IntegrationResult(
                success=True,
                data=result,
                latency_ms=latency_ms,
                trace_id=trace_id
            )
        except CircuitOpenError as e:
            return IntegrationResult(
                success=False,
                error=str(e),
                trace_id=trace_id
            )
        except Exception as e:
            latency_ms = (time.time() - start_time) * 1000
            logger.error(f"Integration error [{trace_id}]: {e}")
            return IntegrationResult(
                success=False,
                error=str(e),
                latency_ms=latency_ms,
                trace_id=trace_id
            )
```

### 2.2 Integration Registry

```python
"""
Registry for managing all system integrations.
"""
from typing import Dict, Type
import asyncio

class IntegrationRegistry:
    """Central registry for all integrations."""

    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._integrations: Dict[str, BaseIntegration] = {}
            cls._instance._health_cache: Dict[str, IntegrationStatus] = {}
        return cls._instance

    def register(self, name: str, integration: BaseIntegration):
        """Register an integration."""
        self._integrations[name] = integration
        logger.info(f"Registered integration: {name}")

    def get(self, name: str) -> Optional[BaseIntegration]:
        """Get an integration by name."""
        return self._integrations.get(name)

    def list_all(self) -> List[str]:
        """List all registered integrations."""
        return list(self._integrations.keys())

    async def health_check_all(self) -> Dict[str, IntegrationStatus]:
        """Check health of all integrations."""
        tasks = {
            name: integration.health_check()
            for name, integration in self._integrations.items()
        }
        results = await asyncio.gather(*tasks.values(), return_exceptions=True)

        health_status = {}
        for name, result in zip(tasks.keys(), results):
            if isinstance(result, Exception):
                health_status[name] = IntegrationStatus.UNHEALTHY
            else:
                health_status[name] = result

        self._health_cache = health_status
        return health_status

    async def close_all(self):
        """Close all integration connections."""
        for integration in self._integrations.values():
            await integration.close()

# Global registry instance
integration_registry = IntegrationRegistry()
```

---

## 3. API Integration Patterns

### 3.1 REST API Integration

```python
"""
REST API integration implementation with full feature support.
"""
from urllib.parse import urljoin
from typing import Union

class RESTIntegration(BaseIntegration):
    """REST API integration with comprehensive features."""

    def __init__(
        self,
        config: IntegrationConfig,
        auth_provider: Optional['AuthProvider'] = None
    ):
        super().__init__(config)
        self.auth_provider = auth_provider
        self._token: Optional[str] = None
        self._token_expires: Optional[datetime] = None

    async def authenticate(self) -> bool:
        """Authenticate and obtain access token."""
        if self.auth_provider:
            self._token = await self.auth_provider.get_token()
            return self._token is not None
        return True

    async def health_check(self) -> IntegrationStatus:
        """Check API health."""
        try:
            result = await self.get("/health", timeout=5.0)
            if result.success:
                return IntegrationStatus.HEALTHY
            return IntegrationStatus.DEGRADED
        except Exception:
            return IntegrationStatus.UNHEALTHY

    async def _get_headers(self) -> Dict[str, str]:
        """Get headers including authentication."""
        headers = dict(self.config.headers)

        if self.config.auth_type == "api_key":
            headers["Authorization"] = f"Bearer {self._token}"
        elif self.config.auth_type == "oauth2":
            if not self._token or (
                self._token_expires and
                datetime.now() >= self._token_expires
            ):
                await self.authenticate()
            headers["Authorization"] = f"Bearer {self._token}"

        return headers

    @backoff.on_exception(
        backoff.expo,
        (aiohttp.ClientError, asyncio.TimeoutError),
        max_tries=3
    )
    async def request(
        self,
        method: str,
        endpoint: str,
        data: Optional[Dict] = None,
        params: Optional[Dict] = None,
        timeout: Optional[float] = None
    ) -> IntegrationResult:
        """Make HTTP request with retry logic."""

        async def _do_request():
            session = await self.get_session()
            url = urljoin(self.config.base_url, endpoint)
            headers = await self._get_headers()

            request_timeout = aiohttp.ClientTimeout(
                total=timeout or self.config.timeout_seconds
            )

            async with session.request(
                method,
                url,
                json=data,
                params=params,
                headers=headers,
                timeout=request_timeout
            ) as response:
                response_data = await response.json()

                if response.status >= 400:
                    raise aiohttp.ClientResponseError(
                        request_info=response.request_info,
                        history=response.history,
                        status=response.status,
                        message=str(response_data)
                    )

                return response_data

        return await self.execute_with_resilience(
            f"{method} {endpoint}",
            _do_request
        )

    async def get(
        self,
        endpoint: str,
        params: Optional[Dict] = None,
        **kwargs
    ) -> IntegrationResult:
        return await self.request("GET", endpoint, params=params, **kwargs)

    async def post(
        self,
        endpoint: str,
        data: Dict,
        **kwargs
    ) -> IntegrationResult:
        return await self.request("POST", endpoint, data=data, **kwargs)

    async def put(
        self,
        endpoint: str,
        data: Dict,
        **kwargs
    ) -> IntegrationResult:
        return await self.request("PUT", endpoint, data=data, **kwargs)

    async def delete(
        self,
        endpoint: str,
        **kwargs
    ) -> IntegrationResult:
        return await self.request("DELETE", endpoint, **kwargs)

    async def patch(
        self,
        endpoint: str,
        data: Dict,
        **kwargs
    ) -> IntegrationResult:
        return await self.request("PATCH", endpoint, data=data, **kwargs)


class PaginatedRESTClient(RESTIntegration):
    """REST client with pagination support."""

    async def get_all_pages(
        self,
        endpoint: str,
        page_size: int = 100,
        max_pages: Optional[int] = None,
        page_param: str = "page",
        size_param: str = "limit",
        data_key: str = "data"
    ) -> List[Dict]:
        """Fetch all pages of a paginated endpoint."""
        all_data = []
        page = 1

        while True:
            if max_pages and page > max_pages:
                break

            result = await self.get(
                endpoint,
                params={page_param: page, size_param: page_size}
            )

            if not result.success:
                logger.error(f"Failed to fetch page {page}: {result.error}")
                break

            page_data = result.data.get(data_key, [])
            if not page_data:
                break

            all_data.extend(page_data)

            if len(page_data) < page_size:
                break

            page += 1

        return all_data
```

### 3.2 GraphQL Integration

```python
"""
GraphQL API integration with query building and caching.
"""
from typing import Any

class GraphQLIntegration(BaseIntegration):
    """GraphQL API integration."""

    def __init__(self, config: IntegrationConfig):
        super().__init__(config)
        self._query_cache: Dict[str, str] = {}

    async def authenticate(self) -> bool:
        return True

    async def health_check(self) -> IntegrationStatus:
        try:
            result = await self.query("{ __typename }")
            return IntegrationStatus.HEALTHY if result.success else IntegrationStatus.DEGRADED
        except Exception:
            return IntegrationStatus.UNHEALTHY

    async def query(
        self,
        query: str,
        variables: Optional[Dict[str, Any]] = None,
        operation_name: Optional[str] = None
    ) -> IntegrationResult:
        """Execute a GraphQL query."""

        async def _do_query():
            session = await self.get_session()

            payload = {"query": query}
            if variables:
                payload["variables"] = variables
            if operation_name:
                payload["operationName"] = operation_name

            async with session.post(
                self.config.base_url,
                json=payload,
                headers=self.config.headers
            ) as response:
                data = await response.json()

                if "errors" in data:
                    raise GraphQLError(data["errors"])

                return data.get("data")

        return await self.execute_with_resilience(
            f"GraphQL: {operation_name or 'query'}",
            _do_query
        )

    async def mutation(
        self,
        mutation: str,
        variables: Optional[Dict[str, Any]] = None,
        operation_name: Optional[str] = None
    ) -> IntegrationResult:
        """Execute a GraphQL mutation."""
        return await self.query(mutation, variables, operation_name)

    def build_query(
        self,
        query_name: str,
        fields: List[str],
        arguments: Optional[Dict[str, Any]] = None
    ) -> str:
        """Build a GraphQL query string."""
        args_str = ""
        if arguments:
            args_parts = [f'{k}: {json.dumps(v)}' for k, v in arguments.items()]
            args_str = f"({', '.join(args_parts)})"

        fields_str = "\n    ".join(fields)
        return f"""
query {{
  {query_name}{args_str} {{
    {fields_str}
  }}
}}
"""

class GraphQLError(Exception):
    def __init__(self, errors: List[Dict]):
        self.errors = errors
        messages = [e.get("message", str(e)) for e in errors]
        super().__init__(f"GraphQL errors: {'; '.join(messages)}")
```

### 3.3 gRPC Integration

```python
"""
gRPC integration with connection pooling and load balancing.
"""
import grpc
from grpc import aio
from typing import Callable

@dataclass
class GRPCConfig:
    """gRPC-specific configuration."""
    host: str
    port: int
    use_tls: bool = True
    cert_path: Optional[str] = None
    key_path: Optional[str] = None
    ca_path: Optional[str] = None
    max_message_size: int = 50 * 1024 * 1024  # 50MB
    keepalive_time_ms: int = 30000
    keepalive_timeout_ms: int = 10000

class GRPCIntegration:
    """gRPC integration with connection management."""

    def __init__(self, config: GRPCConfig):
        self.config = config
        self._channel: Optional[aio.Channel] = None
        self._stubs: Dict[str, Any] = {}
        self.circuit_breaker = CircuitBreaker()

    async def connect(self) -> aio.Channel:
        """Establish gRPC connection."""
        if self._channel is not None:
            return self._channel

        target = f"{self.config.host}:{self.config.port}"

        options = [
            ('grpc.max_receive_message_length', self.config.max_message_size),
            ('grpc.max_send_message_length', self.config.max_message_size),
            ('grpc.keepalive_time_ms', self.config.keepalive_time_ms),
            ('grpc.keepalive_timeout_ms', self.config.keepalive_timeout_ms),
        ]

        if self.config.use_tls:
            if self.config.cert_path and self.config.key_path:
                with open(self.config.cert_path, 'rb') as f:
                    cert = f.read()
                with open(self.config.key_path, 'rb') as f:
                    key = f.read()
                with open(self.config.ca_path, 'rb') as f:
                    ca = f.read()

                credentials = grpc.ssl_channel_credentials(
                    root_certificates=ca,
                    private_key=key,
                    certificate_chain=cert
                )
            else:
                credentials = grpc.ssl_channel_credentials()

            self._channel = aio.secure_channel(target, credentials, options)
        else:
            self._channel = aio.insecure_channel(target, options)

        return self._channel

    def register_stub(self, name: str, stub_class: Type):
        """Register a gRPC stub class."""
        async def create_stub():
            channel = await self.connect()
            return stub_class(channel)
        self._stubs[name] = create_stub

    async def get_stub(self, name: str):
        """Get a stub instance."""
        if name not in self._stubs:
            raise ValueError(f"Unknown stub: {name}")
        return await self._stubs[name]()

    async def call(
        self,
        stub_name: str,
        method_name: str,
        request,
        timeout: float = 30.0
    ):
        """Make a gRPC call with circuit breaker."""
        async def _do_call():
            stub = await self.get_stub(stub_name)
            method = getattr(stub, method_name)
            return await method(request, timeout=timeout)

        return await self.circuit_breaker.call(_do_call)

    async def close(self):
        """Close the gRPC channel."""
        if self._channel:
            await self._channel.close()
            self._channel = None
```

---

## 4. Enterprise System Connectivity

### 4.1 Authentication Providers

```python
"""
Authentication providers for enterprise integrations.
"""
from abc import ABC, abstractmethod
import jwt
import base64

class AuthProvider(ABC):
    """Base authentication provider."""

    @abstractmethod
    async def get_token(self) -> str:
        pass

    @abstractmethod
    async def refresh_token(self) -> str:
        pass

    @abstractmethod
    def is_token_valid(self) -> bool:
        pass

class OAuth2Provider(AuthProvider):
    """OAuth2 authentication provider."""

    def __init__(
        self,
        client_id: str,
        client_secret: str,
        token_url: str,
        scopes: List[str],
        grant_type: str = "client_credentials"
    ):
        self.client_id = client_id
        self.client_secret = client_secret
        self.token_url = token_url
        self.scopes = scopes
        self.grant_type = grant_type
        self._access_token: Optional[str] = None
        self._refresh_token: Optional[str] = None
        self._expires_at: Optional[datetime] = None

    async def get_token(self) -> str:
        if self._access_token and self.is_token_valid():
            return self._access_token

        if self._refresh_token:
            return await self.refresh_token()

        return await self._fetch_new_token()

    async def _fetch_new_token(self) -> str:
        async with aiohttp.ClientSession() as session:
            data = {
                "grant_type": self.grant_type,
                "client_id": self.client_id,
                "client_secret": self.client_secret,
                "scope": " ".join(self.scopes)
            }

            async with session.post(self.token_url, data=data) as response:
                result = await response.json()

                self._access_token = result["access_token"]
                self._refresh_token = result.get("refresh_token")
                expires_in = result.get("expires_in", 3600)
                self._expires_at = datetime.now() + timedelta(seconds=expires_in - 60)

                return self._access_token

    async def refresh_token(self) -> str:
        if not self._refresh_token:
            return await self._fetch_new_token()

        async with aiohttp.ClientSession() as session:
            data = {
                "grant_type": "refresh_token",
                "refresh_token": self._refresh_token,
                "client_id": self.client_id,
                "client_secret": self.client_secret
            }

            async with session.post(self.token_url, data=data) as response:
                result = await response.json()
                self._access_token = result["access_token"]
                self._refresh_token = result.get("refresh_token", self._refresh_token)
                expires_in = result.get("expires_in", 3600)
                self._expires_at = datetime.now() + timedelta(seconds=expires_in - 60)

                return self._access_token

    def is_token_valid(self) -> bool:
        if not self._access_token or not self._expires_at:
            return False
        return datetime.now() < self._expires_at


class SAMLProvider(AuthProvider):
    """SAML authentication provider for SSO."""

    def __init__(
        self,
        idp_url: str,
        sp_entity_id: str,
        assertion_consumer_url: str,
        cert_path: str
    ):
        self.idp_url = idp_url
        self.sp_entity_id = sp_entity_id
        self.assertion_consumer_url = assertion_consumer_url
        self.cert_path = cert_path
        self._assertion: Optional[str] = None

    async def get_token(self) -> str:
        # SAML flow typically requires browser redirect
        # This is a simplified service-to-service flow
        return self._assertion or ""

    async def refresh_token(self) -> str:
        return await self.get_token()

    def is_token_valid(self) -> bool:
        return self._assertion is not None

    def create_authn_request(self) -> str:
        """Create SAML AuthnRequest."""
        request_id = f"_{hashlib.md5(str(time.time()).encode()).hexdigest()}"
        issue_instant = datetime.utcnow().strftime("%Y-%m-%dT%H:%M:%SZ")

        return f"""<?xml version="1.0" encoding="UTF-8"?>
<samlp:AuthnRequest
    xmlns:samlp="urn:oasis:names:tc:SAML:2.0:protocol"
    xmlns:saml="urn:oasis:names:tc:SAML:2.0:assertion"
    ID="{request_id}"
    Version="2.0"
    IssueInstant="{issue_instant}"
    Destination="{self.idp_url}"
    AssertionConsumerServiceURL="{self.assertion_consumer_url}">
    <saml:Issuer>{self.sp_entity_id}</saml:Issuer>
</samlp:AuthnRequest>"""


class APIKeyProvider(AuthProvider):
    """Simple API key authentication."""

    def __init__(self, api_key: str, header_name: str = "X-API-Key"):
        self.api_key = api_key
        self.header_name = header_name

    async def get_token(self) -> str:
        return self.api_key

    async def refresh_token(self) -> str:
        return self.api_key

    def is_token_valid(self) -> bool:
        return bool(self.api_key)

    def get_headers(self) -> Dict[str, str]:
        return {self.header_name: self.api_key}
```

### 4.2 LDAP/Active Directory Integration

```python
"""
LDAP and Active Directory integration for user management.
"""
import ldap3
from ldap3 import Server, Connection, ALL, SUBTREE
from ldap3.core.exceptions import LDAPException

@dataclass
class LDAPConfig:
    """LDAP configuration."""
    server: str
    port: int = 389
    use_ssl: bool = True
    base_dn: str = ""
    bind_dn: str = ""
    bind_password: str = ""
    user_search_base: str = ""
    user_search_filter: str = "(sAMAccountName={username})"
    group_search_base: str = ""
    group_search_filter: str = "(member={user_dn})"

class LDAPIntegration:
    """LDAP integration for authentication and user lookup."""

    def __init__(self, config: LDAPConfig):
        self.config = config
        self._connection: Optional[Connection] = None

    def _get_server(self) -> Server:
        return Server(
            self.config.server,
            port=self.config.port,
            use_ssl=self.config.use_ssl,
            get_info=ALL
        )

    def connect(self) -> Connection:
        """Establish LDAP connection."""
        server = self._get_server()
        self._connection = Connection(
            server,
            user=self.config.bind_dn,
            password=self.config.bind_password,
            auto_bind=True
        )
        return self._connection

    def authenticate_user(self, username: str, password: str) -> bool:
        """Authenticate user against LDAP."""
        try:
            user_dn = self._find_user_dn(username)
            if not user_dn:
                return False

            server = self._get_server()
            conn = Connection(server, user=user_dn, password=password)
            return conn.bind()
        except LDAPException as e:
            logger.error(f"LDAP authentication failed: {e}")
            return False

    def _find_user_dn(self, username: str) -> Optional[str]:
        """Find user DN by username."""
        if not self._connection:
            self.connect()

        search_filter = self.config.user_search_filter.format(username=username)

        self._connection.search(
            search_base=self.config.user_search_base or self.config.base_dn,
            search_filter=search_filter,
            search_scope=SUBTREE,
            attributes=['distinguishedName']
        )

        if self._connection.entries:
            return str(self._connection.entries[0].distinguishedName)
        return None

    def get_user_groups(self, username: str) -> List[str]:
        """Get groups for a user."""
        if not self._connection:
            self.connect()

        user_dn = self._find_user_dn(username)
        if not user_dn:
            return []

        search_filter = self.config.group_search_filter.format(user_dn=user_dn)

        self._connection.search(
            search_base=self.config.group_search_base or self.config.base_dn,
            search_filter=search_filter,
            search_scope=SUBTREE,
            attributes=['cn']
        )

        return [str(entry.cn) for entry in self._connection.entries]

    def get_user_attributes(
        self,
        username: str,
        attributes: List[str]
    ) -> Dict[str, Any]:
        """Get user attributes from LDAP."""
        if not self._connection:
            self.connect()

        search_filter = self.config.user_search_filter.format(username=username)

        self._connection.search(
            search_base=self.config.user_search_base or self.config.base_dn,
            search_filter=search_filter,
            search_scope=SUBTREE,
            attributes=attributes
        )

        if not self._connection.entries:
            return {}

        entry = self._connection.entries[0]
        return {attr: str(getattr(entry, attr, "")) for attr in attributes}

    def close(self):
        """Close LDAP connection."""
        if self._connection:
            self._connection.unbind()
            self._connection = None
```

---

## 5. Event-Driven Integration

### 5.1 Message Queue Integration

```python
"""
Message queue integration supporting Kafka, RabbitMQ, and SQS.
"""
from abc import ABC, abstractmethod
import aiokafka
from aiokafka import AIOKafkaProducer, AIOKafkaConsumer
import aio_pika
import aiobotocore

@dataclass
class MessageEnvelope:
    """Standard message envelope for all queues."""
    id: str
    type: str
    source: str
    timestamp: datetime
    payload: Dict[str, Any]
    metadata: Dict[str, str] = field(default_factory=dict)
    correlation_id: Optional[str] = None

    def to_json(self) -> str:
        return json.dumps({
            "id": self.id,
            "type": self.type,
            "source": self.source,
            "timestamp": self.timestamp.isoformat(),
            "payload": self.payload,
            "metadata": self.metadata,
            "correlation_id": self.correlation_id
        })

    @classmethod
    def from_json(cls, data: str) -> 'MessageEnvelope':
        obj = json.loads(data)
        return cls(
            id=obj["id"],
            type=obj["type"],
            source=obj["source"],
            timestamp=datetime.fromisoformat(obj["timestamp"]),
            payload=obj["payload"],
            metadata=obj.get("metadata", {}),
            correlation_id=obj.get("correlation_id")
        )


class MessageQueueIntegration(ABC):
    """Base class for message queue integrations."""

    @abstractmethod
    async def connect(self):
        pass

    @abstractmethod
    async def publish(self, topic: str, message: MessageEnvelope):
        pass

    @abstractmethod
    async def subscribe(
        self,
        topic: str,
        handler: Callable[[MessageEnvelope], None]
    ):
        pass

    @abstractmethod
    async def close(self):
        pass


class KafkaIntegration(MessageQueueIntegration):
    """Apache Kafka integration."""

    def __init__(
        self,
        bootstrap_servers: List[str],
        client_id: str,
        group_id: str,
        security_protocol: str = "SASL_SSL",
        sasl_mechanism: str = "PLAIN",
        sasl_username: Optional[str] = None,
        sasl_password: Optional[str] = None
    ):
        self.bootstrap_servers = bootstrap_servers
        self.client_id = client_id
        self.group_id = group_id
        self.security_protocol = security_protocol
        self.sasl_mechanism = sasl_mechanism
        self.sasl_username = sasl_username
        self.sasl_password = sasl_password
        self._producer: Optional[AIOKafkaProducer] = None
        self._consumers: Dict[str, AIOKafkaConsumer] = {}

    async def connect(self):
        """Initialize Kafka producer."""
        self._producer = AIOKafkaProducer(
            bootstrap_servers=self.bootstrap_servers,
            client_id=self.client_id,
            security_protocol=self.security_protocol,
            sasl_mechanism=self.sasl_mechanism,
            sasl_plain_username=self.sasl_username,
            sasl_plain_password=self.sasl_password,
            value_serializer=lambda v: v.encode('utf-8')
        )
        await self._producer.start()

    async def publish(
        self,
        topic: str,
        message: MessageEnvelope,
        key: Optional[str] = None
    ):
        """Publish message to Kafka topic."""
        if not self._producer:
            await self.connect()

        await self._producer.send_and_wait(
            topic,
            value=message.to_json(),
            key=key.encode('utf-8') if key else None,
            headers=[
                ("type", message.type.encode()),
                ("source", message.source.encode()),
                ("correlation_id", (message.correlation_id or "").encode())
            ]
        )

    async def subscribe(
        self,
        topic: str,
        handler: Callable[[MessageEnvelope], None],
        from_beginning: bool = False
    ):
        """Subscribe to Kafka topic."""
        consumer = AIOKafkaConsumer(
            topic,
            bootstrap_servers=self.bootstrap_servers,
            group_id=self.group_id,
            security_protocol=self.security_protocol,
            sasl_mechanism=self.sasl_mechanism,
            sasl_plain_username=self.sasl_username,
            sasl_plain_password=self.sasl_password,
            auto_offset_reset='earliest' if from_beginning else 'latest',
            enable_auto_commit=True,
            value_deserializer=lambda v: v.decode('utf-8')
        )

        await consumer.start()
        self._consumers[topic] = consumer

        try:
            async for msg in consumer:
                try:
                    envelope = MessageEnvelope.from_json(msg.value)
                    await handler(envelope)
                except Exception as e:
                    logger.error(f"Error processing message: {e}")
        finally:
            await consumer.stop()

    async def close(self):
        """Close all Kafka connections."""
        if self._producer:
            await self._producer.stop()
        for consumer in self._consumers.values():
            await consumer.stop()


class RabbitMQIntegration(MessageQueueIntegration):
    """RabbitMQ integration using aio-pika."""

    def __init__(self, url: str, exchange_name: str = "rag_platform"):
        self.url = url
        self.exchange_name = exchange_name
        self._connection: Optional[aio_pika.Connection] = None
        self._channel: Optional[aio_pika.Channel] = None
        self._exchange: Optional[aio_pika.Exchange] = None

    async def connect(self):
        """Connect to RabbitMQ."""
        self._connection = await aio_pika.connect_robust(self.url)
        self._channel = await self._connection.channel()
        self._exchange = await self._channel.declare_exchange(
            self.exchange_name,
            aio_pika.ExchangeType.TOPIC,
            durable=True
        )

    async def publish(
        self,
        topic: str,
        message: MessageEnvelope,
        persistent: bool = True
    ):
        """Publish message to RabbitMQ."""
        if not self._exchange:
            await self.connect()

        await self._exchange.publish(
            aio_pika.Message(
                body=message.to_json().encode(),
                delivery_mode=(
                    aio_pika.DeliveryMode.PERSISTENT
                    if persistent
                    else aio_pika.DeliveryMode.NOT_PERSISTENT
                ),
                message_id=message.id,
                type=message.type,
                correlation_id=message.correlation_id,
                timestamp=message.timestamp
            ),
            routing_key=topic
        )

    async def subscribe(
        self,
        topic: str,
        handler: Callable[[MessageEnvelope], None],
        queue_name: Optional[str] = None
    ):
        """Subscribe to RabbitMQ topic."""
        if not self._channel:
            await self.connect()

        queue = await self._channel.declare_queue(
            queue_name or f"rag_platform_{topic}",
            durable=True
        )
        await queue.bind(self._exchange, routing_key=topic)

        async with queue.iterator() as queue_iter:
            async for message in queue_iter:
                async with message.process():
                    try:
                        envelope = MessageEnvelope.from_json(
                            message.body.decode()
                        )
                        await handler(envelope)
                    except Exception as e:
                        logger.error(f"Error processing message: {e}")

    async def close(self):
        """Close RabbitMQ connection."""
        if self._connection:
            await self._connection.close()
```

### 5.2 Webhook Integration

```python
"""
Webhook integration for sending and receiving webhooks.
"""
from aiohttp import web
import hmac
from cryptography.hazmat.primitives import hashes
from cryptography.hazmat.backends import default_backend

@dataclass
class WebhookConfig:
    """Webhook configuration."""
    url: str
    secret: str
    events: List[str]
    retry_count: int = 3
    timeout_seconds: float = 30.0
    signature_header: str = "X-Webhook-Signature"

class WebhookSender:
    """Send webhooks with retry and signature."""

    def __init__(self, configs: Dict[str, WebhookConfig]):
        self.configs = configs
        self._session: Optional[aiohttp.ClientSession] = None

    async def get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession()
        return self._session

    def _sign_payload(self, payload: str, secret: str) -> str:
        """Create HMAC signature for payload."""
        signature = hmac.new(
            secret.encode(),
            payload.encode(),
            hashlib.sha256
        ).hexdigest()
        return f"sha256={signature}"

    @backoff.on_exception(
        backoff.expo,
        (aiohttp.ClientError, asyncio.TimeoutError),
        max_tries=3
    )
    async def send(
        self,
        webhook_id: str,
        event_type: str,
        payload: Dict[str, Any]
    ) -> bool:
        """Send webhook to registered endpoint."""
        config = self.configs.get(webhook_id)
        if not config:
            raise ValueError(f"Unknown webhook: {webhook_id}")

        if event_type not in config.events:
            logger.debug(f"Event {event_type} not configured for {webhook_id}")
            return True

        session = await self.get_session()

        envelope = MessageEnvelope(
            id=hashlib.md5(str(time.time()).encode()).hexdigest(),
            type=event_type,
            source="rag_platform",
            timestamp=datetime.utcnow(),
            payload=payload
        )

        body = envelope.to_json()
        signature = self._sign_payload(body, config.secret)

        headers = {
            "Content-Type": "application/json",
            config.signature_header: signature
        }

        timeout = aiohttp.ClientTimeout(total=config.timeout_seconds)

        async with session.post(
            config.url,
            data=body,
            headers=headers,
            timeout=timeout
        ) as response:
            if response.status >= 400:
                logger.error(
                    f"Webhook {webhook_id} failed: {response.status}"
                )
                return False
            return True

    async def broadcast(
        self,
        event_type: str,
        payload: Dict[str, Any]
    ) -> Dict[str, bool]:
        """Broadcast event to all registered webhooks."""
        results = {}
        tasks = []

        for webhook_id, config in self.configs.items():
            if event_type in config.events:
                tasks.append((
                    webhook_id,
                    self.send(webhook_id, event_type, payload)
                ))

        for webhook_id, task in tasks:
            try:
                results[webhook_id] = await task
            except Exception as e:
                logger.error(f"Webhook {webhook_id} error: {e}")
                results[webhook_id] = False

        return results

    async def close(self):
        if self._session:
            await self._session.close()


class WebhookReceiver:
    """Receive and validate incoming webhooks."""

    def __init__(self, secret: str, signature_header: str = "X-Webhook-Signature"):
        self.secret = secret
        self.signature_header = signature_header
        self._handlers: Dict[str, List[Callable]] = {}

    def register_handler(
        self,
        event_type: str,
        handler: Callable[[MessageEnvelope], None]
    ):
        """Register handler for event type."""
        if event_type not in self._handlers:
            self._handlers[event_type] = []
        self._handlers[event_type].append(handler)

    def verify_signature(self, payload: str, signature: str) -> bool:
        """Verify webhook signature."""
        if not signature.startswith("sha256="):
            return False

        expected = hmac.new(
            self.secret.encode(),
            payload.encode(),
            hashlib.sha256
        ).hexdigest()

        return hmac.compare_digest(f"sha256={expected}", signature)

    async def handle_webhook(self, request: web.Request) -> web.Response:
        """Handle incoming webhook request."""
        signature = request.headers.get(self.signature_header, "")
        body = await request.text()

        if not self.verify_signature(body, signature):
            return web.Response(status=401, text="Invalid signature")

        try:
            envelope = MessageEnvelope.from_json(body)
        except Exception as e:
            return web.Response(status=400, text=f"Invalid payload: {e}")

        handlers = self._handlers.get(envelope.type, [])
        for handler in handlers:
            try:
                await handler(envelope)
            except Exception as e:
                logger.error(f"Webhook handler error: {e}")

        return web.Response(status=200, text="OK")

    def create_app(self, path: str = "/webhook") -> web.Application:
        """Create aiohttp application for receiving webhooks."""
        app = web.Application()
        app.router.add_post(path, self.handle_webhook)
        return app
```

---

## 6. Third-Party Service Integration

### 6.1 LLM Provider Integration

```python
"""
Unified LLM provider integration with failover support.
"""
from abc import ABC, abstractmethod

@dataclass
class LLMRequest:
    """Standardized LLM request."""
    messages: List[Dict[str, str]]
    model: str
    temperature: float = 0.7
    max_tokens: int = 1000
    stop_sequences: List[str] = field(default_factory=list)
    metadata: Dict[str, Any] = field(default_factory=dict)

@dataclass
class LLMResponse:
    """Standardized LLM response."""
    content: str
    model: str
    provider: str
    usage: Dict[str, int]
    latency_ms: float
    finish_reason: str

class LLMProvider(ABC):
    """Base class for LLM providers."""

    @abstractmethod
    async def complete(self, request: LLMRequest) -> LLMResponse:
        pass

    @abstractmethod
    async def health_check(self) -> bool:
        pass

class OpenAIProvider(LLMProvider):
    """OpenAI API integration."""

    def __init__(self, api_key: str, organization: Optional[str] = None):
        self.api_key = api_key
        self.organization = organization
        self.base_url = "https://api.openai.com/v1"
        self._session: Optional[aiohttp.ClientSession] = None

    async def get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            if self.organization:
                headers["OpenAI-Organization"] = self.organization
            self._session = aiohttp.ClientSession(headers=headers)
        return self._session

    async def complete(self, request: LLMRequest) -> LLMResponse:
        start_time = time.time()
        session = await self.get_session()

        payload = {
            "model": request.model,
            "messages": request.messages,
            "temperature": request.temperature,
            "max_tokens": request.max_tokens
        }
        if request.stop_sequences:
            payload["stop"] = request.stop_sequences

        async with session.post(
            f"{self.base_url}/chat/completions",
            json=payload
        ) as response:
            data = await response.json()

            if "error" in data:
                raise Exception(data["error"]["message"])

            return LLMResponse(
                content=data["choices"][0]["message"]["content"],
                model=data["model"],
                provider="openai",
                usage={
                    "prompt_tokens": data["usage"]["prompt_tokens"],
                    "completion_tokens": data["usage"]["completion_tokens"],
                    "total_tokens": data["usage"]["total_tokens"]
                },
                latency_ms=(time.time() - start_time) * 1000,
                finish_reason=data["choices"][0]["finish_reason"]
            )

    async def health_check(self) -> bool:
        try:
            session = await self.get_session()
            async with session.get(f"{self.base_url}/models") as response:
                return response.status == 200
        except Exception:
            return False


class AnthropicProvider(LLMProvider):
    """Anthropic Claude API integration."""

    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://api.anthropic.com/v1"
        self._session: Optional[aiohttp.ClientSession] = None

    async def get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession(headers={
                "x-api-key": self.api_key,
                "Content-Type": "application/json",
                "anthropic-version": "2024-01-01"
            })
        return self._session

    async def complete(self, request: LLMRequest) -> LLMResponse:
        start_time = time.time()
        session = await self.get_session()

        # Convert messages format
        system_message = ""
        messages = []
        for msg in request.messages:
            if msg["role"] == "system":
                system_message = msg["content"]
            else:
                messages.append(msg)

        payload = {
            "model": request.model,
            "messages": messages,
            "max_tokens": request.max_tokens,
            "temperature": request.temperature
        }
        if system_message:
            payload["system"] = system_message
        if request.stop_sequences:
            payload["stop_sequences"] = request.stop_sequences

        async with session.post(
            f"{self.base_url}/messages",
            json=payload
        ) as response:
            data = await response.json()

            if "error" in data:
                raise Exception(data["error"]["message"])

            return LLMResponse(
                content=data["content"][0]["text"],
                model=data["model"],
                provider="anthropic",
                usage={
                    "prompt_tokens": data["usage"]["input_tokens"],
                    "completion_tokens": data["usage"]["output_tokens"],
                    "total_tokens": (
                        data["usage"]["input_tokens"] +
                        data["usage"]["output_tokens"]
                    )
                },
                latency_ms=(time.time() - start_time) * 1000,
                finish_reason=data["stop_reason"]
            )

    async def health_check(self) -> bool:
        try:
            # Simple completion test
            request = LLMRequest(
                messages=[{"role": "user", "content": "Hi"}],
                model="claude-3-haiku-20240307",
                max_tokens=10
            )
            await self.complete(request)
            return True
        except Exception:
            return False


class LLMRouter:
    """Route requests across multiple LLM providers with failover."""

    def __init__(self):
        self.providers: Dict[str, LLMProvider] = {}
        self.model_mapping: Dict[str, str] = {}  # model -> provider
        self.fallback_order: List[str] = []
        self._health_status: Dict[str, bool] = {}

    def register_provider(
        self,
        name: str,
        provider: LLMProvider,
        models: List[str]
    ):
        """Register an LLM provider."""
        self.providers[name] = provider
        for model in models:
            self.model_mapping[model] = name
        self._health_status[name] = True

    def set_fallback_order(self, providers: List[str]):
        """Set provider fallback order."""
        self.fallback_order = providers

    async def complete(
        self,
        request: LLMRequest,
        preferred_provider: Optional[str] = None
    ) -> LLMResponse:
        """Complete request with automatic failover."""
        providers_to_try = []

        if preferred_provider and preferred_provider in self.providers:
            providers_to_try.append(preferred_provider)

        if request.model in self.model_mapping:
            provider = self.model_mapping[request.model]
            if provider not in providers_to_try:
                providers_to_try.append(provider)

        for provider in self.fallback_order:
            if provider not in providers_to_try:
                providers_to_try.append(provider)

        last_error = None
        for provider_name in providers_to_try:
            if not self._health_status.get(provider_name, False):
                continue

            provider = self.providers[provider_name]
            try:
                return await provider.complete(request)
            except Exception as e:
                logger.warning(f"Provider {provider_name} failed: {e}")
                last_error = e
                self._health_status[provider_name] = False

        raise Exception(f"All providers failed. Last error: {last_error}")

    async def health_check_all(self) -> Dict[str, bool]:
        """Check health of all providers."""
        for name, provider in self.providers.items():
            self._health_status[name] = await provider.health_check()
        return dict(self._health_status)
```

### 6.2 Vector Store Integration

```python
"""
Vector store integration for embedding storage and retrieval.
"""

@dataclass
class VectorSearchRequest:
    """Vector search request."""
    query_vector: List[float]
    top_k: int = 10
    filter: Optional[Dict[str, Any]] = None
    namespace: Optional[str] = None
    include_metadata: bool = True

@dataclass
class VectorSearchResult:
    """Single vector search result."""
    id: str
    score: float
    vector: Optional[List[float]] = None
    metadata: Dict[str, Any] = field(default_factory=dict)

class VectorStoreIntegration(ABC):
    """Base class for vector store integrations."""

    @abstractmethod
    async def upsert(
        self,
        vectors: List[Dict[str, Any]],
        namespace: Optional[str] = None
    ) -> int:
        pass

    @abstractmethod
    async def search(
        self,
        request: VectorSearchRequest
    ) -> List[VectorSearchResult]:
        pass

    @abstractmethod
    async def delete(
        self,
        ids: List[str],
        namespace: Optional[str] = None
    ) -> int:
        pass

class PineconeIntegration(VectorStoreIntegration):
    """Pinecone vector database integration."""

    def __init__(
        self,
        api_key: str,
        environment: str,
        index_name: str
    ):
        self.api_key = api_key
        self.environment = environment
        self.index_name = index_name
        self.base_url = f"https://{index_name}-{environment}.svc.pinecone.io"
        self._session: Optional[aiohttp.ClientSession] = None

    async def get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            self._session = aiohttp.ClientSession(headers={
                "Api-Key": self.api_key,
                "Content-Type": "application/json"
            })
        return self._session

    async def upsert(
        self,
        vectors: List[Dict[str, Any]],
        namespace: Optional[str] = None
    ) -> int:
        session = await self.get_session()

        payload = {"vectors": vectors}
        if namespace:
            payload["namespace"] = namespace

        async with session.post(
            f"{self.base_url}/vectors/upsert",
            json=payload
        ) as response:
            data = await response.json()
            return data.get("upsertedCount", 0)

    async def search(
        self,
        request: VectorSearchRequest
    ) -> List[VectorSearchResult]:
        session = await self.get_session()

        payload = {
            "vector": request.query_vector,
            "topK": request.top_k,
            "includeMetadata": request.include_metadata
        }
        if request.namespace:
            payload["namespace"] = request.namespace
        if request.filter:
            payload["filter"] = request.filter

        async with session.post(
            f"{self.base_url}/query",
            json=payload
        ) as response:
            data = await response.json()

            return [
                VectorSearchResult(
                    id=match["id"],
                    score=match["score"],
                    metadata=match.get("metadata", {})
                )
                for match in data.get("matches", [])
            ]

    async def delete(
        self,
        ids: List[str],
        namespace: Optional[str] = None
    ) -> int:
        session = await self.get_session()

        payload = {"ids": ids}
        if namespace:
            payload["namespace"] = namespace

        async with session.post(
            f"{self.base_url}/vectors/delete",
            json=payload
        ) as response:
            return len(ids) if response.status == 200 else 0


class WeaviateIntegration(VectorStoreIntegration):
    """Weaviate vector database integration."""

    def __init__(self, url: str, api_key: Optional[str] = None):
        self.url = url.rstrip("/")
        self.api_key = api_key
        self._session: Optional[aiohttp.ClientSession] = None

    async def get_session(self) -> aiohttp.ClientSession:
        if self._session is None or self._session.closed:
            headers = {"Content-Type": "application/json"}
            if self.api_key:
                headers["Authorization"] = f"Bearer {self.api_key}"
            self._session = aiohttp.ClientSession(headers=headers)
        return self._session

    async def upsert(
        self,
        vectors: List[Dict[str, Any]],
        namespace: Optional[str] = None
    ) -> int:
        session = await self.get_session()
        class_name = namespace or "Document"
        count = 0

        for vector_data in vectors:
            payload = {
                "class": class_name,
                "id": vector_data["id"],
                "vector": vector_data["values"],
                "properties": vector_data.get("metadata", {})
            }

            async with session.post(
                f"{self.url}/v1/objects",
                json=payload
            ) as response:
                if response.status in (200, 201):
                    count += 1

        return count

    async def search(
        self,
        request: VectorSearchRequest
    ) -> List[VectorSearchResult]:
        session = await self.get_session()
        class_name = request.namespace or "Document"

        query = {
            "query": f"""
            {{
                Get {{
                    {class_name}(
                        nearVector: {{
                            vector: {request.query_vector}
                        }}
                        limit: {request.top_k}
                    ) {{
                        _additional {{
                            id
                            distance
                        }}
                    }}
                }}
            }}
            """
        }

        async with session.post(
            f"{self.url}/v1/graphql",
            json=query
        ) as response:
            data = await response.json()
            results = data.get("data", {}).get("Get", {}).get(class_name, [])

            return [
                VectorSearchResult(
                    id=r["_additional"]["id"],
                    score=1 - r["_additional"]["distance"],
                    metadata=r
                )
                for r in results
            ]

    async def delete(
        self,
        ids: List[str],
        namespace: Optional[str] = None
    ) -> int:
        session = await self.get_session()
        count = 0

        for id in ids:
            async with session.delete(
                f"{self.url}/v1/objects/{id}"
            ) as response:
                if response.status == 204:
                    count += 1

        return count
```

---

## 7. Integration Testing

### 7.1 Integration Test Framework

```python
"""
Integration testing framework for system integrations.
"""
import pytest
from unittest.mock import AsyncMock, patch
from typing import Callable

@dataclass
class IntegrationTestCase:
    """Definition of an integration test case."""
    name: str
    integration_name: str
    setup: Optional[Callable] = None
    teardown: Optional[Callable] = None
    timeout_seconds: float = 30.0
    retry_count: int = 1

class IntegrationTestRunner:
    """Runner for integration tests."""

    def __init__(self, registry: IntegrationRegistry):
        self.registry = registry
        self.results: List[Dict[str, Any]] = []

    async def run_test(
        self,
        test_case: IntegrationTestCase,
        test_func: Callable
    ) -> Dict[str, Any]:
        """Run a single integration test."""
        result = {
            "name": test_case.name,
            "integration": test_case.integration_name,
            "success": False,
            "error": None,
            "duration_ms": 0
        }

        integration = self.registry.get(test_case.integration_name)
        if not integration:
            result["error"] = f"Integration not found: {test_case.integration_name}"
            return result

        start_time = time.time()

        try:
            if test_case.setup:
                await test_case.setup()

            for attempt in range(test_case.retry_count):
                try:
                    await asyncio.wait_for(
                        test_func(integration),
                        timeout=test_case.timeout_seconds
                    )
                    result["success"] = True
                    break
                except asyncio.TimeoutError:
                    result["error"] = "Test timed out"
                except Exception as e:
                    result["error"] = str(e)
                    if attempt < test_case.retry_count - 1:
                        await asyncio.sleep(1)
        finally:
            if test_case.teardown:
                await test_case.teardown()

        result["duration_ms"] = (time.time() - start_time) * 1000
        self.results.append(result)
        return result

    async def run_health_checks(self) -> Dict[str, Any]:
        """Run health checks on all integrations."""
        health_status = await self.registry.health_check_all()

        return {
            "timestamp": datetime.utcnow().isoformat(),
            "total": len(health_status),
            "healthy": sum(1 for s in health_status.values() if s == IntegrationStatus.HEALTHY),
            "degraded": sum(1 for s in health_status.values() if s == IntegrationStatus.DEGRADED),
            "unhealthy": sum(1 for s in health_status.values() if s == IntegrationStatus.UNHEALTHY),
            "details": {k: v.value for k, v in health_status.items()}
        }

    def generate_report(self) -> Dict[str, Any]:
        """Generate test report."""
        passed = sum(1 for r in self.results if r["success"])
        failed = len(self.results) - passed

        return {
            "timestamp": datetime.utcnow().isoformat(),
            "summary": {
                "total": len(self.results),
                "passed": passed,
                "failed": failed,
                "pass_rate": passed / len(self.results) if self.results else 0
            },
            "results": self.results
        }


class MockIntegration(BaseIntegration):
    """Mock integration for testing."""

    def __init__(self, config: IntegrationConfig):
        super().__init__(config)
        self.call_history: List[Dict] = []
        self.mock_responses: Dict[str, Any] = {}

    async def health_check(self) -> IntegrationStatus:
        return IntegrationStatus.HEALTHY

    async def authenticate(self) -> bool:
        return True

    def set_mock_response(self, operation: str, response: Any):
        """Set mock response for an operation."""
        self.mock_responses[operation] = response

    async def mock_call(self, operation: str, **kwargs) -> Any:
        """Make a mock call."""
        self.call_history.append({
            "operation": operation,
            "kwargs": kwargs,
            "timestamp": datetime.utcnow().isoformat()
        })

        if operation in self.mock_responses:
            response = self.mock_responses[operation]
            if callable(response):
                return response(**kwargs)
            return response

        return None


# Pytest fixtures for integration testing
@pytest.fixture
async def integration_registry():
    """Create test integration registry."""
    registry = IntegrationRegistry()
    yield registry
    await registry.close_all()


@pytest.fixture
def mock_rest_integration():
    """Create mock REST integration."""
    config = IntegrationConfig(
        name="test_api",
        integration_type=IntegrationType.REST_API,
        base_url="http://test.example.com",
        auth_type="api_key"
    )
    return MockIntegration(config)
```

### 7.2 Contract Testing

```python
"""
Contract testing for API integrations using Pact.
"""
from dataclasses import dataclass
from typing import List, Dict, Any

@dataclass
class ContractInteraction:
    """Definition of a contract interaction."""
    description: str
    provider_state: str
    request: Dict[str, Any]
    response: Dict[str, Any]

class ContractTest:
    """Contract test definition."""

    def __init__(
        self,
        consumer: str,
        provider: str,
        interactions: List[ContractInteraction]
    ):
        self.consumer = consumer
        self.provider = provider
        self.interactions = interactions

    def to_pact_format(self) -> Dict[str, Any]:
        """Convert to Pact contract format."""
        return {
            "consumer": {"name": self.consumer},
            "provider": {"name": self.provider},
            "interactions": [
                {
                    "description": i.description,
                    "providerState": i.provider_state,
                    "request": i.request,
                    "response": i.response
                }
                for i in self.interactions
            ],
            "metadata": {
                "pactSpecification": {"version": "2.0.0"}
            }
        }


class ContractVerifier:
    """Verify contracts against provider implementation."""

    def __init__(self, provider_url: str):
        self.provider_url = provider_url
        self._session: Optional[aiohttp.ClientSession] = None

    async def verify_contract(
        self,
        contract: ContractTest
    ) -> Dict[str, Any]:
        """Verify all interactions in a contract."""
        results = []

        for interaction in contract.interactions:
            result = await self._verify_interaction(interaction)
            results.append(result)

        passed = sum(1 for r in results if r["success"])

        return {
            "consumer": contract.consumer,
            "provider": contract.provider,
            "total": len(results),
            "passed": passed,
            "failed": len(results) - passed,
            "interactions": results
        }

    async def _verify_interaction(
        self,
        interaction: ContractInteraction
    ) -> Dict[str, Any]:
        """Verify a single interaction."""
        if self._session is None:
            self._session = aiohttp.ClientSession()

        result = {
            "description": interaction.description,
            "success": False,
            "errors": []
        }

        try:
            request = interaction.request
            method = request.get("method", "GET")
            path = request.get("path", "/")
            headers = request.get("headers", {})
            body = request.get("body")

            url = f"{self.provider_url}{path}"

            async with self._session.request(
                method,
                url,
                headers=headers,
                json=body
            ) as response:
                expected = interaction.response

                # Verify status
                if response.status != expected.get("status"):
                    result["errors"].append(
                        f"Status mismatch: expected {expected.get('status')}, "
                        f"got {response.status}"
                    )

                # Verify headers
                for header, value in expected.get("headers", {}).items():
                    actual = response.headers.get(header)
                    if actual != value:
                        result["errors"].append(
                            f"Header {header} mismatch: expected {value}, "
                            f"got {actual}"
                        )

                # Verify body (simplified matching)
                if "body" in expected:
                    actual_body = await response.json()
                    if not self._match_body(expected["body"], actual_body):
                        result["errors"].append("Body mismatch")

                result["success"] = len(result["errors"]) == 0

        except Exception as e:
            result["errors"].append(str(e))

        return result

    def _match_body(self, expected: Any, actual: Any) -> bool:
        """Match expected body against actual (simplified)."""
        if isinstance(expected, dict):
            if not isinstance(actual, dict):
                return False
            for key, value in expected.items():
                if key not in actual:
                    return False
                if not self._match_body(value, actual[key]):
                    return False
            return True
        elif isinstance(expected, list):
            if not isinstance(actual, list):
                return False
            if len(expected) != len(actual):
                return False
            return all(
                self._match_body(e, a)
                for e, a in zip(expected, actual)
            )
        else:
            return expected == actual
```

---

## 8. Monitoring and Operations

### 8.1 Integration Monitoring

```python
"""
Monitoring and observability for integrations.
"""
from prometheus_client import Counter, Histogram, Gauge
import structlog

# Prometheus metrics
INTEGRATION_REQUESTS = Counter(
    'integration_requests_total',
    'Total integration requests',
    ['integration', 'operation', 'status']
)

INTEGRATION_LATENCY = Histogram(
    'integration_latency_seconds',
    'Integration request latency',
    ['integration', 'operation'],
    buckets=[0.01, 0.05, 0.1, 0.25, 0.5, 1.0, 2.5, 5.0, 10.0]
)

INTEGRATION_HEALTH = Gauge(
    'integration_health',
    'Integration health status (1=healthy, 0=unhealthy)',
    ['integration']
)

CIRCUIT_BREAKER_STATE = Gauge(
    'circuit_breaker_state',
    'Circuit breaker state (0=closed, 1=open, 2=half_open)',
    ['integration']
)

class IntegrationMonitor:
    """Monitor integration health and performance."""

    def __init__(self, registry: IntegrationRegistry):
        self.registry = registry
        self.logger = structlog.get_logger()
        self._alerts: List[Dict] = []

    def record_request(
        self,
        integration: str,
        operation: str,
        status: str,
        latency_seconds: float
    ):
        """Record an integration request."""
        INTEGRATION_REQUESTS.labels(
            integration=integration,
            operation=operation,
            status=status
        ).inc()

        INTEGRATION_LATENCY.labels(
            integration=integration,
            operation=operation
        ).observe(latency_seconds)

        self.logger.info(
            "integration_request",
            integration=integration,
            operation=operation,
            status=status,
            latency_seconds=latency_seconds
        )

    async def update_health_metrics(self):
        """Update health metrics for all integrations."""
        health_status = await self.registry.health_check_all()

        for name, status in health_status.items():
            health_value = 1 if status == IntegrationStatus.HEALTHY else 0
            INTEGRATION_HEALTH.labels(integration=name).set(health_value)

            integration = self.registry.get(name)
            if integration:
                cb_state = {"closed": 0, "open": 1, "half_open": 2}
                CIRCUIT_BREAKER_STATE.labels(integration=name).set(
                    cb_state.get(integration.circuit_breaker.state, 0)
                )

            if status != IntegrationStatus.HEALTHY:
                self._create_alert(name, status)

    def _create_alert(self, integration: str, status: IntegrationStatus):
        """Create an alert for unhealthy integration."""
        alert = {
            "integration": integration,
            "status": status.value,
            "timestamp": datetime.utcnow().isoformat(),
            "severity": "critical" if status == IntegrationStatus.UNHEALTHY else "warning"
        }
        self._alerts.append(alert)

        self.logger.warning(
            "integration_unhealthy",
            **alert
        )

    def get_dashboard_data(self) -> Dict[str, Any]:
        """Get data for monitoring dashboard."""
        integrations = []

        for name in self.registry.list_all():
            integration = self.registry.get(name)
            integrations.append({
                "name": name,
                "type": integration.config.integration_type.value,
                "circuit_breaker_state": integration.circuit_breaker.state,
                "circuit_breaker_failures": integration.circuit_breaker.failures
            })

        return {
            "timestamp": datetime.utcnow().isoformat(),
            "integrations": integrations,
            "recent_alerts": self._alerts[-10:]
        }


class IntegrationDashboard:
    """Dashboard for integration monitoring."""

    def __init__(self, monitor: IntegrationMonitor):
        self.monitor = monitor

    def create_app(self) -> web.Application:
        """Create dashboard web application."""
        app = web.Application()
        app.router.add_get("/health", self._health_handler)
        app.router.add_get("/metrics", self._metrics_handler)
        app.router.add_get("/dashboard", self._dashboard_handler)
        return app

    async def _health_handler(self, request: web.Request) -> web.Response:
        await self.monitor.update_health_metrics()
        health = await self.monitor.registry.health_check_all()

        all_healthy = all(
            s == IntegrationStatus.HEALTHY
            for s in health.values()
        )

        return web.json_response(
            {"status": "healthy" if all_healthy else "degraded", "integrations": {k: v.value for k, v in health.items()}},
            status=200 if all_healthy else 503
        )

    async def _metrics_handler(self, request: web.Request) -> web.Response:
        from prometheus_client import generate_latest
        return web.Response(
            body=generate_latest(),
            content_type="text/plain"
        )

    async def _dashboard_handler(self, request: web.Request) -> web.Response:
        data = self.monitor.get_dashboard_data()
        return web.json_response(data)
```

### 8.2 Distributed Tracing

```python
"""
Distributed tracing for integration calls.
"""
from opentelemetry import trace
from opentelemetry.trace import SpanKind
from opentelemetry.sdk.trace import TracerProvider
from opentelemetry.sdk.trace.export import BatchSpanProcessor
from opentelemetry.exporter.otlp.proto.grpc.trace_exporter import OTLPSpanExporter

class TracingMiddleware:
    """Middleware for tracing integration calls."""

    def __init__(self, service_name: str, otlp_endpoint: str):
        provider = TracerProvider()
        processor = BatchSpanProcessor(
            OTLPSpanExporter(endpoint=otlp_endpoint)
        )
        provider.add_span_processor(processor)
        trace.set_tracer_provider(provider)
        self.tracer = trace.get_tracer(service_name)

    def trace_integration_call(
        self,
        integration_name: str,
        operation: str
    ):
        """Decorator for tracing integration calls."""
        def decorator(func):
            @wraps(func)
            async def wrapper(*args, **kwargs):
                with self.tracer.start_as_current_span(
                    f"{integration_name}.{operation}",
                    kind=SpanKind.CLIENT
                ) as span:
                    span.set_attribute("integration.name", integration_name)
                    span.set_attribute("integration.operation", operation)

                    try:
                        result = await func(*args, **kwargs)
                        span.set_attribute("integration.success", True)
                        return result
                    except Exception as e:
                        span.set_attribute("integration.success", False)
                        span.set_attribute("integration.error", str(e))
                        span.record_exception(e)
                        raise
            return wrapper
        return decorator
```

---

## Appendix A: Quick Reference

### Integration Checklist

```markdown
## New Integration Checklist

### Planning
- [ ] Define integration type (REST, GraphQL, gRPC, Event)
- [ ] Document API contracts and schemas
- [ ] Identify authentication requirements
- [ ] Plan error handling strategy
- [ ] Define SLAs and timeouts

### Implementation
- [ ] Implement base integration class
- [ ] Add circuit breaker
- [ ] Add rate limiting
- [ ] Implement retry logic
- [ ] Add authentication provider
- [ ] Register with IntegrationRegistry

### Testing
- [ ] Write unit tests with mocks
- [ ] Write integration tests
- [ ] Create contract tests
- [ ] Test failure scenarios
- [ ] Test timeout handling

### Monitoring
- [ ] Add Prometheus metrics
- [ ] Configure alerting
- [ ] Add distributed tracing
- [ ] Create dashboard panel
- [ ] Document runbooks

### Documentation
- [ ] API documentation
- [ ] Configuration guide
- [ ] Troubleshooting guide
- [ ] Example code
```

### Common Patterns

| Pattern | Use Case | Implementation |
|---------|----------|----------------|
| Circuit Breaker | Prevent cascade failures | `CircuitBreaker` class |
| Rate Limiting | Respect API limits | `RateLimiter` class |
| Retry with Backoff | Handle transient failures | `@backoff.on_exception` |
| Request Signing | Webhook security | HMAC-SHA256 |
| Token Refresh | OAuth2 auth | `OAuth2Provider` |
| Connection Pooling | gRPC performance | `GRPCIntegration` |

---

## Document Control

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2024-01-15 | Platform Team | Initial release |

---

> **Navigation**
> [← 15.2 Data Migration](15.2_data_migration_guide.md) | **[Index](../README.md#15-repository-structure)** | [README →](../README.md)
