> **Navigation** | [← 7.6 Advanced RAG](../07_rag_pipeline/7.6_advanced_rag_patterns_guide.md) | [8.2 Experiment Tracking →](8.2_experiment_tracking_guide.md)
>
> | | |
> |---|---|
> | **Prerequisites** | MLOps fundamentals &#124; Version control |
> | **Related** | [8.2 Experiment Tracking](8.2_experiment_tracking_guide.md) &#124; [8.3 Model Versioning](8.3_model_versioning_artifacts_guide.md) &#124; [8.5 CI/CD](8.5_llm_cicd_pipeline_guide.md) |
> | **Next** | [8.2 Experiment Tracking](8.2_experiment_tracking_guide.md) |

# 8.1 Model Registry Guide

## Document Purpose

This guide provides comprehensive guidance for implementing and operating model registries to manage the full lifecycle of ML models, from development through production deployment, with focus on LLM-specific requirements.

## Prerequisites

- Understanding of ML model development workflows
- Familiarity with version control concepts
- Basic knowledge of MLOps principles
- Experience with model deployment

## Target Audience

- MLOps Engineers managing model lifecycles
- ML Engineers developing and deploying models
- Platform Teams building ML infrastructure

---

## 1. Model Registry Fundamentals

### 1.1 Registry Core Concepts

```python
"""
Core model registry concepts and data structures
"""
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional
from enum import Enum
from datetime import datetime
import hashlib


class ModelStage(Enum):
    """Model lifecycle stages"""
    NONE = "none"              # Just registered
    DEVELOPMENT = "development" # Active development
    STAGING = "staging"         # Integration testing
    PRODUCTION = "production"   # Live serving
    ARCHIVED = "archived"       # Retired


class ModelType(Enum):
    """Types of models in registry"""
    BASE_MODEL = "base_model"          # Foundation/pre-trained model
    FINE_TUNED = "fine_tuned"          # Fine-tuned variant
    ADAPTER = "adapter"                 # LoRA/PEFT adapter
    QUANTIZED = "quantized"            # Quantized version
    DISTILLED = "distilled"            # Distilled model
    MERGED = "merged"                  # Merged model


@dataclass
class ModelArtifact:
    """Individual model artifact"""
    artifact_type: str          # weights, config, tokenizer, adapter
    path: str                   # Storage path (S3, GCS, local)
    size_bytes: int
    checksum: str               # SHA256 hash
    format: str                 # safetensors, pytorch, gguf
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ModelMetrics:
    """Model evaluation metrics"""
    benchmark_name: str
    metric_name: str
    value: float
    evaluation_date: datetime
    configuration: Dict[str, Any] = field(default_factory=dict)


@dataclass
class ModelVersion:
    """Complete model version record"""
    model_name: str
    version: int
    model_type: ModelType
    stage: ModelStage

    # Source tracking
    source_experiment_id: Optional[str] = None
    source_run_id: Optional[str] = None
    parent_model: Optional[str] = None  # For fine-tuned models

    # Artifacts
    artifacts: List[ModelArtifact] = field(default_factory=list)

    # Metadata
    description: str = ""
    tags: Dict[str, str] = field(default_factory=dict)
    parameters: Dict[str, Any] = field(default_factory=dict)

    # Training info
    training_data_version: Optional[str] = None
    training_config: Dict[str, Any] = field(default_factory=dict)

    # Evaluation
    metrics: List[ModelMetrics] = field(default_factory=list)

    # Timestamps
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)
    registered_by: str = ""

    # Aliases
    aliases: List[str] = field(default_factory=list)


@dataclass
class RegisteredModel:
    """Top-level model registration"""
    name: str
    description: str
    model_type: ModelType
    versions: List[ModelVersion] = field(default_factory=list)
    latest_version: int = 0
    tags: Dict[str, str] = field(default_factory=dict)
    created_at: datetime = field(default_factory=datetime.now)
    updated_at: datetime = field(default_factory=datetime.now)


class ModelRegistry:
    """
    Abstract model registry interface.
    Concrete implementations: MLflow, W&B, Custom
    """

    def register_model(
        self,
        name: str,
        description: str,
        model_type: ModelType
    ) -> RegisteredModel:
        """Register a new model in the registry"""
        raise NotImplementedError

    def create_version(
        self,
        model_name: str,
        artifacts: List[ModelArtifact],
        metrics: Optional[List[ModelMetrics]] = None,
        **kwargs
    ) -> ModelVersion:
        """Create a new version of an existing model"""
        raise NotImplementedError

    def get_model(self, name: str) -> RegisteredModel:
        """Get registered model by name"""
        raise NotImplementedError

    def get_version(
        self,
        model_name: str,
        version: int
    ) -> ModelVersion:
        """Get specific model version"""
        raise NotImplementedError

    def get_latest_version(
        self,
        model_name: str,
        stage: Optional[ModelStage] = None
    ) -> ModelVersion:
        """Get latest version, optionally filtered by stage"""
        raise NotImplementedError

    def transition_stage(
        self,
        model_name: str,
        version: int,
        stage: ModelStage,
        archive_existing: bool = True
    ):
        """Transition model version to new stage"""
        raise NotImplementedError

    def set_alias(
        self,
        model_name: str,
        version: int,
        alias: str
    ):
        """Set mutable alias pointing to version"""
        raise NotImplementedError

    def list_models(
        self,
        filter_tags: Optional[Dict[str, str]] = None
    ) -> List[RegisteredModel]:
        """List all registered models"""
        raise NotImplementedError

    def delete_version(
        self,
        model_name: str,
        version: int
    ):
        """Delete a model version (soft delete)"""
        raise NotImplementedError
```

### 1.2 Artifact Management

```python
"""
Model artifact storage and management
"""
from typing import List, Dict, Any, Optional, BinaryIO
from dataclasses import dataclass
import hashlib
import os
from pathlib import Path
from abc import ABC, abstractmethod


class ArtifactStore(ABC):
    """Abstract artifact storage backend"""

    @abstractmethod
    def upload(
        self,
        local_path: str,
        artifact_path: str
    ) -> str:
        """Upload artifact and return storage URI"""
        pass

    @abstractmethod
    def download(
        self,
        artifact_path: str,
        local_path: str
    ):
        """Download artifact to local path"""
        pass

    @abstractmethod
    def exists(self, artifact_path: str) -> bool:
        """Check if artifact exists"""
        pass

    @abstractmethod
    def delete(self, artifact_path: str):
        """Delete artifact"""
        pass


class S3ArtifactStore(ArtifactStore):
    """S3-based artifact storage"""

    def __init__(
        self,
        bucket: str,
        prefix: str = "models",
        region: str = "us-east-1"
    ):
        import boto3
        self.bucket = bucket
        self.prefix = prefix
        self.s3 = boto3.client('s3', region_name=region)

    def upload(
        self,
        local_path: str,
        artifact_path: str
    ) -> str:
        """Upload to S3"""
        full_path = f"{self.prefix}/{artifact_path}"

        # Upload with multipart for large files
        self.s3.upload_file(
            local_path,
            self.bucket,
            full_path,
            Config=boto3.s3.transfer.TransferConfig(
                multipart_threshold=100 * 1024 * 1024,  # 100MB
                multipart_chunksize=100 * 1024 * 1024
            )
        )

        return f"s3://{self.bucket}/{full_path}"

    def download(
        self,
        artifact_path: str,
        local_path: str
    ):
        """Download from S3"""
        full_path = f"{self.prefix}/{artifact_path}"
        os.makedirs(os.path.dirname(local_path), exist_ok=True)
        self.s3.download_file(self.bucket, full_path, local_path)

    def exists(self, artifact_path: str) -> bool:
        """Check existence in S3"""
        full_path = f"{self.prefix}/{artifact_path}"
        try:
            self.s3.head_object(Bucket=self.bucket, Key=full_path)
            return True
        except:
            return False

    def delete(self, artifact_path: str):
        """Delete from S3"""
        full_path = f"{self.prefix}/{artifact_path}"
        self.s3.delete_object(Bucket=self.bucket, Key=full_path)


class HuggingFaceHubStore(ArtifactStore):
    """HuggingFace Hub artifact storage for LLMs"""

    def __init__(
        self,
        organization: str,
        token: Optional[str] = None
    ):
        from huggingface_hub import HfApi
        self.org = organization
        self.api = HfApi(token=token)

    def upload(
        self,
        local_path: str,
        artifact_path: str
    ) -> str:
        """Upload to HuggingFace Hub"""
        # Parse artifact path: repo_name/file_path
        parts = artifact_path.split("/", 1)
        repo_name = f"{self.org}/{parts[0]}"
        file_path = parts[1] if len(parts) > 1 else os.path.basename(local_path)

        # Create repo if doesn't exist
        try:
            self.api.create_repo(repo_name, exist_ok=True)
        except:
            pass

        # Upload
        self.api.upload_file(
            path_or_fileobj=local_path,
            path_in_repo=file_path,
            repo_id=repo_name,
            commit_message=f"Upload {file_path}"
        )

        return f"https://huggingface.co/{repo_name}/blob/main/{file_path}"

    def download(
        self,
        artifact_path: str,
        local_path: str
    ):
        """Download from HuggingFace Hub"""
        from huggingface_hub import hf_hub_download

        parts = artifact_path.split("/", 1)
        repo_name = f"{self.org}/{parts[0]}"
        file_path = parts[1] if len(parts) > 1 else artifact_path

        downloaded = hf_hub_download(
            repo_id=repo_name,
            filename=file_path,
            local_dir=os.path.dirname(local_path)
        )

        if downloaded != local_path:
            os.rename(downloaded, local_path)

    def exists(self, artifact_path: str) -> bool:
        """Check existence on Hub"""
        parts = artifact_path.split("/", 1)
        repo_name = f"{self.org}/{parts[0]}"
        file_path = parts[1] if len(parts) > 1 else artifact_path

        try:
            self.api.file_info(repo_id=repo_name, path=file_path)
            return True
        except:
            return False

    def delete(self, artifact_path: str):
        """Delete from Hub"""
        parts = artifact_path.split("/", 1)
        repo_name = f"{self.org}/{parts[0]}"
        file_path = parts[1] if len(parts) > 1 else artifact_path

        self.api.delete_file(
            path_in_repo=file_path,
            repo_id=repo_name,
            commit_message=f"Delete {file_path}"
        )


class ModelArtifactManager:
    """Manage model artifacts with integrity verification"""

    def __init__(
        self,
        store: ArtifactStore,
        verify_checksums: bool = True
    ):
        self.store = store
        self.verify_checksums = verify_checksums

    def upload_model(
        self,
        model_name: str,
        version: int,
        local_dir: str
    ) -> List[ModelArtifact]:
        """Upload all model files from directory"""
        artifacts = []
        local_path = Path(local_dir)

        # Define expected LLM artifact files
        artifact_patterns = [
            ("*.safetensors", "weights", "safetensors"),
            ("*.bin", "weights", "pytorch"),
            ("*.gguf", "weights", "gguf"),
            ("config.json", "config", "json"),
            ("tokenizer*.json", "tokenizer", "json"),
            ("tokenizer.model", "tokenizer", "sentencepiece"),
            ("adapter_*.safetensors", "adapter", "safetensors"),
            ("adapter_config.json", "adapter_config", "json"),
        ]

        for pattern, artifact_type, format_type in artifact_patterns:
            for file_path in local_path.glob(pattern):
                artifact = self._upload_file(
                    file_path=file_path,
                    model_name=model_name,
                    version=version,
                    artifact_type=artifact_type,
                    format_type=format_type
                )
                artifacts.append(artifact)

        return artifacts

    def _upload_file(
        self,
        file_path: Path,
        model_name: str,
        version: int,
        artifact_type: str,
        format_type: str
    ) -> ModelArtifact:
        """Upload single file and create artifact record"""
        # Calculate checksum
        checksum = self._calculate_checksum(file_path)

        # Determine storage path
        artifact_path = f"{model_name}/v{version}/{file_path.name}"

        # Upload
        storage_uri = self.store.upload(str(file_path), artifact_path)

        return ModelArtifact(
            artifact_type=artifact_type,
            path=storage_uri,
            size_bytes=file_path.stat().st_size,
            checksum=checksum,
            format=format_type
        )

    def download_model(
        self,
        model_name: str,
        version: int,
        artifacts: List[ModelArtifact],
        local_dir: str
    ):
        """Download model artifacts to local directory"""
        os.makedirs(local_dir, exist_ok=True)

        for artifact in artifacts:
            # Extract filename from path
            filename = Path(artifact.path).name
            local_path = os.path.join(local_dir, filename)

            # Download
            self.store.download(artifact.path, local_path)

            # Verify checksum
            if self.verify_checksums:
                actual_checksum = self._calculate_checksum(Path(local_path))
                if actual_checksum != artifact.checksum:
                    raise ValueError(
                        f"Checksum mismatch for {filename}: "
                        f"expected {artifact.checksum}, got {actual_checksum}"
                    )

    def _calculate_checksum(self, file_path: Path) -> str:
        """Calculate SHA256 checksum of file"""
        sha256 = hashlib.sha256()
        with open(file_path, 'rb') as f:
            for chunk in iter(lambda: f.read(8192), b''):
                sha256.update(chunk)
        return sha256.hexdigest()
```

---

## 2. MLflow Model Registry Implementation

### 2.1 MLflow Setup and Configuration

```python
"""
MLflow Model Registry implementation
"""
import mlflow
from mlflow.tracking import MlflowClient
from mlflow.models import Model
from mlflow.pyfunc import PythonModel
from typing import List, Dict, Any, Optional
from dataclasses import asdict
import os


class MLflowRegistryConfig:
    """Configuration for MLflow Model Registry"""

    def __init__(
        self,
        tracking_uri: str = "http://localhost:5000",
        artifact_root: str = "s3://mlflow-artifacts",
        registry_uri: Optional[str] = None
    ):
        self.tracking_uri = tracking_uri
        self.artifact_root = artifact_root
        self.registry_uri = registry_uri or tracking_uri

    def configure(self):
        """Apply configuration"""
        mlflow.set_tracking_uri(self.tracking_uri)
        mlflow.set_registry_uri(self.registry_uri)


class MLflowModelRegistry(ModelRegistry):
    """
    MLflow-based model registry implementation
    """

    def __init__(self, config: MLflowRegistryConfig):
        self.config = config
        config.configure()
        self.client = MlflowClient()

    def register_model(
        self,
        name: str,
        description: str,
        model_type: ModelType
    ) -> RegisteredModel:
        """Register new model in MLflow"""

        # Create or get registered model
        try:
            rm = self.client.create_registered_model(
                name=name,
                tags={"model_type": model_type.value},
                description=description
            )
        except mlflow.exceptions.MlflowException:
            # Already exists
            rm = self.client.get_registered_model(name)
            self.client.update_registered_model(
                name=name,
                description=description
            )

        return RegisteredModel(
            name=rm.name,
            description=rm.description or "",
            model_type=model_type,
            tags=rm.tags or {}
        )

    def create_version(
        self,
        model_name: str,
        artifacts: List[ModelArtifact],
        metrics: Optional[List[ModelMetrics]] = None,
        **kwargs
    ) -> ModelVersion:
        """Create new model version from artifacts"""

        # Start MLflow run to log artifacts
        with mlflow.start_run() as run:
            # Log artifacts
            for artifact in artifacts:
                if artifact.artifact_type == "weights":
                    mlflow.log_artifact(artifact.path, "model")
                else:
                    mlflow.log_artifact(artifact.path)

            # Log metrics
            if metrics:
                for metric in metrics:
                    mlflow.log_metric(
                        f"{metric.benchmark_name}_{metric.metric_name}",
                        metric.value
                    )

            # Log parameters
            if "parameters" in kwargs:
                mlflow.log_params(kwargs["parameters"])

            # Log tags
            if "tags" in kwargs:
                for key, value in kwargs["tags"].items():
                    mlflow.set_tag(key, value)

            # Register model version
            model_uri = f"runs:/{run.info.run_id}/model"
            mv = mlflow.register_model(model_uri, model_name)

        # Add description if provided
        if "description" in kwargs:
            self.client.update_model_version(
                name=model_name,
                version=mv.version,
                description=kwargs["description"]
            )

        return self._convert_mlflow_version(mv)

    def get_model(self, name: str) -> RegisteredModel:
        """Get registered model by name"""
        rm = self.client.get_registered_model(name)
        return RegisteredModel(
            name=rm.name,
            description=rm.description or "",
            model_type=ModelType(rm.tags.get("model_type", "base_model")),
            tags=rm.tags or {}
        )

    def get_version(
        self,
        model_name: str,
        version: int
    ) -> ModelVersion:
        """Get specific model version"""
        mv = self.client.get_model_version(model_name, str(version))
        return self._convert_mlflow_version(mv)

    def get_latest_version(
        self,
        model_name: str,
        stage: Optional[ModelStage] = None
    ) -> ModelVersion:
        """Get latest version by stage"""
        if stage:
            stages = [stage.value.title()]  # MLflow uses title case
        else:
            stages = None

        versions = self.client.get_latest_versions(model_name, stages)
        if not versions:
            raise ValueError(f"No versions found for {model_name}")

        # Return most recent
        latest = max(versions, key=lambda v: int(v.version))
        return self._convert_mlflow_version(latest)

    def transition_stage(
        self,
        model_name: str,
        version: int,
        stage: ModelStage,
        archive_existing: bool = True
    ):
        """Transition model to new stage"""
        self.client.transition_model_version_stage(
            name=model_name,
            version=str(version),
            stage=stage.value.title(),
            archive_existing_versions=archive_existing
        )

    def set_alias(
        self,
        model_name: str,
        version: int,
        alias: str
    ):
        """Set alias for model version (MLflow 2.x+)"""
        self.client.set_registered_model_alias(
            name=model_name,
            alias=alias,
            version=str(version)
        )

    def get_model_by_alias(
        self,
        model_name: str,
        alias: str
    ) -> ModelVersion:
        """Get model version by alias"""
        mv = self.client.get_model_version_by_alias(model_name, alias)
        return self._convert_mlflow_version(mv)

    def list_models(
        self,
        filter_tags: Optional[Dict[str, str]] = None
    ) -> List[RegisteredModel]:
        """List all registered models"""
        filter_string = None
        if filter_tags:
            filters = [f"tag.{k}='{v}'" for k, v in filter_tags.items()]
            filter_string = " AND ".join(filters)

        models = self.client.search_registered_models(filter_string)
        return [
            RegisteredModel(
                name=rm.name,
                description=rm.description or "",
                model_type=ModelType(rm.tags.get("model_type", "base_model")),
                tags=rm.tags or {}
            )
            for rm in models
        ]

    def delete_version(
        self,
        model_name: str,
        version: int
    ):
        """Delete model version"""
        self.client.delete_model_version(model_name, str(version))

    def _convert_mlflow_version(self, mv) -> ModelVersion:
        """Convert MLflow ModelVersion to our ModelVersion"""
        return ModelVersion(
            model_name=mv.name,
            version=int(mv.version),
            model_type=ModelType.BASE_MODEL,  # Would need to lookup
            stage=ModelStage(mv.current_stage.lower()),
            source_run_id=mv.run_id,
            description=mv.description or "",
            tags=mv.tags or {}
        )


class LLMModelWrapper(PythonModel):
    """
    MLflow PythonModel wrapper for LLMs.
    Enables logging LLMs with custom loading and inference.
    """

    def __init__(
        self,
        model_path: str,
        model_type: str = "causal_lm",
        quantization: Optional[str] = None
    ):
        self.model_path = model_path
        self.model_type = model_type
        self.quantization = quantization
        self.model = None
        self.tokenizer = None

    def load_context(self, context):
        """Load model when MLflow loads the wrapper"""
        from transformers import AutoModelForCausalLM, AutoTokenizer
        import torch

        # Load tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(
            context.artifacts["model_dir"]
        )

        # Load model with appropriate configuration
        load_kwargs = {
            "device_map": "auto",
            "torch_dtype": torch.float16
        }

        if self.quantization == "4bit":
            from transformers import BitsAndBytesConfig
            load_kwargs["quantization_config"] = BitsAndBytesConfig(
                load_in_4bit=True,
                bnb_4bit_compute_dtype=torch.float16
            )

        self.model = AutoModelForCausalLM.from_pretrained(
            context.artifacts["model_dir"],
            **load_kwargs
        )

    def predict(self, context, model_input):
        """Generate predictions"""
        import torch

        prompts = model_input["prompt"].tolist()
        max_new_tokens = model_input.get("max_new_tokens", [100])[0]

        results = []
        for prompt in prompts:
            inputs = self.tokenizer(prompt, return_tensors="pt").to(
                self.model.device
            )

            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_new_tokens=max_new_tokens,
                    do_sample=True,
                    temperature=0.7
                )

            response = self.tokenizer.decode(
                outputs[0][inputs['input_ids'].shape[1]:],
                skip_special_tokens=True
            )
            results.append(response)

        return {"response": results}


def log_llm_to_mlflow(
    model_path: str,
    model_name: str,
    quantization: Optional[str] = None,
    metrics: Optional[Dict[str, float]] = None
):
    """Convenience function to log LLM to MLflow"""

    wrapper = LLMModelWrapper(
        model_path=model_path,
        quantization=quantization
    )

    with mlflow.start_run():
        # Log metrics
        if metrics:
            mlflow.log_metrics(metrics)

        # Log model
        mlflow.pyfunc.log_model(
            artifact_path="model",
            python_model=wrapper,
            artifacts={"model_dir": model_path},
            registered_model_name=model_name,
            pip_requirements=[
                "transformers>=4.36.0",
                "torch>=2.0.0",
                "accelerate",
                "bitsandbytes"
            ]
        )
```

### 2.2 MLflow Best Practices

```python
"""
MLflow model registry best practices
"""
from typing import Dict, Any, Optional, List
from dataclasses import dataclass
import json


@dataclass
class ModelCard:
    """Model documentation card"""
    model_name: str
    version: int

    # Overview
    description: str
    intended_use: str
    limitations: str

    # Training
    training_data: str
    training_procedure: str
    hyperparameters: Dict[str, Any]

    # Evaluation
    evaluation_data: str
    metrics: Dict[str, float]
    benchmark_results: Dict[str, float]

    # Ethics & Safety
    bias_risks: str
    safety_evaluations: str

    # Usage
    example_usage: str
    input_format: str
    output_format: str


class ModelRegistryBestPractices:
    """
    Implement MLflow model registry best practices
    """

    def __init__(self, registry: MLflowModelRegistry):
        self.registry = registry

    # Naming conventions
    def validate_model_name(self, name: str) -> bool:
        """
        Validate model name follows conventions:
        - Product-centric, not version-centric
        - Lowercase with underscores
        - Descriptive but concise
        """
        # Bad: fraud_detector_v2, new_search_model
        # Good: fraud_detector, search_ranker

        if any(x in name for x in ["_v1", "_v2", "_new", "_old", "_legacy"]):
            return False

        if not name.islower():
            return False

        if not name.replace("_", "").isalnum():
            return False

        return True

    def create_model_card(
        self,
        model_name: str,
        version: int,
        card: ModelCard
    ):
        """Attach model card documentation to version"""
        card_json = json.dumps(asdict(card), indent=2)

        self.registry.client.set_model_version_tag(
            name=model_name,
            version=str(version),
            key="model_card",
            value=card_json
        )

    def get_model_card(
        self,
        model_name: str,
        version: int
    ) -> Optional[ModelCard]:
        """Retrieve model card from version"""
        mv = self.registry.client.get_model_version(model_name, str(version))
        card_json = mv.tags.get("model_card")

        if card_json:
            return ModelCard(**json.loads(card_json))
        return None

    # Stage management
    def promote_to_staging(
        self,
        model_name: str,
        version: int,
        validation_results: Dict[str, Any]
    ) -> bool:
        """
        Promote model to staging with validation gates.
        Returns True if promotion succeeded.
        """
        # Check validation results
        required_checks = [
            "unit_tests_passed",
            "integration_tests_passed",
            "performance_baseline_met"
        ]

        for check in required_checks:
            if not validation_results.get(check, False):
                print(f"Promotion blocked: {check} not satisfied")
                return False

        # Transition to staging
        self.registry.transition_stage(
            model_name=model_name,
            version=version,
            stage=ModelStage.STAGING
        )

        # Log validation results
        for key, value in validation_results.items():
            self.registry.client.set_model_version_tag(
                name=model_name,
                version=str(version),
                key=f"validation_{key}",
                value=str(value)
            )

        return True

    def promote_to_production(
        self,
        model_name: str,
        version: int,
        approval_info: Dict[str, Any]
    ) -> bool:
        """
        Promote model to production with approval workflow.
        """
        # Verify model is in staging
        mv = self.registry.get_version(model_name, version)
        if mv.stage != ModelStage.STAGING:
            print(f"Cannot promote: model must be in staging first")
            return False

        # Verify approvals
        required_approvals = ["ml_lead", "qa_lead"]
        for approver in required_approvals:
            if approver not in approval_info:
                print(f"Missing approval from: {approver}")
                return False

        # Set production alias
        self.registry.set_alias(
            model_name=model_name,
            version=version,
            alias="production"
        )

        # Transition to production
        self.registry.transition_stage(
            model_name=model_name,
            version=version,
            stage=ModelStage.PRODUCTION
        )

        # Log approval info
        self.registry.client.set_model_version_tag(
            name=model_name,
            version=str(version),
            key="production_approval",
            value=json.dumps(approval_info)
        )

        return True

    def rollback(
        self,
        model_name: str,
        target_version: int,
        reason: str
    ):
        """
        Rollback production to previous version.
        """
        # Update alias to point to target version
        self.registry.set_alias(
            model_name=model_name,
            version=target_version,
            alias="production"
        )

        # Log rollback reason
        self.registry.client.set_model_version_tag(
            name=model_name,
            version=str(target_version),
            key="rollback_reason",
            value=reason
        )

        print(f"Rolled back {model_name} to v{target_version}")

    # Lineage tracking
    def track_model_lineage(
        self,
        model_name: str,
        version: int,
        parent_model: str,
        parent_version: int,
        lineage_type: str  # "fine_tuned", "distilled", "merged"
    ):
        """Track model derivation lineage"""
        lineage_info = {
            "parent_model": parent_model,
            "parent_version": parent_version,
            "lineage_type": lineage_type
        }

        self.registry.client.set_model_version_tag(
            name=model_name,
            version=str(version),
            key="lineage",
            value=json.dumps(lineage_info)
        )

    def get_model_lineage(
        self,
        model_name: str,
        version: int
    ) -> List[Dict[str, Any]]:
        """Trace full model lineage back to base model"""
        lineage_chain = []

        current_name = model_name
        current_version = version

        while True:
            mv = self.registry.client.get_model_version(
                current_name, str(current_version)
            )

            lineage_json = mv.tags.get("lineage")
            if not lineage_json:
                break

            lineage = json.loads(lineage_json)
            lineage_chain.append({
                "model": current_name,
                "version": current_version,
                "derived_from": lineage
            })

            current_name = lineage["parent_model"]
            current_version = lineage["parent_version"]

        return lineage_chain
```

---

## 3. Weights & Biases Model Registry

### 3.1 W&B Registry Implementation

```python
"""
Weights & Biases Model Registry implementation
"""
import wandb
from typing import List, Dict, Any, Optional
from datetime import datetime


class WandBModelRegistry(ModelRegistry):
    """
    Weights & Biases Model Registry implementation.
    Integrates with W&B experiment tracking.
    """

    def __init__(
        self,
        entity: str,
        project: str
    ):
        self.entity = entity
        self.project = project
        self.api = wandb.Api()

    def register_model(
        self,
        name: str,
        description: str,
        model_type: ModelType
    ) -> RegisteredModel:
        """Register model in W&B"""
        # W&B models are created implicitly when artifacts are logged
        # We create a placeholder artifact to establish the model
        with wandb.init(
            entity=self.entity,
            project=self.project,
            job_type="register_model"
        ) as run:
            artifact = wandb.Artifact(
                name=name,
                type="model",
                description=description,
                metadata={"model_type": model_type.value}
            )
            run.log_artifact(artifact)

        return RegisteredModel(
            name=name,
            description=description,
            model_type=model_type
        )

    def create_version(
        self,
        model_name: str,
        artifacts: List[ModelArtifact],
        metrics: Optional[List[ModelMetrics]] = None,
        **kwargs
    ) -> ModelVersion:
        """Create model version by logging artifact"""

        with wandb.init(
            entity=self.entity,
            project=self.project,
            job_type="create_model_version"
        ) as run:
            # Create artifact
            artifact = wandb.Artifact(
                name=model_name,
                type="model",
                description=kwargs.get("description", ""),
                metadata={
                    "model_type": kwargs.get("model_type", "base_model"),
                    "training_config": kwargs.get("training_config", {}),
                    **kwargs.get("tags", {})
                }
            )

            # Add files to artifact
            for art in artifacts:
                artifact.add_file(art.path)

            # Log artifact
            run.log_artifact(artifact)

            # Log metrics
            if metrics:
                for metric in metrics:
                    run.log({
                        f"{metric.benchmark_name}/{metric.metric_name}":
                            metric.value
                    })

        # Get version info
        art = self.api.artifact(f"{self.entity}/{self.project}/{model_name}:latest")

        return ModelVersion(
            model_name=model_name,
            version=int(art.version.lstrip('v')),
            model_type=ModelType(art.metadata.get("model_type", "base_model")),
            stage=ModelStage.NONE,
            artifacts=artifacts,
            metrics=metrics or []
        )

    def get_version(
        self,
        model_name: str,
        version: int
    ) -> ModelVersion:
        """Get specific model version"""
        artifact_name = f"{self.entity}/{self.project}/{model_name}:v{version}"
        art = self.api.artifact(artifact_name)

        return ModelVersion(
            model_name=model_name,
            version=version,
            model_type=ModelType(art.metadata.get("model_type", "base_model")),
            stage=self._get_stage_from_aliases(art),
            description=art.description or ""
        )

    def transition_stage(
        self,
        model_name: str,
        version: int,
        stage: ModelStage,
        archive_existing: bool = True
    ):
        """Transition stage using W&B aliases"""
        artifact_name = f"{self.entity}/{self.project}/{model_name}:v{version}"
        art = self.api.artifact(artifact_name)

        # W&B uses aliases for stage management
        alias = stage.value
        art.aliases.append(alias)
        art.save()

    def set_alias(
        self,
        model_name: str,
        version: int,
        alias: str
    ):
        """Set alias for model version"""
        artifact_name = f"{self.entity}/{self.project}/{model_name}:v{version}"
        art = self.api.artifact(artifact_name)
        art.aliases.append(alias)
        art.save()

    def _get_stage_from_aliases(self, artifact) -> ModelStage:
        """Determine stage from W&B aliases"""
        aliases = artifact.aliases

        if "production" in aliases:
            return ModelStage.PRODUCTION
        elif "staging" in aliases:
            return ModelStage.STAGING
        elif "archived" in aliases:
            return ModelStage.ARCHIVED
        else:
            return ModelStage.NONE

    def link_to_registry(
        self,
        model_name: str,
        version: int,
        registry_name: str
    ):
        """
        Link model artifact to W&B Model Registry.
        This is the new W&B approach for model management.
        """
        artifact_name = f"{self.entity}/{self.project}/{model_name}:v{version}"
        art = self.api.artifact(artifact_name)

        # Link to registry
        art.link(
            f"{self.entity}/model-registry/{registry_name}"
        )


class WandBModelTracker:
    """
    Track models during training with W&B integration
    """

    def __init__(
        self,
        project: str,
        entity: Optional[str] = None
    ):
        self.project = project
        self.entity = entity

    def track_training(
        self,
        model_name: str,
        config: Dict[str, Any],
        callback_fn=None
    ):
        """Track training run and log model"""

        run = wandb.init(
            project=self.project,
            entity=self.entity,
            config=config,
            name=f"{model_name}_training"
        )

        # Return callback for logging during training
        class WandBCallback:
            def __init__(self, run):
                self.run = run

            def log_metrics(self, metrics: Dict[str, float], step: int):
                self.run.log(metrics, step=step)

            def log_model(self, model_path: str, metadata: Dict = None):
                artifact = wandb.Artifact(
                    name=model_name,
                    type="model",
                    metadata=metadata or {}
                )
                artifact.add_dir(model_path)
                self.run.log_artifact(artifact)

            def finish(self):
                self.run.finish()

        return WandBCallback(run)
```

---

## 4. Custom Model Registry

### 4.1 Database-Backed Registry

```python
"""
Custom model registry with PostgreSQL backend
"""
from typing import List, Dict, Any, Optional
from datetime import datetime
import json
from sqlalchemy import (
    create_engine, Column, Integer, String, DateTime,
    ForeignKey, Text, JSON, Enum as SQLEnum
)
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker, relationship


Base = declarative_base()


class RegisteredModelDB(Base):
    """Database model for registered models"""
    __tablename__ = "registered_models"

    id = Column(Integer, primary_key=True)
    name = Column(String(255), unique=True, nullable=False)
    description = Column(Text)
    model_type = Column(String(50))
    tags = Column(JSON)
    created_at = Column(DateTime, default=datetime.utcnow)
    updated_at = Column(DateTime, default=datetime.utcnow, onupdate=datetime.utcnow)

    versions = relationship("ModelVersionDB", back_populates="model")


class ModelVersionDB(Base):
    """Database model for model versions"""
    __tablename__ = "model_versions"

    id = Column(Integer, primary_key=True)
    model_id = Column(Integer, ForeignKey("registered_models.id"))
    version = Column(Integer, nullable=False)
    stage = Column(String(50), default="none")

    # Lineage
    source_experiment_id = Column(String(255))
    source_run_id = Column(String(255))
    parent_model_version_id = Column(Integer, ForeignKey("model_versions.id"))

    # Metadata
    description = Column(Text)
    tags = Column(JSON)
    parameters = Column(JSON)
    training_config = Column(JSON)

    # Timestamps
    created_at = Column(DateTime, default=datetime.utcnow)
    registered_by = Column(String(255))

    model = relationship("RegisteredModelDB", back_populates="versions")
    artifacts = relationship("ModelArtifactDB", back_populates="version")
    metrics = relationship("ModelMetricsDB", back_populates="version")
    aliases = relationship("ModelAliasDB", back_populates="version")


class ModelArtifactDB(Base):
    """Database model for artifacts"""
    __tablename__ = "model_artifacts"

    id = Column(Integer, primary_key=True)
    version_id = Column(Integer, ForeignKey("model_versions.id"))
    artifact_type = Column(String(50))
    path = Column(String(1024))
    size_bytes = Column(Integer)
    checksum = Column(String(64))
    format = Column(String(50))
    metadata = Column(JSON)

    version = relationship("ModelVersionDB", back_populates="artifacts")


class ModelMetricsDB(Base):
    """Database model for metrics"""
    __tablename__ = "model_metrics"

    id = Column(Integer, primary_key=True)
    version_id = Column(Integer, ForeignKey("model_versions.id"))
    benchmark_name = Column(String(255))
    metric_name = Column(String(255))
    value = Column(String(50))  # Store as string for flexibility
    evaluation_date = Column(DateTime, default=datetime.utcnow)
    configuration = Column(JSON)

    version = relationship("ModelVersionDB", back_populates="metrics")


class ModelAliasDB(Base):
    """Database model for aliases"""
    __tablename__ = "model_aliases"

    id = Column(Integer, primary_key=True)
    version_id = Column(Integer, ForeignKey("model_versions.id"))
    alias = Column(String(255), nullable=False)
    created_at = Column(DateTime, default=datetime.utcnow)

    version = relationship("ModelVersionDB", back_populates="aliases")


class PostgresModelRegistry(ModelRegistry):
    """
    PostgreSQL-backed custom model registry
    """

    def __init__(
        self,
        connection_string: str,
        artifact_store: ArtifactStore
    ):
        self.engine = create_engine(connection_string)
        Base.metadata.create_all(self.engine)
        self.Session = sessionmaker(bind=self.engine)
        self.artifact_store = artifact_store

    def register_model(
        self,
        name: str,
        description: str,
        model_type: ModelType
    ) -> RegisteredModel:
        """Register new model"""
        session = self.Session()
        try:
            db_model = RegisteredModelDB(
                name=name,
                description=description,
                model_type=model_type.value
            )
            session.add(db_model)
            session.commit()

            return RegisteredModel(
                name=name,
                description=description,
                model_type=model_type
            )
        finally:
            session.close()

    def create_version(
        self,
        model_name: str,
        artifacts: List[ModelArtifact],
        metrics: Optional[List[ModelMetrics]] = None,
        **kwargs
    ) -> ModelVersion:
        """Create new model version"""
        session = self.Session()
        try:
            # Get model
            model = session.query(RegisteredModelDB).filter_by(
                name=model_name
            ).first()

            if not model:
                raise ValueError(f"Model {model_name} not found")

            # Calculate next version
            max_version = session.query(
                ModelVersionDB
            ).filter_by(model_id=model.id).count()

            version_num = max_version + 1

            # Create version
            db_version = ModelVersionDB(
                model_id=model.id,
                version=version_num,
                description=kwargs.get("description", ""),
                tags=kwargs.get("tags", {}),
                parameters=kwargs.get("parameters", {}),
                training_config=kwargs.get("training_config", {}),
                registered_by=kwargs.get("registered_by", "")
            )
            session.add(db_version)
            session.flush()  # Get ID

            # Add artifacts
            for art in artifacts:
                db_artifact = ModelArtifactDB(
                    version_id=db_version.id,
                    artifact_type=art.artifact_type,
                    path=art.path,
                    size_bytes=art.size_bytes,
                    checksum=art.checksum,
                    format=art.format,
                    metadata=art.metadata
                )
                session.add(db_artifact)

            # Add metrics
            if metrics:
                for metric in metrics:
                    db_metric = ModelMetricsDB(
                        version_id=db_version.id,
                        benchmark_name=metric.benchmark_name,
                        metric_name=metric.metric_name,
                        value=str(metric.value),
                        configuration=metric.configuration
                    )
                    session.add(db_metric)

            session.commit()

            return ModelVersion(
                model_name=model_name,
                version=version_num,
                model_type=ModelType(model.model_type),
                stage=ModelStage.NONE,
                artifacts=artifacts,
                metrics=metrics or []
            )
        finally:
            session.close()

    def get_version(
        self,
        model_name: str,
        version: int
    ) -> ModelVersion:
        """Get specific model version"""
        session = self.Session()
        try:
            db_version = session.query(ModelVersionDB).join(
                RegisteredModelDB
            ).filter(
                RegisteredModelDB.name == model_name,
                ModelVersionDB.version == version
            ).first()

            if not db_version:
                raise ValueError(
                    f"Version {version} of {model_name} not found"
                )

            return self._convert_db_version(db_version)
        finally:
            session.close()

    def transition_stage(
        self,
        model_name: str,
        version: int,
        stage: ModelStage,
        archive_existing: bool = True
    ):
        """Transition model stage"""
        session = self.Session()
        try:
            # Archive existing if needed
            if archive_existing and stage == ModelStage.PRODUCTION:
                session.query(ModelVersionDB).join(
                    RegisteredModelDB
                ).filter(
                    RegisteredModelDB.name == model_name,
                    ModelVersionDB.stage == "production"
                ).update({ModelVersionDB.stage: "archived"})

            # Update version stage
            session.query(ModelVersionDB).join(
                RegisteredModelDB
            ).filter(
                RegisteredModelDB.name == model_name,
                ModelVersionDB.version == version
            ).update({ModelVersionDB.stage: stage.value})

            session.commit()
        finally:
            session.close()

    def set_alias(
        self,
        model_name: str,
        version: int,
        alias: str
    ):
        """Set alias for version"""
        session = self.Session()
        try:
            db_version = session.query(ModelVersionDB).join(
                RegisteredModelDB
            ).filter(
                RegisteredModelDB.name == model_name,
                ModelVersionDB.version == version
            ).first()

            if not db_version:
                raise ValueError(f"Version not found")

            # Remove existing alias
            session.query(ModelAliasDB).filter_by(alias=alias).delete()

            # Create new alias
            db_alias = ModelAliasDB(
                version_id=db_version.id,
                alias=alias
            )
            session.add(db_alias)
            session.commit()
        finally:
            session.close()

    def _convert_db_version(self, db_version) -> ModelVersion:
        """Convert database version to ModelVersion"""
        artifacts = [
            ModelArtifact(
                artifact_type=a.artifact_type,
                path=a.path,
                size_bytes=a.size_bytes,
                checksum=a.checksum,
                format=a.format
            )
            for a in db_version.artifacts
        ]

        metrics = [
            ModelMetrics(
                benchmark_name=m.benchmark_name,
                metric_name=m.metric_name,
                value=float(m.value),
                evaluation_date=m.evaluation_date
            )
            for m in db_version.metrics
        ]

        return ModelVersion(
            model_name=db_version.model.name,
            version=db_version.version,
            model_type=ModelType(db_version.model.model_type),
            stage=ModelStage(db_version.stage),
            artifacts=artifacts,
            metrics=metrics,
            description=db_version.description or "",
            tags=db_version.tags or {}
        )
```

---

## 5. Registry Operations

### 5.1 Model Loading and Serving

```python
"""
Load models from registry for serving
"""
from typing import Dict, Any, Optional
from pathlib import Path
import tempfile


class ModelLoader:
    """
    Load models from registry for inference
    """

    def __init__(
        self,
        registry: ModelRegistry,
        artifact_manager: ModelArtifactManager,
        cache_dir: str = "/tmp/model_cache"
    ):
        self.registry = registry
        self.artifact_manager = artifact_manager
        self.cache_dir = Path(cache_dir)
        self.cache_dir.mkdir(parents=True, exist_ok=True)
        self._loaded_models = {}

    def load_model(
        self,
        model_name: str,
        version: Optional[int] = None,
        alias: Optional[str] = None,
        device: str = "auto"
    ):
        """
        Load model from registry.
        Uses version, alias, or latest production.
        """
        # Determine which version to load
        if alias:
            model_version = self.registry.get_model_by_alias(model_name, alias)
        elif version:
            model_version = self.registry.get_version(model_name, version)
        else:
            model_version = self.registry.get_latest_version(
                model_name,
                stage=ModelStage.PRODUCTION
            )

        # Check cache
        cache_key = f"{model_name}_v{model_version.version}"
        if cache_key in self._loaded_models:
            return self._loaded_models[cache_key]

        # Download artifacts
        local_dir = self.cache_dir / cache_key
        if not local_dir.exists():
            self.artifact_manager.download_model(
                model_name=model_name,
                version=model_version.version,
                artifacts=model_version.artifacts,
                local_dir=str(local_dir)
            )

        # Load model based on type
        model = self._load_model_by_type(
            local_dir=str(local_dir),
            model_type=model_version.model_type,
            device=device
        )

        self._loaded_models[cache_key] = model
        return model

    def _load_model_by_type(
        self,
        local_dir: str,
        model_type: ModelType,
        device: str
    ):
        """Load model based on its type"""
        from transformers import AutoModelForCausalLM, AutoTokenizer
        import torch

        device_map = "auto" if device == "auto" else device

        if model_type in [ModelType.BASE_MODEL, ModelType.FINE_TUNED]:
            model = AutoModelForCausalLM.from_pretrained(
                local_dir,
                device_map=device_map,
                torch_dtype=torch.float16
            )
            tokenizer = AutoTokenizer.from_pretrained(local_dir)
            return {"model": model, "tokenizer": tokenizer}

        elif model_type == ModelType.ADAPTER:
            # Load base model + adapter
            from peft import PeftModel

            # Load adapter config to find base model
            import json
            with open(f"{local_dir}/adapter_config.json") as f:
                adapter_config = json.load(f)

            base_model = AutoModelForCausalLM.from_pretrained(
                adapter_config["base_model_name_or_path"],
                device_map=device_map,
                torch_dtype=torch.float16
            )

            model = PeftModel.from_pretrained(base_model, local_dir)
            tokenizer = AutoTokenizer.from_pretrained(
                adapter_config["base_model_name_or_path"]
            )
            return {"model": model, "tokenizer": tokenizer}

        elif model_type == ModelType.QUANTIZED:
            # Load quantized model
            if (Path(local_dir) / "model.gguf").exists():
                # GGUF format
                from llama_cpp import Llama
                model = Llama(
                    model_path=f"{local_dir}/model.gguf",
                    n_gpu_layers=-1
                )
                return {"model": model, "type": "gguf"}
            else:
                # AWQ/GPTQ format
                model = AutoModelForCausalLM.from_pretrained(
                    local_dir,
                    device_map=device_map
                )
                tokenizer = AutoTokenizer.from_pretrained(local_dir)
                return {"model": model, "tokenizer": tokenizer}

        else:
            raise ValueError(f"Unknown model type: {model_type}")

    def unload_model(self, model_name: str, version: int):
        """Unload model from memory"""
        cache_key = f"{model_name}_v{version}"
        if cache_key in self._loaded_models:
            del self._loaded_models[cache_key]
            import gc
            import torch
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()


class ModelServingConfig:
    """Configuration for model serving from registry"""

    def __init__(
        self,
        model_name: str,
        alias: str = "production",
        max_batch_size: int = 8,
        max_concurrent_requests: int = 10,
        auto_reload: bool = True,
        reload_check_interval: int = 60
    ):
        self.model_name = model_name
        self.alias = alias
        self.max_batch_size = max_batch_size
        self.max_concurrent_requests = max_concurrent_requests
        self.auto_reload = auto_reload
        self.reload_check_interval = reload_check_interval


class ServingModelManager:
    """
    Manage models for serving with automatic updates
    """

    def __init__(
        self,
        registry: ModelRegistry,
        loader: ModelLoader
    ):
        self.registry = registry
        self.loader = loader
        self.serving_models: Dict[str, Dict] = {}

    def start_serving(self, config: ModelServingConfig):
        """Start serving a model configuration"""
        # Load initial model
        model = self.loader.load_model(
            model_name=config.model_name,
            alias=config.alias
        )

        # Get current version
        version_info = self.registry.get_model_by_alias(
            config.model_name,
            config.alias
        )

        self.serving_models[config.model_name] = {
            "model": model,
            "config": config,
            "current_version": version_info.version
        }

        # Start auto-reload if enabled
        if config.auto_reload:
            self._start_reload_checker(config)

    def _start_reload_checker(self, config: ModelServingConfig):
        """Start background thread to check for model updates"""
        import threading

        def check_and_reload():
            import time
            while config.model_name in self.serving_models:
                time.sleep(config.reload_check_interval)

                # Check for new version
                try:
                    latest = self.registry.get_model_by_alias(
                        config.model_name,
                        config.alias
                    )

                    current = self.serving_models[config.model_name]["current_version"]

                    if latest.version != current:
                        print(f"New version detected: v{latest.version}")
                        self._reload_model(config.model_name)
                except Exception as e:
                    print(f"Error checking for updates: {e}")

        thread = threading.Thread(target=check_and_reload, daemon=True)
        thread.start()

    def _reload_model(self, model_name: str):
        """Hot-reload model to new version"""
        config = self.serving_models[model_name]["config"]
        old_version = self.serving_models[model_name]["current_version"]

        # Load new model
        new_model = self.loader.load_model(
            model_name=model_name,
            alias=config.alias
        )

        # Get new version info
        version_info = self.registry.get_model_by_alias(
            model_name,
            config.alias
        )

        # Swap models
        self.serving_models[model_name]["model"] = new_model
        self.serving_models[model_name]["current_version"] = version_info.version

        # Unload old version
        self.loader.unload_model(model_name, old_version)

        print(f"Reloaded {model_name}: v{old_version} -> v{version_info.version}")
```

---

## 6. Governance and Access Control

### 6.1 Access Control Implementation

```python
"""
Model registry access control and governance
"""
from typing import List, Dict, Set, Optional
from dataclasses import dataclass
from enum import Enum


class Permission(Enum):
    """Registry permissions"""
    READ = "read"
    CREATE = "create"
    UPDATE = "update"
    DELETE = "delete"
    PROMOTE = "promote"
    ADMIN = "admin"


@dataclass
class Role:
    """User role with permissions"""
    name: str
    permissions: Set[Permission]
    allowed_models: Optional[Set[str]] = None  # None = all models


class ModelRegistryACL:
    """
    Access control for model registry
    """

    def __init__(self):
        self.roles: Dict[str, Role] = {}
        self.user_roles: Dict[str, str] = {}

        # Default roles
        self._setup_default_roles()

    def _setup_default_roles(self):
        """Setup default roles"""
        self.roles["viewer"] = Role(
            name="viewer",
            permissions={Permission.READ}
        )

        self.roles["developer"] = Role(
            name="developer",
            permissions={Permission.READ, Permission.CREATE, Permission.UPDATE}
        )

        self.roles["ml_lead"] = Role(
            name="ml_lead",
            permissions={
                Permission.READ, Permission.CREATE,
                Permission.UPDATE, Permission.PROMOTE
            }
        )

        self.roles["admin"] = Role(
            name="admin",
            permissions={
                Permission.READ, Permission.CREATE,
                Permission.UPDATE, Permission.DELETE,
                Permission.PROMOTE, Permission.ADMIN
            }
        )

    def assign_role(self, user_id: str, role_name: str):
        """Assign role to user"""
        if role_name not in self.roles:
            raise ValueError(f"Unknown role: {role_name}")
        self.user_roles[user_id] = role_name

    def check_permission(
        self,
        user_id: str,
        permission: Permission,
        model_name: Optional[str] = None
    ) -> bool:
        """Check if user has permission"""
        role_name = self.user_roles.get(user_id)
        if not role_name:
            return False

        role = self.roles.get(role_name)
        if not role:
            return False

        # Check permission
        if permission not in role.permissions:
            return False

        # Check model-level access
        if role.allowed_models and model_name:
            if model_name not in role.allowed_models:
                return False

        return True

    def require_permission(
        self,
        user_id: str,
        permission: Permission,
        model_name: Optional[str] = None
    ):
        """Raise exception if permission not granted"""
        if not self.check_permission(user_id, permission, model_name):
            raise PermissionError(
                f"User {user_id} lacks {permission.value} permission"
                + (f" for model {model_name}" if model_name else "")
            )


class AuditLog:
    """
    Audit logging for registry operations
    """

    def __init__(self, storage_backend=None):
        self.storage = storage_backend or []

    def log(
        self,
        user_id: str,
        action: str,
        model_name: str,
        version: Optional[int] = None,
        details: Optional[Dict] = None
    ):
        """Log registry action"""
        from datetime import datetime

        entry = {
            "timestamp": datetime.utcnow().isoformat(),
            "user_id": user_id,
            "action": action,
            "model_name": model_name,
            "version": version,
            "details": details or {}
        }

        if isinstance(self.storage, list):
            self.storage.append(entry)
        else:
            self.storage.insert(entry)

    def get_audit_trail(
        self,
        model_name: Optional[str] = None,
        user_id: Optional[str] = None,
        action: Optional[str] = None,
        limit: int = 100
    ) -> List[Dict]:
        """Query audit trail"""
        results = self.storage if isinstance(self.storage, list) else list(self.storage.find())

        # Filter
        if model_name:
            results = [r for r in results if r["model_name"] == model_name]
        if user_id:
            results = [r for r in results if r["user_id"] == user_id]
        if action:
            results = [r for r in results if r["action"] == action]

        return results[-limit:]


class SecureModelRegistry:
    """
    Model registry with access control and audit logging
    """

    def __init__(
        self,
        base_registry: ModelRegistry,
        acl: ModelRegistryACL,
        audit_log: AuditLog
    ):
        self.registry = base_registry
        self.acl = acl
        self.audit = audit_log

    def register_model(
        self,
        user_id: str,
        name: str,
        description: str,
        model_type: ModelType
    ) -> RegisteredModel:
        """Register model with access control"""
        self.acl.require_permission(user_id, Permission.CREATE)

        result = self.registry.register_model(name, description, model_type)

        self.audit.log(
            user_id=user_id,
            action="register_model",
            model_name=name,
            details={"description": description, "model_type": model_type.value}
        )

        return result

    def create_version(
        self,
        user_id: str,
        model_name: str,
        artifacts: List[ModelArtifact],
        **kwargs
    ) -> ModelVersion:
        """Create version with access control"""
        self.acl.require_permission(user_id, Permission.CREATE, model_name)

        result = self.registry.create_version(model_name, artifacts, **kwargs)

        self.audit.log(
            user_id=user_id,
            action="create_version",
            model_name=model_name,
            version=result.version,
            details={"artifact_count": len(artifacts)}
        )

        return result

    def transition_stage(
        self,
        user_id: str,
        model_name: str,
        version: int,
        stage: ModelStage,
        **kwargs
    ):
        """Transition stage with access control"""
        if stage == ModelStage.PRODUCTION:
            self.acl.require_permission(user_id, Permission.PROMOTE, model_name)
        else:
            self.acl.require_permission(user_id, Permission.UPDATE, model_name)

        self.registry.transition_stage(model_name, version, stage, **kwargs)

        self.audit.log(
            user_id=user_id,
            action="transition_stage",
            model_name=model_name,
            version=version,
            details={"new_stage": stage.value}
        )
```

---

## 7. Troubleshooting Guide

### Common Issues

| Issue | Cause | Solution |
|-------|-------|----------|
| Version conflicts | Concurrent registrations | Use optimistic locking |
| Missing artifacts | Storage sync issues | Verify checksums on download |
| Slow loading | Large model files | Use streaming/chunked downloads |
| Stage stuck | Approval workflow blocked | Check required approvals |
| Alias not found | Alias moved to new version | Use version numbers for reproducibility |

### Diagnostic Commands

```python
"""
Registry diagnostic utilities
"""

class RegistryDiagnostics:
    """Diagnostic tools for model registry"""

    def __init__(self, registry: ModelRegistry):
        self.registry = registry

    def verify_model_integrity(
        self,
        model_name: str,
        version: int
    ) -> Dict[str, Any]:
        """Verify all artifacts are accessible and valid"""
        mv = self.registry.get_version(model_name, version)

        results = {
            "model": model_name,
            "version": version,
            "artifacts": [],
            "issues": []
        }

        for artifact in mv.artifacts:
            artifact_result = {
                "path": artifact.path,
                "type": artifact.artifact_type,
                "status": "ok"
            }

            # Check existence
            # (Implementation depends on storage backend)

            results["artifacts"].append(artifact_result)

        return results

    def list_orphaned_artifacts(self) -> List[str]:
        """Find artifacts not linked to any model version"""
        # Implementation depends on storage backend
        pass

    def check_lineage_consistency(
        self,
        model_name: str
    ) -> Dict[str, Any]:
        """Verify model lineage chain is consistent"""
        # Implementation
        pass
```

---

## 8. References

### Documentation
- MLflow Model Registry: https://mlflow.org/docs/latest/model-registry.html
- Weights & Biases Model Registry: https://docs.wandb.ai/guides/model_registry
- Databricks Unity Catalog: https://docs.databricks.com/unity-catalog/

### Best Practices
- Neptune.ai ML Model Registry Guide
- Google Cloud Vertex AI Model Registry
- AWS SageMaker Model Registry

---

## Document Metadata

- **Version**: 1.0
- **Last Updated**: 2024
- **Prerequisites**: MLOps fundamentals, version control
- **Estimated Reading Time**: 45 minutes
- **Hands-on Lab Time**: 3-4 hours
