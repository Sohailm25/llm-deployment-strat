> **Navigation** | [← 13.4 On-Call](13.4_on_call_practices_guide.md) | [14.1 Total Cost Ownership →](../14_cost_capacity_management/14.1_total_cost_ownership_guide.md)
>
> | | |
> |---|---|
> | **Prerequisites** | Platform architecture &#124; [13.1 Incident Response](13.1_incident_response_guide.md) &#124; [13.4 On-Call](13.4_on_call_practices_guide.md) |
> | **Related** | [13.1 Incident Response](13.1_incident_response_guide.md) &#124; [10.1 Monitoring](../10_monitoring_observability/10.1_llm_monitoring_strategy_guide.md) |
> | **Next** | [14.1 Total Cost of Ownership](../14_cost_capacity_management/14.1_total_cost_ownership_guide.md) |

# 13.5 Operational Runbooks Guide

## Document Information
- **Version**: 1.0
- **Last Updated**: 2024-01-15
- **Owner**: Site Reliability Engineering Team
- **Classification**: Internal

## Purpose and Scope

This guide provides a comprehensive framework for creating, maintaining, and executing operational runbooks for the Multi-Cloud RAG Platform. Runbooks document standardized procedures for handling common operational tasks and incident scenarios.

## Prerequisites

- Familiarity with platform architecture
- Access to operational tools and dashboards
- Understanding of incident response procedures (see 13.1)
- On-call training completed (see 13.4)

## 1. Runbook Framework

### 1.1 Runbook Structure and Metadata

```python
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
from enum import Enum
from datetime import datetime
import yaml
import json


class RunbookCategory(Enum):
    """Categories of runbooks."""
    INCIDENT_RESPONSE = "incident_response"
    MAINTENANCE = "maintenance"
    DEPLOYMENT = "deployment"
    RECOVERY = "recovery"
    SCALING = "scaling"
    TROUBLESHOOTING = "troubleshooting"
    SECURITY = "security"


class RunbookSeverity(Enum):
    """Severity level the runbook addresses."""
    SEV1 = "sev1"
    SEV2 = "sev2"
    SEV3 = "sev3"
    SEV4 = "sev4"
    ALL = "all"


class StepType(Enum):
    """Types of runbook steps."""
    MANUAL = "manual"
    AUTOMATED = "automated"
    DECISION = "decision"
    VERIFICATION = "verification"
    NOTIFICATION = "notification"


@dataclass
class RunbookStep:
    """A single step in a runbook."""
    step_number: int
    title: str
    description: str
    step_type: StepType
    commands: List[str] = field(default_factory=list)
    expected_output: Optional[str] = None
    success_criteria: Optional[str] = None
    failure_action: Optional[str] = None
    estimated_duration_minutes: int = 5
    requires_approval: bool = False
    rollback_step: Optional[int] = None
    automation_script: Optional[str] = None
    decision_branches: Optional[Dict[str, int]] = None  # condition -> next step


@dataclass
class RunbookMetadata:
    """Metadata for a runbook."""
    runbook_id: str
    title: str
    description: str
    category: RunbookCategory
    severity: RunbookSeverity
    services_affected: List[str]
    triggers: List[str]
    author: str
    created_at: datetime
    updated_at: datetime
    version: str
    review_date: datetime
    approvers: List[str]
    tags: List[str]
    estimated_total_duration_minutes: int
    requires_change_ticket: bool
    automation_level: str  # manual, semi-automated, fully-automated


@dataclass
class Runbook:
    """Complete runbook definition."""
    metadata: RunbookMetadata
    prerequisites: List[str]
    steps: List[RunbookStep]
    post_conditions: List[str]
    related_runbooks: List[str]
    references: List[str]
    changelog: List[Dict[str, str]]

    def to_yaml(self) -> str:
        """Export runbook to YAML format."""
        return yaml.dump(self.__dict__, default_flow_style=False)

    def to_markdown(self) -> str:
        """Export runbook to Markdown format."""
        md = f"# {self.metadata.title}\n\n"
        md += f"**Runbook ID**: {self.metadata.runbook_id}\n"
        md += f"**Category**: {self.metadata.category.value}\n"
        md += f"**Severity**: {self.metadata.severity.value}\n"
        md += f"**Version**: {self.metadata.version}\n"
        md += f"**Last Updated**: {self.metadata.updated_at.isoformat()}\n\n"

        md += f"## Description\n\n{self.metadata.description}\n\n"

        md += "## Triggers\n\n"
        for trigger in self.metadata.triggers:
            md += f"- {trigger}\n"

        md += "\n## Prerequisites\n\n"
        for prereq in self.prerequisites:
            md += f"- {prereq}\n"

        md += "\n## Procedure\n\n"
        for step in self.steps:
            md += f"### Step {step.step_number}: {step.title}\n\n"
            md += f"{step.description}\n\n"

            if step.commands:
                md += "**Commands:**\n```bash\n"
                for cmd in step.commands:
                    md += f"{cmd}\n"
                md += "```\n\n"

            if step.expected_output:
                md += f"**Expected Output:** {step.expected_output}\n\n"

            if step.success_criteria:
                md += f"**Success Criteria:** {step.success_criteria}\n\n"

            if step.failure_action:
                md += f"**If Failed:** {step.failure_action}\n\n"

        md += "## Post-Conditions\n\n"
        for condition in self.post_conditions:
            md += f"- {condition}\n"

        return md


class RunbookRepository:
    """Repository for managing runbooks."""

    def __init__(self, storage_path: str):
        self.storage_path = storage_path
        self.runbooks: Dict[str, Runbook] = {}
        self._load_runbooks()

    def _load_runbooks(self):
        """Load runbooks from storage."""
        # Implementation would load from filesystem/database
        pass

    def get_runbook(self, runbook_id: str) -> Optional[Runbook]:
        """Get a runbook by ID."""
        return self.runbooks.get(runbook_id)

    def search_runbooks(
        self,
        category: Optional[RunbookCategory] = None,
        severity: Optional[RunbookSeverity] = None,
        service: Optional[str] = None,
        tags: Optional[List[str]] = None
    ) -> List[Runbook]:
        """Search for runbooks matching criteria."""
        results = list(self.runbooks.values())

        if category:
            results = [r for r in results if r.metadata.category == category]

        if severity:
            results = [
                r for r in results
                if r.metadata.severity == severity or r.metadata.severity == RunbookSeverity.ALL
            ]

        if service:
            results = [
                r for r in results
                if service in r.metadata.services_affected
            ]

        if tags:
            results = [
                r for r in results
                if any(t in r.metadata.tags for t in tags)
            ]

        return results

    def find_runbook_for_alert(self, alert_name: str) -> Optional[Runbook]:
        """Find the appropriate runbook for an alert."""
        for runbook in self.runbooks.values():
            if alert_name in runbook.metadata.triggers:
                return runbook
        return None

    def save_runbook(self, runbook: Runbook):
        """Save or update a runbook."""
        self.runbooks[runbook.metadata.runbook_id] = runbook
        # Implementation would persist to storage

    def validate_runbook(self, runbook: Runbook) -> List[str]:
        """Validate a runbook for completeness and correctness."""
        issues = []

        # Check metadata
        if not runbook.metadata.title:
            issues.append("Missing title")
        if not runbook.metadata.description:
            issues.append("Missing description")
        if not runbook.metadata.triggers:
            issues.append("No triggers defined")

        # Check steps
        if not runbook.steps:
            issues.append("No steps defined")

        for step in runbook.steps:
            if not step.title:
                issues.append(f"Step {step.step_number}: Missing title")
            if not step.description:
                issues.append(f"Step {step.step_number}: Missing description")
            if step.step_type == StepType.DECISION and not step.decision_branches:
                issues.append(f"Step {step.step_number}: Decision step missing branches")

        # Check for orphan steps in decision branches
        step_numbers = {s.step_number for s in runbook.steps}
        for step in runbook.steps:
            if step.decision_branches:
                for branch, target in step.decision_branches.items():
                    if target not in step_numbers:
                        issues.append(
                            f"Step {step.step_number}: Decision branch '{branch}' "
                            f"points to non-existent step {target}"
                        )

        # Check review date
        if runbook.metadata.review_date < datetime.utcnow():
            issues.append("Runbook is overdue for review")

        return issues
```

### 1.2 Runbook Execution Engine

```python
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Callable, Any
from datetime import datetime
from enum import Enum
import subprocess
import asyncio


class ExecutionStatus(Enum):
    """Status of runbook execution."""
    NOT_STARTED = "not_started"
    IN_PROGRESS = "in_progress"
    PAUSED = "paused"
    COMPLETED = "completed"
    FAILED = "failed"
    ROLLED_BACK = "rolled_back"


@dataclass
class StepExecution:
    """Record of a step execution."""
    step_number: int
    started_at: datetime
    completed_at: Optional[datetime] = None
    status: ExecutionStatus = ExecutionStatus.NOT_STARTED
    output: str = ""
    error: Optional[str] = None
    operator: str = ""
    notes: str = ""
    approver: Optional[str] = None


@dataclass
class RunbookExecution:
    """Record of a runbook execution."""
    execution_id: str
    runbook_id: str
    incident_id: Optional[str]
    started_at: datetime
    started_by: str
    status: ExecutionStatus = ExecutionStatus.NOT_STARTED
    current_step: int = 1
    step_executions: List[StepExecution] = field(default_factory=list)
    variables: Dict[str, Any] = field(default_factory=dict)
    completed_at: Optional[datetime] = None
    total_duration_minutes: float = 0


class RunbookExecutor:
    """Execute runbooks with tracking and automation."""

    def __init__(
        self,
        repository: RunbookRepository,
        automation_registry: 'AutomationRegistry',
        notification_service: 'NotificationService'
    ):
        self.repository = repository
        self.automation = automation_registry
        self.notifications = notification_service
        self.active_executions: Dict[str, RunbookExecution] = {}

    async def start_execution(
        self,
        runbook_id: str,
        operator: str,
        incident_id: Optional[str] = None,
        variables: Optional[Dict[str, Any]] = None
    ) -> RunbookExecution:
        """Start executing a runbook."""
        runbook = self.repository.get_runbook(runbook_id)
        if not runbook:
            raise ValueError(f"Runbook {runbook_id} not found")

        execution = RunbookExecution(
            execution_id=f"exec-{runbook_id}-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}",
            runbook_id=runbook_id,
            incident_id=incident_id,
            started_at=datetime.utcnow(),
            started_by=operator,
            status=ExecutionStatus.IN_PROGRESS,
            variables=variables or {}
        )

        self.active_executions[execution.execution_id] = execution

        # Log execution start
        await self._log_execution_event(
            execution,
            "started",
            f"Runbook execution started by {operator}"
        )

        return execution

    async def execute_step(
        self,
        execution_id: str,
        operator: str,
        notes: Optional[str] = None,
        skip_automation: bool = False
    ) -> StepExecution:
        """Execute the current step of a runbook."""
        execution = self.active_executions.get(execution_id)
        if not execution:
            raise ValueError(f"Execution {execution_id} not found")

        runbook = self.repository.get_runbook(execution.runbook_id)
        step = next(
            (s for s in runbook.steps if s.step_number == execution.current_step),
            None
        )

        if not step:
            raise ValueError(f"Step {execution.current_step} not found")

        step_exec = StepExecution(
            step_number=step.step_number,
            started_at=datetime.utcnow(),
            operator=operator,
            notes=notes or "",
            status=ExecutionStatus.IN_PROGRESS
        )

        # Check if approval required
        if step.requires_approval:
            await self._request_approval(execution, step)
            step_exec.status = ExecutionStatus.PAUSED
            execution.step_executions.append(step_exec)
            return step_exec

        # Execute step
        try:
            if step.step_type == StepType.AUTOMATED and not skip_automation:
                output = await self._execute_automation(step, execution.variables)
            elif step.step_type == StepType.MANUAL:
                output = "Manual step - verified by operator"
            elif step.step_type == StepType.DECISION:
                output = "Decision point reached"
            else:
                output = "Step executed"

            step_exec.output = output
            step_exec.status = ExecutionStatus.COMPLETED
            step_exec.completed_at = datetime.utcnow()

        except Exception as e:
            step_exec.error = str(e)
            step_exec.status = ExecutionStatus.FAILED
            step_exec.completed_at = datetime.utcnow()

            if step.failure_action:
                await self._handle_step_failure(execution, step, step_exec)

        execution.step_executions.append(step_exec)

        # Advance to next step
        if step_exec.status == ExecutionStatus.COMPLETED:
            self._advance_step(execution, runbook, step)

        return step_exec

    async def _execute_automation(
        self,
        step: RunbookStep,
        variables: Dict[str, Any]
    ) -> str:
        """Execute automated step."""
        outputs = []

        for command in step.commands:
            # Substitute variables
            cmd = command.format(**variables)

            # Execute command
            result = subprocess.run(
                cmd,
                shell=True,
                capture_output=True,
                text=True,
                timeout=300
            )

            outputs.append(f"$ {cmd}\n{result.stdout}")

            if result.returncode != 0:
                raise Exception(f"Command failed: {result.stderr}")

        if step.automation_script:
            # Execute registered automation
            automation = self.automation.get(step.automation_script)
            if automation:
                result = await automation.execute(variables)
                outputs.append(f"Automation result: {result}")

        return "\n".join(outputs)

    def _advance_step(
        self,
        execution: RunbookExecution,
        runbook: Runbook,
        current_step: RunbookStep
    ):
        """Advance to the next step."""
        if current_step.step_type == StepType.DECISION:
            # Decision steps require explicit branch selection
            return

        next_step_num = current_step.step_number + 1
        if next_step_num > len(runbook.steps):
            # Runbook complete
            execution.status = ExecutionStatus.COMPLETED
            execution.completed_at = datetime.utcnow()
            execution.total_duration_minutes = (
                execution.completed_at - execution.started_at
            ).total_seconds() / 60
        else:
            execution.current_step = next_step_num

    async def select_decision_branch(
        self,
        execution_id: str,
        branch: str,
        operator: str
    ) -> int:
        """Select a branch at a decision point."""
        execution = self.active_executions.get(execution_id)
        if not execution:
            raise ValueError(f"Execution {execution_id} not found")

        runbook = self.repository.get_runbook(execution.runbook_id)
        step = next(
            (s for s in runbook.steps if s.step_number == execution.current_step),
            None
        )

        if not step or step.step_type != StepType.DECISION:
            raise ValueError("Current step is not a decision point")

        if branch not in step.decision_branches:
            raise ValueError(f"Invalid branch: {branch}")

        next_step = step.decision_branches[branch]
        execution.current_step = next_step

        await self._log_execution_event(
            execution,
            "decision",
            f"Branch '{branch}' selected, advancing to step {next_step}"
        )

        return next_step

    async def _request_approval(
        self,
        execution: RunbookExecution,
        step: RunbookStep
    ):
        """Request approval for a step."""
        runbook = self.repository.get_runbook(execution.runbook_id)

        await self.notifications.send_approval_request(
            execution_id=execution.execution_id,
            step_number=step.step_number,
            step_title=step.title,
            runbook_title=runbook.metadata.title,
            approvers=runbook.metadata.approvers
        )

    async def approve_step(
        self,
        execution_id: str,
        approver: str
    ) -> bool:
        """Approve a pending step."""
        execution = self.active_executions.get(execution_id)
        if not execution:
            return False

        runbook = self.repository.get_runbook(execution.runbook_id)

        if approver not in runbook.metadata.approvers:
            return False

        # Find pending step
        for step_exec in execution.step_executions:
            if step_exec.status == ExecutionStatus.PAUSED:
                step_exec.approver = approver
                step_exec.status = ExecutionStatus.IN_PROGRESS
                return True

        return False

    async def rollback(
        self,
        execution_id: str,
        operator: str,
        reason: str
    ) -> bool:
        """Rollback a runbook execution."""
        execution = self.active_executions.get(execution_id)
        if not execution:
            return False

        runbook = self.repository.get_runbook(execution.runbook_id)

        # Execute rollback steps in reverse
        for step_exec in reversed(execution.step_executions):
            if step_exec.status != ExecutionStatus.COMPLETED:
                continue

            step = next(
                (s for s in runbook.steps if s.step_number == step_exec.step_number),
                None
            )

            if step and step.rollback_step:
                rollback_step = next(
                    (s for s in runbook.steps if s.step_number == step.rollback_step),
                    None
                )
                if rollback_step:
                    await self._execute_automation(
                        rollback_step,
                        execution.variables
                    )

        execution.status = ExecutionStatus.ROLLED_BACK
        execution.completed_at = datetime.utcnow()

        await self._log_execution_event(
            execution,
            "rollback",
            f"Runbook rolled back by {operator}: {reason}"
        )

        return True

    async def _log_execution_event(
        self,
        execution: RunbookExecution,
        event_type: str,
        message: str
    ):
        """Log an execution event."""
        # Implementation would log to audit system
        pass

    async def _handle_step_failure(
        self,
        execution: RunbookExecution,
        step: RunbookStep,
        step_exec: StepExecution
    ):
        """Handle a failed step."""
        if "escalate" in step.failure_action.lower():
            await self.notifications.send_escalation(
                execution_id=execution.execution_id,
                step_number=step.step_number,
                error=step_exec.error
            )
        elif "rollback" in step.failure_action.lower():
            await self.rollback(
                execution.execution_id,
                "system",
                f"Auto-rollback due to step {step.step_number} failure"
            )
```

## 2. Core Platform Runbooks

### 2.1 LLM Provider Failover Runbook

```python
def create_llm_failover_runbook() -> Runbook:
    """Create the LLM provider failover runbook."""
    return Runbook(
        metadata=RunbookMetadata(
            runbook_id="RB-LLM-001",
            title="LLM Provider Failover",
            description="Procedure for failing over from a degraded LLM provider to backup providers",
            category=RunbookCategory.INCIDENT_RESPONSE,
            severity=RunbookSeverity.SEV1,
            services_affected=["llm-gateway", "rag-service", "chat-api"],
            triggers=[
                "LLMProviderErrorRateHigh",
                "LLMProviderLatencyHigh",
                "LLMProviderUnavailable"
            ],
            author="Platform Team",
            created_at=datetime(2024, 1, 1),
            updated_at=datetime(2024, 1, 15),
            version="2.1",
            review_date=datetime(2024, 4, 15),
            approvers=["oncall-lead", "platform-manager"],
            tags=["llm", "failover", "provider", "critical"],
            estimated_total_duration_minutes=15,
            requires_change_ticket=False,
            automation_level="semi-automated"
        ),
        prerequisites=[
            "Access to LLM Gateway admin console",
            "kubectl access to production clusters",
            "Access to provider status pages",
            "Understanding of provider routing configuration"
        ],
        steps=[
            RunbookStep(
                step_number=1,
                title="Assess Provider Health",
                description="Check the current health of all LLM providers",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl exec -it deploy/llm-gateway -- curl localhost:8080/health/providers",
                    "curl -s https://status.openai.com/api/v2/status.json | jq '.status'",
                    "curl -s https://status.anthropic.com/api/v2/status.json | jq '.status'"
                ],
                expected_output="JSON with provider health status",
                success_criteria="Identify which provider(s) are degraded",
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=2,
                title="Verify Backup Provider Capacity",
                description="Ensure backup providers have sufficient capacity",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl exec -it deploy/llm-gateway -- llm-cli check-quota --provider anthropic",
                    "kubectl exec -it deploy/llm-gateway -- llm-cli check-quota --provider azure-openai"
                ],
                expected_output="Available quota/rate limits for backup providers",
                success_criteria="Backup provider has >50% remaining quota",
                failure_action="Contact provider for quota increase, continue with reduced capacity",
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=3,
                title="Decision: Failover Type",
                description="Determine the appropriate failover strategy",
                step_type=StepType.DECISION,
                decision_branches={
                    "complete_outage": 4,  # Full failover
                    "degraded_performance": 5,  # Partial shift
                    "intermittent_errors": 6  # Increase retry/circuit breaker
                },
                estimated_duration_minutes=1
            ),
            RunbookStep(
                step_number=4,
                title="Execute Full Failover",
                description="Redirect all traffic to backup provider",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl set env deployment/llm-gateway LLM_PRIMARY_PROVIDER=anthropic",
                    "kubectl set env deployment/llm-gateway LLM_FALLBACK_ENABLED=true",
                    "kubectl rollout status deployment/llm-gateway --timeout=120s"
                ],
                expected_output="Deployment successfully rolled out",
                success_criteria="All pods running with new configuration",
                rollback_step=8,
                requires_approval=True,
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=5,
                title="Shift Partial Traffic",
                description="Redirect portion of traffic to backup provider",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/llm-gateway -- llm-cli set-weight openai 30",
                    "kubectl exec -it deploy/llm-gateway -- llm-cli set-weight anthropic 70"
                ],
                expected_output="Traffic weights updated",
                success_criteria="Traffic distribution matches configured weights",
                rollback_step=9,
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=6,
                title="Adjust Circuit Breaker",
                description="Tighten circuit breaker settings for degraded provider",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/llm-gateway -- llm-cli set-circuit-breaker openai --error-threshold 5 --timeout 30s"
                ],
                expected_output="Circuit breaker configuration updated",
                success_criteria="Errors isolated, requests routed to healthy endpoints",
                estimated_duration_minutes=1
            ),
            RunbookStep(
                step_number=7,
                title="Verify Failover Success",
                description="Confirm service is healthy after failover",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl exec -it deploy/llm-gateway -- curl localhost:8080/health",
                    "curl -X POST https://api.example.com/v1/chat/test -d '{\"message\": \"test\"}'"
                ],
                expected_output="200 OK responses, normal latency",
                success_criteria="Error rate < 1%, p95 latency < 2s",
                failure_action="Escalate to on-call lead, consider rollback",
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=8,
                title="Rollback Full Failover",
                description="Revert to original provider configuration",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl set env deployment/llm-gateway LLM_PRIMARY_PROVIDER=openai",
                    "kubectl rollout status deployment/llm-gateway --timeout=120s"
                ],
                expected_output="Rollback completed",
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=9,
                title="Rollback Traffic Shift",
                description="Restore original traffic weights",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/llm-gateway -- llm-cli set-weight openai 100",
                    "kubectl exec -it deploy/llm-gateway -- llm-cli set-weight anthropic 0"
                ],
                expected_output="Traffic weights restored",
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=10,
                title="Update Status and Notify",
                description="Update status page and notify stakeholders",
                step_type=StepType.NOTIFICATION,
                commands=[
                    "statuspage-cli incident update --status resolved --message 'LLM service restored'"
                ],
                estimated_duration_minutes=2
            )
        ],
        post_conditions=[
            "LLM service is operational with acceptable latency",
            "Error rates are below threshold",
            "Status page updated with resolution",
            "Incident channel notified of completion"
        ],
        related_runbooks=[
            "RB-LLM-002 (LLM Rate Limit Exceeded)",
            "RB-LLM-003 (LLM Model Degradation)"
        ],
        references=[
            "LLM Gateway Architecture Doc",
            "Provider SLA Documentation",
            "Traffic Management Guide"
        ],
        changelog=[
            {"date": "2024-01-15", "author": "platform-team", "changes": "Added Azure OpenAI as backup option"},
            {"date": "2024-01-01", "author": "platform-team", "changes": "Initial version"}
        ]
    )
```

### 2.2 Database Recovery Runbook

```python
def create_database_recovery_runbook() -> Runbook:
    """Create the database recovery runbook."""
    return Runbook(
        metadata=RunbookMetadata(
            runbook_id="RB-DB-001",
            title="PostgreSQL Database Recovery",
            description="Procedure for recovering PostgreSQL database from backup or replica",
            category=RunbookCategory.RECOVERY,
            severity=RunbookSeverity.SEV1,
            services_affected=["postgresql", "rag-service", "user-service", "document-service"],
            triggers=[
                "DatabaseConnectionPoolExhausted",
                "DatabaseReplicationLagHigh",
                "DatabasePrimaryUnreachable"
            ],
            author="Database Team",
            created_at=datetime(2024, 1, 1),
            updated_at=datetime(2024, 1, 15),
            version="1.2",
            review_date=datetime(2024, 4, 15),
            approvers=["dba-oncall", "platform-manager"],
            tags=["database", "postgresql", "recovery", "critical"],
            estimated_total_duration_minutes=45,
            requires_change_ticket=True,
            automation_level="semi-automated"
        ),
        prerequisites=[
            "DBA access to database clusters",
            "Access to backup storage (S3)",
            "kubectl access to production",
            "pgAdmin or psql client access"
        ],
        steps=[
            RunbookStep(
                step_number=1,
                title="Assess Database State",
                description="Determine current state of primary and replicas",
                step_type=StepType.VERIFICATION,
                commands=[
                    "psql -h primary.db.internal -c 'SELECT pg_is_in_recovery();'",
                    "psql -h replica.db.internal -c 'SELECT pg_last_wal_receive_lsn(), pg_last_wal_replay_lsn();'",
                    "kubectl get pods -l app=postgresql -o wide"
                ],
                expected_output="Database state and replication status",
                success_criteria="Clear understanding of which nodes are healthy",
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=2,
                title="Decision: Recovery Strategy",
                description="Choose appropriate recovery method",
                step_type=StepType.DECISION,
                decision_branches={
                    "promote_replica": 3,
                    "restore_from_backup": 7,
                    "repair_primary": 12
                },
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=3,
                title="Prepare Replica Promotion",
                description="Verify replica is suitable for promotion",
                step_type=StepType.VERIFICATION,
                commands=[
                    "psql -h replica.db.internal -c 'SELECT pg_wal_lsn_diff(pg_last_wal_receive_lsn(), pg_last_wal_replay_lsn());'"
                ],
                expected_output="Replication lag in bytes",
                success_criteria="Replication lag < 1MB",
                failure_action="Wait for replica to catch up or choose different recovery",
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=4,
                title="Stop Writes to Primary",
                description="Prevent new writes to corrupted/failing primary",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl scale deployment/rag-service --replicas=0",
                    "kubectl scale deployment/user-service --replicas=0"
                ],
                expected_output="Deployments scaled to 0",
                requires_approval=True,
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=5,
                title="Promote Replica to Primary",
                description="Execute replica promotion",
                step_type=StepType.AUTOMATED,
                commands=[
                    "psql -h replica.db.internal -c 'SELECT pg_promote();'",
                    "sleep 10",
                    "psql -h replica.db.internal -c 'SELECT pg_is_in_recovery();'"
                ],
                expected_output="pg_is_in_recovery returns false",
                success_criteria="Replica is now accepting writes",
                rollback_step=13,
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=6,
                title="Update Connection Strings",
                description="Point applications to new primary",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl set env deployment/rag-service DATABASE_HOST=replica.db.internal",
                    "kubectl set env deployment/user-service DATABASE_HOST=replica.db.internal",
                    "kubectl scale deployment/rag-service --replicas=3",
                    "kubectl scale deployment/user-service --replicas=3"
                ],
                expected_output="Deployments updated and scaled",
                success_criteria="Applications connecting to new primary",
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=7,
                title="Identify Latest Backup",
                description="Find the most recent valid backup",
                step_type=StepType.VERIFICATION,
                commands=[
                    "aws s3 ls s3://backups/postgresql/ --recursive | sort -k1,2 | tail -5",
                    "pgbackrest info --stanza=main"
                ],
                expected_output="List of available backups with timestamps",
                success_criteria="Identify backup within RPO",
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=8,
                title="Stop All Database Access",
                description="Prevent connections during restore",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl scale deployment/rag-service --replicas=0",
                    "kubectl scale deployment/user-service --replicas=0",
                    "kubectl scale deployment/document-service --replicas=0"
                ],
                requires_approval=True,
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=9,
                title="Restore from Backup",
                description="Execute backup restoration",
                step_type=StepType.AUTOMATED,
                commands=[
                    "pgbackrest restore --stanza=main --delta --target-timeline=latest",
                    "sudo systemctl start postgresql"
                ],
                expected_output="Restore completed successfully",
                success_criteria="Database service starts without errors",
                estimated_duration_minutes=20
            ),
            RunbookStep(
                step_number=10,
                title="Verify Data Integrity",
                description="Check restored data is valid",
                step_type=StepType.VERIFICATION,
                commands=[
                    "psql -c 'SELECT count(*) FROM documents;'",
                    "psql -c 'SELECT count(*) FROM users;'",
                    "psql -c 'SELECT count(*) FROM embeddings;'"
                ],
                expected_output="Row counts matching expected values",
                success_criteria="Data counts within expected range",
                failure_action="Escalate to DBA lead for investigation",
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=11,
                title="Resume Application Access",
                description="Restore application connectivity",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl scale deployment/rag-service --replicas=3",
                    "kubectl scale deployment/user-service --replicas=3",
                    "kubectl scale deployment/document-service --replicas=3"
                ],
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=12,
                title="Attempt Primary Repair",
                description="Try to repair primary without failover",
                step_type=StepType.MANUAL,
                commands=[
                    "# Check PostgreSQL logs",
                    "kubectl logs -l app=postgresql-primary --tail=100",
                    "# Check disk space",
                    "kubectl exec -it postgresql-primary-0 -- df -h",
                    "# Check connections",
                    "psql -c 'SELECT count(*) FROM pg_stat_activity;'"
                ],
                failure_action="If repair fails, proceed to replica promotion or backup restore",
                estimated_duration_minutes=10
            ),
            RunbookStep(
                step_number=13,
                title="Rollback Promotion",
                description="Revert replica promotion if issues found",
                step_type=StepType.MANUAL,
                commands=[
                    "# This requires manual intervention",
                    "# 1. Stop the promoted replica",
                    "# 2. Restore original primary if possible",
                    "# 3. Reconfigure replication"
                ],
                estimated_duration_minutes=15
            ),
            RunbookStep(
                step_number=14,
                title="Post-Recovery Verification",
                description="Comprehensive verification of database health",
                step_type=StepType.VERIFICATION,
                commands=[
                    "psql -c 'SELECT * FROM pg_stat_replication;'",
                    "curl -s http://rag-service:8080/health | jq '.database'",
                    "curl -s http://user-service:8080/health | jq '.database'"
                ],
                expected_output="All health checks passing",
                success_criteria="Database fully operational",
                estimated_duration_minutes=5
            )
        ],
        post_conditions=[
            "Database is operational and accepting connections",
            "Replication is configured and healthy",
            "All dependent services are running",
            "Backup schedule verified",
            "Incident documented"
        ],
        related_runbooks=[
            "RB-DB-002 (Connection Pool Exhaustion)",
            "RB-DB-003 (Replication Lag Recovery)",
            "RB-DB-004 (Vacuum and Maintenance)"
        ],
        references=[
            "PostgreSQL High Availability Guide",
            "pgBackRest Documentation",
            "Database Architecture Document"
        ],
        changelog=[
            {"date": "2024-01-15", "author": "dba-team", "changes": "Added pgbackrest commands"},
            {"date": "2024-01-01", "author": "dba-team", "changes": "Initial version"}
        ]
    )
```

### 2.3 Vector Store Recovery Runbook

```python
def create_vector_store_recovery_runbook() -> Runbook:
    """Create the vector store recovery runbook."""
    return Runbook(
        metadata=RunbookMetadata(
            runbook_id="RB-VS-001",
            title="Vector Store Recovery and Reindexing",
            description="Procedure for recovering vector store from corruption or rebuilding indices",
            category=RunbookCategory.RECOVERY,
            severity=RunbookSeverity.SEV2,
            services_affected=["vector-store", "rag-service", "embedding-service"],
            triggers=[
                "VectorStoreSearchLatencyHigh",
                "VectorStoreIndexCorrupted",
                "VectorStoreReplicaLag"
            ],
            author="Platform Team",
            created_at=datetime(2024, 1, 1),
            updated_at=datetime(2024, 1, 15),
            version="1.1",
            review_date=datetime(2024, 4, 15),
            approvers=["platform-lead"],
            tags=["vector", "pinecone", "pgvector", "rag"],
            estimated_total_duration_minutes=60,
            requires_change_ticket=True,
            automation_level="semi-automated"
        ),
        prerequisites=[
            "Access to vector store admin console",
            "kubectl access to production",
            "Access to embedding generation service",
            "Source documents available in object storage"
        ],
        steps=[
            RunbookStep(
                step_number=1,
                title="Assess Vector Store Health",
                description="Check current state of vector indices",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl exec -it deploy/vector-store -- curl localhost:8080/health",
                    "kubectl exec -it deploy/vector-store -- vs-cli index-stats",
                    "kubectl exec -it deploy/vector-store -- vs-cli check-integrity"
                ],
                expected_output="Index statistics and integrity status",
                success_criteria="Identify scope of corruption or degradation",
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=2,
                title="Decision: Recovery Type",
                description="Choose recovery strategy based on assessment",
                step_type=StepType.DECISION,
                decision_branches={
                    "partial_reindex": 3,
                    "full_reindex": 6,
                    "failover_to_backup": 10
                },
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=3,
                title="Identify Corrupted Segments",
                description="Find which index segments need reindexing",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/vector-store -- vs-cli list-segments --status corrupted",
                    "kubectl exec -it deploy/vector-store -- vs-cli segment-mapping > /tmp/segments.json"
                ],
                expected_output="List of corrupted segments with document IDs",
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=4,
                title="Reindex Corrupted Segments",
                description="Rebuild corrupted index segments",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/embedding-service -- embed-cli reindex --segments /tmp/segments.json",
                    "kubectl exec -it deploy/vector-store -- vs-cli await-reindex --timeout 30m"
                ],
                expected_output="Reindexing progress and completion",
                success_criteria="All segments successfully reindexed",
                failure_action="Proceed to full reindex if partial fails",
                estimated_duration_minutes=20
            ),
            RunbookStep(
                step_number=5,
                title="Verify Partial Reindex",
                description="Confirm reindexed segments are healthy",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl exec -it deploy/vector-store -- vs-cli check-integrity",
                    "kubectl exec -it deploy/vector-store -- vs-cli query-test --samples 100"
                ],
                expected_output="Integrity check passed, query tests successful",
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=6,
                title="Prepare Full Reindex",
                description="Set up for complete index rebuild",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/vector-store -- vs-cli create-index rag-index-new --config /etc/vector/index-config.yaml",
                    "aws s3 ls s3://documents/embeddings/ --recursive | wc -l"
                ],
                expected_output="New index created, document count confirmed",
                requires_approval=True,
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=7,
                title="Execute Full Reindex",
                description="Rebuild all embeddings from source documents",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/embedding-service -- embed-cli reindex-all --target rag-index-new --parallel 10",
                    "kubectl exec -it deploy/vector-store -- vs-cli await-reindex --timeout 4h"
                ],
                expected_output="Full reindex completion",
                success_criteria="All documents indexed",
                estimated_duration_minutes=120  # Can take hours for large datasets
            ),
            RunbookStep(
                step_number=8,
                title="Swap Index Aliases",
                description="Point production traffic to new index",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/vector-store -- vs-cli alias-swap rag-index rag-index-new",
                    "kubectl exec -it deploy/rag-service -- curl -X POST localhost:8080/admin/refresh-index"
                ],
                expected_output="Alias updated, services refreshed",
                rollback_step=14,
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=9,
                title="Verify Full Reindex",
                description="Comprehensive verification of new index",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl exec -it deploy/vector-store -- vs-cli index-stats rag-index",
                    "curl -X POST http://rag-service:8080/search -d '{\"query\": \"test query\", \"k\": 10}'",
                    "kubectl exec -it deploy/vector-store -- vs-cli query-test --samples 1000"
                ],
                expected_output="Index stats match expected, queries return results",
                estimated_duration_minutes=10
            ),
            RunbookStep(
                step_number=10,
                title="Failover to Backup Store",
                description="Switch to backup vector store instance",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl set env deployment/rag-service VECTOR_STORE_HOST=vector-store-backup.internal",
                    "kubectl rollout status deployment/rag-service --timeout=120s"
                ],
                expected_output="RAG service using backup vector store",
                requires_approval=True,
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=11,
                title="Verify Backup Store",
                description="Confirm backup store is functioning",
                step_type=StepType.VERIFICATION,
                commands=[
                    "curl -X POST http://rag-service:8080/search -d '{\"query\": \"test query\", \"k\": 10}'",
                    "kubectl exec -it deploy/vector-store-backup -- vs-cli health"
                ],
                expected_output="Search returns results from backup",
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=12,
                title="Cleanup Old Index",
                description="Remove old/corrupted index after successful recovery",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/vector-store -- vs-cli delete-index rag-index-old --confirm"
                ],
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=13,
                title="Update Monitoring",
                description="Verify monitoring is tracking new index",
                step_type=StepType.VERIFICATION,
                commands=[
                    "curl http://prometheus:9090/api/v1/query?query=vector_store_index_size",
                    "kubectl exec -it deploy/vector-store -- vs-cli metrics"
                ],
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=14,
                title="Rollback Index Swap",
                description="Revert to previous index if issues found",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl exec -it deploy/vector-store -- vs-cli alias-swap rag-index rag-index-old",
                    "kubectl exec -it deploy/rag-service -- curl -X POST localhost:8080/admin/refresh-index"
                ],
                estimated_duration_minutes=2
            )
        ],
        post_conditions=[
            "Vector store is operational with acceptable latency",
            "Search quality verified with test queries",
            "All RAG-dependent services functioning",
            "Old indices cleaned up",
            "Monitoring confirmed"
        ],
        related_runbooks=[
            "RB-VS-002 (Vector Store Scaling)",
            "RB-EMB-001 (Embedding Service Recovery)",
            "RB-RAG-001 (RAG Pipeline Troubleshooting)"
        ],
        references=[
            "Vector Store Architecture",
            "Embedding Pipeline Documentation",
            "RAG Service Configuration Guide"
        ],
        changelog=[
            {"date": "2024-01-15", "author": "platform-team", "changes": "Added parallel reindexing option"},
            {"date": "2024-01-01", "author": "platform-team", "changes": "Initial version"}
        ]
    )
```

## 3. Maintenance Runbooks

### 3.1 Kubernetes Cluster Upgrade Runbook

```python
def create_k8s_upgrade_runbook() -> Runbook:
    """Create the Kubernetes cluster upgrade runbook."""
    return Runbook(
        metadata=RunbookMetadata(
            runbook_id="RB-K8S-001",
            title="Kubernetes Cluster Upgrade",
            description="Procedure for upgrading Kubernetes cluster version",
            category=RunbookCategory.MAINTENANCE,
            severity=RunbookSeverity.ALL,
            services_affected=["all"],
            triggers=["Scheduled maintenance", "Security patch required"],
            author="Platform Team",
            created_at=datetime(2024, 1, 1),
            updated_at=datetime(2024, 1, 15),
            version="1.3",
            review_date=datetime(2024, 4, 15),
            approvers=["platform-manager", "security-lead"],
            tags=["kubernetes", "upgrade", "maintenance"],
            estimated_total_duration_minutes=180,
            requires_change_ticket=True,
            automation_level="semi-automated"
        ),
        prerequisites=[
            "Change ticket approved",
            "Maintenance window scheduled",
            "Backup of etcd completed",
            "All nodes healthy",
            "kubectl admin access"
        ],
        steps=[
            RunbookStep(
                step_number=1,
                title="Pre-Upgrade Validation",
                description="Verify cluster is ready for upgrade",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl get nodes -o wide",
                    "kubectl get pods --all-namespaces | grep -v Running",
                    "kubectl cluster-info",
                    "kubectl version --short"
                ],
                expected_output="All nodes Ready, no failing pods",
                success_criteria="Cluster is healthy",
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=2,
                title="Backup etcd",
                description="Create etcd backup before upgrade",
                step_type=StepType.AUTOMATED,
                commands=[
                    "ETCDCTL_API=3 etcdctl snapshot save /backup/etcd-$(date +%Y%m%d-%H%M%S).db",
                    "aws s3 cp /backup/etcd-*.db s3://backups/etcd/"
                ],
                expected_output="Backup created and uploaded",
                success_criteria="Backup file exists and is valid",
                estimated_duration_minutes=10
            ),
            RunbookStep(
                step_number=3,
                title="Upgrade Control Plane",
                description="Upgrade control plane components",
                step_type=StepType.AUTOMATED,
                commands=[
                    "# For EKS",
                    "aws eks update-cluster-version --name production --kubernetes-version 1.28",
                    "aws eks wait cluster-active --name production",
                    "",
                    "# For GKE",
                    "gcloud container clusters upgrade production --master --cluster-version 1.28"
                ],
                expected_output="Control plane upgraded",
                requires_approval=True,
                estimated_duration_minutes=30
            ),
            RunbookStep(
                step_number=4,
                title="Verify Control Plane",
                description="Confirm control plane is healthy after upgrade",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl version --short",
                    "kubectl get componentstatuses",
                    "kubectl get nodes"
                ],
                expected_output="Server version matches target, components healthy",
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=5,
                title="Cordon First Node Group",
                description="Prepare first node group for upgrade",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl cordon -l node-group=workers-a",
                    "kubectl drain -l node-group=workers-a --ignore-daemonsets --delete-emptydir-data"
                ],
                expected_output="Nodes cordoned and drained",
                estimated_duration_minutes=15
            ),
            RunbookStep(
                step_number=6,
                title="Upgrade First Node Group",
                description="Upgrade worker nodes in first group",
                step_type=StepType.AUTOMATED,
                commands=[
                    "# For EKS",
                    "aws eks update-nodegroup-version --cluster-name production --nodegroup-name workers-a --kubernetes-version 1.28",
                    "",
                    "# Wait for completion",
                    "aws eks wait nodegroup-active --cluster-name production --nodegroup-name workers-a"
                ],
                expected_output="Node group upgraded",
                estimated_duration_minutes=20
            ),
            RunbookStep(
                step_number=7,
                title="Verify First Node Group",
                description="Confirm first node group is healthy",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl get nodes -l node-group=workers-a",
                    "kubectl uncordon -l node-group=workers-a",
                    "kubectl get pods --field-selector spec.nodeName=workers-a-node1"
                ],
                expected_output="Nodes Ready, pods running",
                failure_action="Pause upgrade, investigate issues",
                estimated_duration_minutes=10
            ),
            RunbookStep(
                step_number=8,
                title="Upgrade Remaining Node Groups",
                description="Repeat upgrade process for remaining node groups",
                step_type=StepType.AUTOMATED,
                commands=[
                    "# Repeat steps 5-7 for each node group",
                    "for ng in workers-b workers-c; do",
                    "  kubectl cordon -l node-group=$ng",
                    "  kubectl drain -l node-group=$ng --ignore-daemonsets --delete-emptydir-data",
                    "  aws eks update-nodegroup-version --cluster-name production --nodegroup-name $ng --kubernetes-version 1.28",
                    "  aws eks wait nodegroup-active --cluster-name production --nodegroup-name $ng",
                    "  kubectl uncordon -l node-group=$ng",
                    "done"
                ],
                estimated_duration_minutes=60
            ),
            RunbookStep(
                step_number=9,
                title="Update Cluster Add-ons",
                description="Upgrade cluster add-ons to compatible versions",
                step_type=StepType.AUTOMATED,
                commands=[
                    "helm upgrade --install aws-load-balancer-controller eks/aws-load-balancer-controller -n kube-system",
                    "helm upgrade --install cluster-autoscaler autoscaler/cluster-autoscaler -n kube-system",
                    "helm upgrade --install metrics-server metrics-server/metrics-server -n kube-system"
                ],
                expected_output="Add-ons upgraded",
                estimated_duration_minutes=15
            ),
            RunbookStep(
                step_number=10,
                title="Final Verification",
                description="Comprehensive verification of upgraded cluster",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl get nodes -o wide",
                    "kubectl get pods --all-namespaces | grep -v Running",
                    "kubectl run test-pod --image=nginx --rm -it --restart=Never -- echo 'Cluster working'",
                    "curl -s http://rag-service:8080/health"
                ],
                expected_output="All nodes upgraded, all services healthy",
                estimated_duration_minutes=10
            )
        ],
        post_conditions=[
            "All nodes running target Kubernetes version",
            "All pods healthy",
            "All services accessible",
            "Monitoring confirmed",
            "Documentation updated"
        ],
        related_runbooks=[
            "RB-K8S-002 (Node Replacement)",
            "RB-K8S-003 (etcd Recovery)"
        ],
        references=[
            "EKS Upgrade Documentation",
            "Kubernetes Release Notes",
            "Add-on Compatibility Matrix"
        ],
        changelog=[
            {"date": "2024-01-15", "author": "platform-team", "changes": "Updated for EKS 1.28"},
            {"date": "2024-01-01", "author": "platform-team", "changes": "Initial version"}
        ]
    )
```

### 3.2 Certificate Rotation Runbook

```python
def create_certificate_rotation_runbook() -> Runbook:
    """Create the certificate rotation runbook."""
    return Runbook(
        metadata=RunbookMetadata(
            runbook_id="RB-SEC-001",
            title="TLS Certificate Rotation",
            description="Procedure for rotating TLS certificates across services",
            category=RunbookCategory.SECURITY,
            severity=RunbookSeverity.SEV2,
            services_affected=["ingress", "api-gateway", "internal-services"],
            triggers=[
                "Certificate expiration warning",
                "Security audit requirement",
                "Certificate compromise"
            ],
            author="Security Team",
            created_at=datetime(2024, 1, 1),
            updated_at=datetime(2024, 1, 15),
            version="1.1",
            review_date=datetime(2024, 4, 15),
            approvers=["security-lead", "platform-lead"],
            tags=["security", "certificates", "tls"],
            estimated_total_duration_minutes=45,
            requires_change_ticket=True,
            automation_level="semi-automated"
        ),
        prerequisites=[
            "Access to certificate management system",
            "New certificates generated or ready to generate",
            "kubectl access to all clusters",
            "DNS management access"
        ],
        steps=[
            RunbookStep(
                step_number=1,
                title="Audit Current Certificates",
                description="Review all certificates and their expiration dates",
                step_type=StepType.VERIFICATION,
                commands=[
                    "kubectl get certificates -A",
                    "kubectl get secrets -A -o json | jq '.items[] | select(.type==\"kubernetes.io/tls\") | .metadata.name'",
                    "openssl x509 -in /tmp/current-cert.pem -noout -dates"
                ],
                expected_output="List of certificates with expiration dates",
                success_criteria="Identify all certificates requiring rotation",
                estimated_duration_minutes=10
            ),
            RunbookStep(
                step_number=2,
                title="Generate New Certificates",
                description="Generate or request new certificates",
                step_type=StepType.AUTOMATED,
                commands=[
                    "# If using cert-manager",
                    "kubectl annotate certificate production-tls cert-manager.io/renew=true",
                    "",
                    "# If manual generation",
                    "openssl req -new -newkey rsa:4096 -nodes -keyout new-key.pem -out new-csr.pem -config cert.conf",
                    "# Submit CSR to CA"
                ],
                expected_output="New certificate and key generated",
                requires_approval=True,
                estimated_duration_minutes=10
            ),
            RunbookStep(
                step_number=3,
                title="Validate New Certificates",
                description="Verify new certificates are valid",
                step_type=StepType.VERIFICATION,
                commands=[
                    "openssl x509 -in new-cert.pem -text -noout",
                    "openssl verify -CAfile ca-chain.pem new-cert.pem",
                    "openssl x509 -in new-cert.pem -noout -checkend 86400"
                ],
                expected_output="Certificate valid, chain verified",
                success_criteria="Certificate passes all validation",
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=4,
                title="Update Kubernetes Secrets",
                description="Deploy new certificates to clusters",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl create secret tls production-tls-new --cert=new-cert.pem --key=new-key.pem -n ingress",
                    "kubectl label secret production-tls-new app=ingress rotation-date=$(date +%Y%m%d)"
                ],
                expected_output="Secret created",
                rollback_step=8,
                estimated_duration_minutes=3
            ),
            RunbookStep(
                step_number=5,
                title="Update Ingress Configuration",
                description="Point ingress to new certificate",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl patch ingress production-ingress -n ingress --type=json -p='[{\"op\": \"replace\", \"path\": \"/spec/tls/0/secretName\", \"value\": \"production-tls-new\"}]'"
                ],
                expected_output="Ingress patched",
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=6,
                title="Verify Certificate Deployment",
                description="Confirm new certificate is being served",
                step_type=StepType.VERIFICATION,
                commands=[
                    "curl -v https://api.example.com 2>&1 | grep 'expire date'",
                    "openssl s_client -connect api.example.com:443 -servername api.example.com 2>/dev/null | openssl x509 -noout -dates"
                ],
                expected_output="New certificate expiration date shown",
                success_criteria="New certificate being served",
                failure_action="Rollback to previous certificate",
                estimated_duration_minutes=5
            ),
            RunbookStep(
                step_number=7,
                title="Clean Up Old Certificates",
                description="Remove old certificate secrets after successful rotation",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl delete secret production-tls-old -n ingress",
                    "kubectl rename secret production-tls production-tls-old -n ingress || true",
                    "kubectl rename secret production-tls-new production-tls -n ingress"
                ],
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=8,
                title="Rollback Certificate",
                description="Revert to previous certificate if issues found",
                step_type=StepType.AUTOMATED,
                commands=[
                    "kubectl patch ingress production-ingress -n ingress --type=json -p='[{\"op\": \"replace\", \"path\": \"/spec/tls/0/secretName\", \"value\": \"production-tls-old\"}]'"
                ],
                estimated_duration_minutes=2
            ),
            RunbookStep(
                step_number=9,
                title="Update Monitoring",
                description="Ensure certificate monitoring is tracking new cert",
                step_type=StepType.VERIFICATION,
                commands=[
                    "curl http://prometheus:9090/api/v1/query?query=ssl_certificate_expiry_seconds",
                    "kubectl logs -l app=cert-exporter -n monitoring --tail=20"
                ],
                expected_output="Monitoring shows new certificate expiration",
                estimated_duration_minutes=3
            )
        ],
        post_conditions=[
            "New certificate deployed and serving traffic",
            "Old certificate backed up or removed",
            "Monitoring tracking new certificate",
            "Documentation updated with new expiration date"
        ],
        related_runbooks=[
            "RB-SEC-002 (CA Certificate Update)",
            "RB-SEC-003 (mTLS Configuration)"
        ],
        references=[
            "Certificate Management Policy",
            "cert-manager Documentation",
            "PKI Architecture Document"
        ],
        changelog=[
            {"date": "2024-01-15", "author": "security-team", "changes": "Added cert-manager integration"},
            {"date": "2024-01-01", "author": "security-team", "changes": "Initial version"}
        ]
    )
```

## 4. Runbook Automation

### 4.1 Automation Registry

```python
from typing import Dict, Callable, Any, Optional
from dataclasses import dataclass
import asyncio
import subprocess


@dataclass
class AutomationResult:
    """Result of an automation execution."""
    success: bool
    output: str
    error: Optional[str] = None
    duration_seconds: float = 0


class Automation:
    """Base class for runbook automations."""

    def __init__(self, name: str, description: str):
        self.name = name
        self.description = description

    async def execute(self, variables: Dict[str, Any]) -> AutomationResult:
        """Execute the automation."""
        raise NotImplementedError

    async def validate(self, variables: Dict[str, Any]) -> bool:
        """Validate prerequisites before execution."""
        return True

    async def rollback(self, variables: Dict[str, Any]) -> AutomationResult:
        """Rollback the automation if supported."""
        return AutomationResult(
            success=False,
            output="Rollback not supported",
            error="Not implemented"
        )


class ShellAutomation(Automation):
    """Automation that executes shell commands."""

    def __init__(
        self,
        name: str,
        description: str,
        commands: list[str],
        timeout_seconds: int = 300
    ):
        super().__init__(name, description)
        self.commands = commands
        self.timeout_seconds = timeout_seconds

    async def execute(self, variables: Dict[str, Any]) -> AutomationResult:
        import time
        start = time.time()

        outputs = []
        try:
            for cmd in self.commands:
                # Substitute variables
                formatted_cmd = cmd.format(**variables)

                result = subprocess.run(
                    formatted_cmd,
                    shell=True,
                    capture_output=True,
                    text=True,
                    timeout=self.timeout_seconds
                )

                outputs.append(f"$ {formatted_cmd}\n{result.stdout}")

                if result.returncode != 0:
                    return AutomationResult(
                        success=False,
                        output="\n".join(outputs),
                        error=result.stderr,
                        duration_seconds=time.time() - start
                    )

            return AutomationResult(
                success=True,
                output="\n".join(outputs),
                duration_seconds=time.time() - start
            )

        except subprocess.TimeoutExpired:
            return AutomationResult(
                success=False,
                output="\n".join(outputs),
                error="Command timed out",
                duration_seconds=time.time() - start
            )
        except Exception as e:
            return AutomationResult(
                success=False,
                output="\n".join(outputs),
                error=str(e),
                duration_seconds=time.time() - start
            )


class KubernetesAutomation(Automation):
    """Automation that interacts with Kubernetes."""

    def __init__(
        self,
        name: str,
        description: str,
        operations: list[Dict]
    ):
        super().__init__(name, description)
        self.operations = operations

    async def execute(self, variables: Dict[str, Any]) -> AutomationResult:
        from kubernetes import client, config
        import time

        start = time.time()
        outputs = []

        try:
            config.load_incluster_config()
        except:
            config.load_kube_config()

        v1 = client.CoreV1Api()
        apps_v1 = client.AppsV1Api()

        try:
            for op in self.operations:
                op_type = op["type"]
                result = ""

                if op_type == "scale_deployment":
                    name = op["name"].format(**variables)
                    namespace = op.get("namespace", "default")
                    replicas = op["replicas"]

                    apps_v1.patch_namespaced_deployment_scale(
                        name=name,
                        namespace=namespace,
                        body={"spec": {"replicas": replicas}}
                    )
                    result = f"Scaled {name} to {replicas} replicas"

                elif op_type == "restart_deployment":
                    name = op["name"].format(**variables)
                    namespace = op.get("namespace", "default")

                    apps_v1.patch_namespaced_deployment(
                        name=name,
                        namespace=namespace,
                        body={
                            "spec": {
                                "template": {
                                    "metadata": {
                                        "annotations": {
                                            "kubectl.kubernetes.io/restartedAt": datetime.utcnow().isoformat()
                                        }
                                    }
                                }
                            }
                        }
                    )
                    result = f"Restarted deployment {name}"

                elif op_type == "update_configmap":
                    name = op["name"].format(**variables)
                    namespace = op.get("namespace", "default")
                    data = {k: v.format(**variables) for k, v in op["data"].items()}

                    v1.patch_namespaced_config_map(
                        name=name,
                        namespace=namespace,
                        body={"data": data}
                    )
                    result = f"Updated configmap {name}"

                outputs.append(result)

            return AutomationResult(
                success=True,
                output="\n".join(outputs),
                duration_seconds=time.time() - start
            )

        except Exception as e:
            return AutomationResult(
                success=False,
                output="\n".join(outputs),
                error=str(e),
                duration_seconds=time.time() - start
            )


class AutomationRegistry:
    """Registry of available automations."""

    def __init__(self):
        self.automations: Dict[str, Automation] = {}
        self._register_defaults()

    def _register_defaults(self):
        """Register default automations."""
        self.register(ShellAutomation(
            name="llm_provider_failover",
            description="Failover LLM provider",
            commands=[
                "kubectl set env deployment/llm-gateway LLM_PRIMARY_PROVIDER={target_provider}",
                "kubectl rollout status deployment/llm-gateway --timeout=120s"
            ]
        ))

        self.register(KubernetesAutomation(
            name="scale_service",
            description="Scale a service deployment",
            operations=[
                {
                    "type": "scale_deployment",
                    "name": "{deployment_name}",
                    "namespace": "{namespace}",
                    "replicas": "{replicas}"
                }
            ]
        ))

        self.register(ShellAutomation(
            name="database_failover",
            description="Promote database replica",
            commands=[
                "psql -h {replica_host} -c 'SELECT pg_promote();'",
                "sleep 10",
                "psql -h {replica_host} -c 'SELECT pg_is_in_recovery();'"
            ]
        ))

    def register(self, automation: Automation):
        """Register an automation."""
        self.automations[automation.name] = automation

    def get(self, name: str) -> Optional[Automation]:
        """Get an automation by name."""
        return self.automations.get(name)

    def list_automations(self) -> List[Dict]:
        """List all registered automations."""
        return [
            {"name": a.name, "description": a.description}
            for a in self.automations.values()
        ]
```

### 4.2 Runbook Testing Framework

```python
from dataclasses import dataclass
from typing import Dict, List, Optional
from datetime import datetime


@dataclass
class RunbookTestCase:
    """Test case for a runbook."""
    test_id: str
    runbook_id: str
    description: str
    scenario: str
    input_variables: Dict
    expected_outcomes: List[str]
    mock_responses: Dict[int, str]  # step number -> mock output


@dataclass
class RunbookTestResult:
    """Result of a runbook test."""
    test_id: str
    passed: bool
    executed_steps: List[int]
    step_results: Dict[int, Dict]
    errors: List[str]
    duration_seconds: float


class RunbookTestRunner:
    """Run tests against runbooks in a safe environment."""

    def __init__(
        self,
        repository: RunbookRepository,
        executor: RunbookExecutor
    ):
        self.repository = repository
        self.executor = executor
        self.test_results: List[RunbookTestResult] = []

    async def run_test(
        self,
        test_case: RunbookTestCase,
        dry_run: bool = True
    ) -> RunbookTestResult:
        """Run a single runbook test case."""
        import time
        start = time.time()

        runbook = self.repository.get_runbook(test_case.runbook_id)
        if not runbook:
            return RunbookTestResult(
                test_id=test_case.test_id,
                passed=False,
                executed_steps=[],
                step_results={},
                errors=[f"Runbook {test_case.runbook_id} not found"],
                duration_seconds=time.time() - start
            )

        executed_steps = []
        step_results = {}
        errors = []

        try:
            # Start execution
            execution = await self.executor.start_execution(
                test_case.runbook_id,
                "test-runner",
                variables=test_case.input_variables
            )

            # Execute each step
            for step in runbook.steps:
                step_num = step.step_number

                if dry_run and step_num in test_case.mock_responses:
                    # Use mock response in dry run
                    result = {
                        "status": "completed",
                        "output": test_case.mock_responses[step_num]
                    }
                else:
                    # Actually execute the step
                    step_exec = await self.executor.execute_step(
                        execution.execution_id,
                        "test-runner",
                        skip_automation=dry_run
                    )
                    result = {
                        "status": step_exec.status.value,
                        "output": step_exec.output,
                        "error": step_exec.error
                    }

                executed_steps.append(step_num)
                step_results[step_num] = result

                if result.get("error"):
                    errors.append(f"Step {step_num}: {result['error']}")

                # Handle decision branches in test
                if step.step_type == StepType.DECISION:
                    # Determine which branch based on scenario
                    branch = self._get_test_branch(test_case.scenario, step)
                    if branch:
                        await self.executor.select_decision_branch(
                            execution.execution_id,
                            branch,
                            "test-runner"
                        )

        except Exception as e:
            errors.append(str(e))

        # Verify outcomes
        outcomes_met = self._verify_outcomes(test_case.expected_outcomes, step_results)
        passed = len(errors) == 0 and outcomes_met

        result = RunbookTestResult(
            test_id=test_case.test_id,
            passed=passed,
            executed_steps=executed_steps,
            step_results=step_results,
            errors=errors,
            duration_seconds=time.time() - start
        )

        self.test_results.append(result)
        return result

    def _get_test_branch(
        self,
        scenario: str,
        step: RunbookStep
    ) -> Optional[str]:
        """Determine which branch to take based on test scenario."""
        # Implementation would map scenarios to branches
        scenario_mappings = {
            "complete_outage": "complete_outage",
            "degraded": "degraded_performance",
            "intermittent": "intermittent_errors"
        }
        return scenario_mappings.get(scenario)

    def _verify_outcomes(
        self,
        expected: List[str],
        results: Dict[int, Dict]
    ) -> bool:
        """Verify that expected outcomes were achieved."""
        for outcome in expected:
            # Simple string matching - could be more sophisticated
            found = False
            for step_result in results.values():
                if outcome.lower() in str(step_result.get("output", "")).lower():
                    found = True
                    break
            if not found:
                return False
        return True

    async def run_all_tests(
        self,
        test_cases: List[RunbookTestCase],
        dry_run: bool = True
    ) -> Dict:
        """Run all test cases."""
        results = []
        for test_case in test_cases:
            result = await self.run_test(test_case, dry_run)
            results.append(result)

        passed = sum(1 for r in results if r.passed)
        failed = len(results) - passed

        return {
            "total_tests": len(results),
            "passed": passed,
            "failed": failed,
            "pass_rate": passed / len(results) * 100 if results else 0,
            "results": [
                {
                    "test_id": r.test_id,
                    "passed": r.passed,
                    "duration": r.duration_seconds,
                    "errors": r.errors
                }
                for r in results
            ]
        }

    def generate_test_report(self) -> str:
        """Generate a test report."""
        report = "# Runbook Test Report\n\n"
        report += f"**Generated**: {datetime.utcnow().isoformat()}\n\n"

        passed = sum(1 for r in self.test_results if r.passed)
        total = len(self.test_results)

        report += f"## Summary\n\n"
        report += f"- Total Tests: {total}\n"
        report += f"- Passed: {passed}\n"
        report += f"- Failed: {total - passed}\n"
        report += f"- Pass Rate: {passed/total*100:.1f}%\n\n"

        report += "## Test Results\n\n"
        for result in self.test_results:
            status = "PASS" if result.passed else "FAIL"
            report += f"### {result.test_id}: {status}\n\n"
            report += f"- Duration: {result.duration_seconds:.2f}s\n"
            report += f"- Steps Executed: {len(result.executed_steps)}\n"

            if result.errors:
                report += "- Errors:\n"
                for error in result.errors:
                    report += f"  - {error}\n"

            report += "\n"

        return report
```

## 5. Runbook Documentation Generator

### 5.1 Documentation Export

```python
from typing import List
import os


class RunbookDocumentationGenerator:
    """Generate documentation from runbooks."""

    def __init__(self, repository: RunbookRepository):
        self.repository = repository

    def generate_runbook_index(self) -> str:
        """Generate an index of all runbooks."""
        md = "# Runbook Index\n\n"

        # Group by category
        by_category: Dict[RunbookCategory, List[Runbook]] = {}
        for runbook in self.repository.runbooks.values():
            cat = runbook.metadata.category
            if cat not in by_category:
                by_category[cat] = []
            by_category[cat].append(runbook)

        for category, runbooks in sorted(by_category.items(), key=lambda x: x[0].value):
            md += f"## {category.value.replace('_', ' ').title()}\n\n"
            md += "| ID | Title | Severity | Services | Est. Duration |\n"
            md += "|----|-------|----------|----------|---------------|\n"

            for rb in sorted(runbooks, key=lambda x: x.metadata.runbook_id):
                services = ", ".join(rb.metadata.services_affected[:3])
                if len(rb.metadata.services_affected) > 3:
                    services += "..."
                md += f"| [{rb.metadata.runbook_id}]({rb.metadata.runbook_id}.md) "
                md += f"| {rb.metadata.title} "
                md += f"| {rb.metadata.severity.value} "
                md += f"| {services} "
                md += f"| {rb.metadata.estimated_total_duration_minutes} min |\n"

            md += "\n"

        return md

    def generate_quick_reference(self) -> str:
        """Generate a quick reference card for common scenarios."""
        md = "# Runbook Quick Reference\n\n"

        # Common scenarios
        scenarios = {
            "LLM Provider Issues": [
                ("Provider returning errors", "RB-LLM-001"),
                ("High latency", "RB-LLM-001"),
                ("Rate limits exceeded", "RB-LLM-002")
            ],
            "Database Issues": [
                ("Primary unreachable", "RB-DB-001"),
                ("High replication lag", "RB-DB-003"),
                ("Connection pool exhausted", "RB-DB-002")
            ],
            "Vector Store Issues": [
                ("Search latency high", "RB-VS-001"),
                ("Index corruption", "RB-VS-001"),
                ("Reindexing needed", "RB-VS-001")
            ],
            "Infrastructure": [
                ("Pod crashes", "RB-K8S-004"),
                ("Node not ready", "RB-K8S-002"),
                ("Certificate expiring", "RB-SEC-001")
            ]
        }

        for scenario_group, items in scenarios.items():
            md += f"## {scenario_group}\n\n"
            md += "| Symptom | Runbook |\n"
            md += "|---------|----------|\n"
            for symptom, runbook_id in items:
                rb = self.repository.get_runbook(runbook_id)
                if rb:
                    md += f"| {symptom} | [{runbook_id}]({runbook_id}.md) - {rb.metadata.title} |\n"
            md += "\n"

        return md

    def export_all_runbooks(self, output_dir: str):
        """Export all runbooks to markdown files."""
        os.makedirs(output_dir, exist_ok=True)

        # Generate index
        with open(os.path.join(output_dir, "README.md"), "w") as f:
            f.write(self.generate_runbook_index())

        # Generate quick reference
        with open(os.path.join(output_dir, "QUICK_REFERENCE.md"), "w") as f:
            f.write(self.generate_quick_reference())

        # Export individual runbooks
        for runbook in self.repository.runbooks.values():
            filename = f"{runbook.metadata.runbook_id}.md"
            with open(os.path.join(output_dir, filename), "w") as f:
                f.write(runbook.to_markdown())
```

## Troubleshooting

### Common Runbook Issues

| Issue | Cause | Resolution |
|-------|-------|------------|
| Step execution fails | Command error | Check command syntax, verify access |
| Automation not found | Unregistered automation | Register automation in registry |
| Variable substitution fails | Missing variable | Ensure all required variables provided |
| Approval timeout | Approver unavailable | Escalate or find alternate approver |
| Rollback fails | Incompatible state | Manual intervention required |

### Runbook Best Practices

1. **Keep steps atomic** - Each step should do one thing
2. **Include verification** - Always verify after critical actions
3. **Document rollback** - Every change should have a rollback
4. **Test regularly** - Run test cases monthly
5. **Update promptly** - Update runbooks after incidents

## Related Documentation

- [13.1 Incident Response Guide](13.1_incident_response_guide.md)
- [13.4 On-Call Practices Guide](13.4_on_call_practices_guide.md)
- [13.2 Disaster Recovery Guide](13.2_disaster_recovery_guide.md)

## Version History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2024-01-15 | Platform Team | Initial release |
