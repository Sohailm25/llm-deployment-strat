# 13.2 Disaster Recovery Guide

## Document Information
- **Version**: 1.0
- **Last Updated**: 2024
- **Owner**: Site Reliability Engineering Team
- **Classification**: Internal

## Purpose and Scope

This guide provides comprehensive frameworks for disaster recovery planning, implementation, and testing for LLM platforms. Effective DR ensures business continuity, minimizes data loss, and maintains service availability during catastrophic failures.

## Prerequisites

- Understanding of distributed systems and replication
- Familiarity with cloud infrastructure (AWS, GCP, Azure)
- Knowledge of database backup and recovery
- Access to infrastructure management tools

---

## 1. Disaster Recovery Fundamentals

### 1.1 Recovery Objectives and Classification

```python
"""
Disaster recovery objectives and tier classification.
"""

from enum import Enum
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta


class DisasterType(Enum):
    """Types of disasters."""
    REGIONAL_OUTAGE = "regional_outage"
    DATA_CENTER_FAILURE = "data_center_failure"
    NETWORK_PARTITION = "network_partition"
    DATA_CORRUPTION = "data_corruption"
    SECURITY_BREACH = "security_breach"
    PROVIDER_OUTAGE = "provider_outage"
    NATURAL_DISASTER = "natural_disaster"
    HUMAN_ERROR = "human_error"


class RecoveryTier(Enum):
    """Recovery tier classification."""
    TIER_1 = "tier_1"  # Mission critical - minutes
    TIER_2 = "tier_2"  # Business critical - hours
    TIER_3 = "tier_3"  # Business operational - day
    TIER_4 = "tier_4"  # Non-critical - days


@dataclass
class RecoveryObjectives:
    """Recovery objectives for a service or system."""
    service_name: str
    tier: RecoveryTier
    rto_minutes: int  # Recovery Time Objective
    rpo_minutes: int  # Recovery Point Objective
    mtpd_hours: int   # Maximum Tolerable Period of Disruption
    dependencies: List[str] = field(default_factory=list)
    data_classification: str = "standard"
    compliance_requirements: List[str] = field(default_factory=list)


class RecoveryObjectivesMatrix:
    """
    Define and manage recovery objectives across services.
    """

    def __init__(self):
        self.objectives: Dict[str, RecoveryObjectives] = {}
        self._load_default_objectives()

    def _load_default_objectives(self) -> None:
        """Load default recovery objectives for LLM platform."""
        defaults = [
            RecoveryObjectives(
                service_name="api-gateway",
                tier=RecoveryTier.TIER_1,
                rto_minutes=15,
                rpo_minutes=5,
                mtpd_hours=4,
                dependencies=["authentication", "rate-limiter", "model-router"],
                data_classification="standard"
            ),
            RecoveryObjectives(
                service_name="model-router",
                tier=RecoveryTier.TIER_1,
                rto_minutes=15,
                rpo_minutes=5,
                mtpd_hours=4,
                dependencies=["provider-connectors", "cache"],
                data_classification="standard"
            ),
            RecoveryObjectives(
                service_name="authentication",
                tier=RecoveryTier.TIER_1,
                rto_minutes=15,
                rpo_minutes=1,
                mtpd_hours=2,
                dependencies=["user-database", "token-store"],
                data_classification="sensitive",
                compliance_requirements=["SOC2", "GDPR"]
            ),
            RecoveryObjectives(
                service_name="user-database",
                tier=RecoveryTier.TIER_1,
                rto_minutes=30,
                rpo_minutes=1,
                mtpd_hours=4,
                dependencies=[],
                data_classification="sensitive",
                compliance_requirements=["SOC2", "GDPR", "PCI-DSS"]
            ),
            RecoveryObjectives(
                service_name="vector-database",
                tier=RecoveryTier.TIER_2,
                rto_minutes=60,
                rpo_minutes=15,
                mtpd_hours=8,
                dependencies=[],
                data_classification="standard"
            ),
            RecoveryObjectives(
                service_name="analytics-database",
                tier=RecoveryTier.TIER_3,
                rto_minutes=240,
                rpo_minutes=60,
                mtpd_hours=24,
                dependencies=[],
                data_classification="internal"
            ),
            RecoveryObjectives(
                service_name="dashboard",
                tier=RecoveryTier.TIER_2,
                rto_minutes=60,
                rpo_minutes=30,
                mtpd_hours=8,
                dependencies=["api-gateway", "authentication"],
                data_classification="standard"
            ),
            RecoveryObjectives(
                service_name="billing-service",
                tier=RecoveryTier.TIER_1,
                rto_minutes=30,
                rpo_minutes=1,
                mtpd_hours=4,
                dependencies=["billing-database"],
                data_classification="sensitive",
                compliance_requirements=["PCI-DSS", "SOC2"]
            ),
            RecoveryObjectives(
                service_name="webhook-service",
                tier=RecoveryTier.TIER_2,
                rto_minutes=60,
                rpo_minutes=15,
                mtpd_hours=8,
                dependencies=["webhook-queue"],
                data_classification="standard"
            ),
            RecoveryObjectives(
                service_name="logging-service",
                tier=RecoveryTier.TIER_3,
                rto_minutes=120,
                rpo_minutes=30,
                mtpd_hours=24,
                dependencies=["log-storage"],
                data_classification="internal"
            )
        ]

        for obj in defaults:
            self.objectives[obj.service_name] = obj

    def get_objectives(self, service_name: str) -> Optional[RecoveryObjectives]:
        """Get recovery objectives for a service."""
        return self.objectives.get(service_name)

    def get_services_by_tier(self, tier: RecoveryTier) -> List[str]:
        """Get all services in a recovery tier."""
        return [
            name for name, obj in self.objectives.items()
            if obj.tier == tier
        ]

    def get_recovery_order(self) -> List[List[str]]:
        """Get ordered list of services for recovery."""
        # Group by tier
        tiers = {tier: [] for tier in RecoveryTier}
        for name, obj in self.objectives.items():
            tiers[obj.tier].append(name)

        # Return in order
        return [
            tiers[RecoveryTier.TIER_1],
            tiers[RecoveryTier.TIER_2],
            tiers[RecoveryTier.TIER_3],
            tiers[RecoveryTier.TIER_4]
        ]

    def validate_dependencies(self) -> List[str]:
        """Validate that all dependencies are defined."""
        issues = []
        all_services = set(self.objectives.keys())

        for name, obj in self.objectives.items():
            for dep in obj.dependencies:
                if dep not in all_services:
                    issues.append(f"{name} depends on undefined service: {dep}")

        return issues


@dataclass
class DRStrategy:
    """Disaster recovery strategy configuration."""
    strategy_type: str  # active-active, active-passive, pilot-light, backup-restore
    primary_region: str
    dr_regions: List[str]
    failover_mode: str  # automatic, manual, semi-automatic
    data_replication: str  # synchronous, asynchronous
    replication_lag_tolerance_seconds: int
    health_check_interval_seconds: int
    failover_threshold_failures: int
    failback_mode: str  # automatic, manual


class DRStrategyManager:
    """
    Manage disaster recovery strategies.
    """

    def __init__(self):
        self.strategies: Dict[str, DRStrategy] = {}
        self._load_default_strategies()

    def _load_default_strategies(self) -> None:
        """Load default DR strategies."""
        self.strategies = {
            "api-tier": DRStrategy(
                strategy_type="active-active",
                primary_region="us-east-1",
                dr_regions=["us-west-2", "eu-west-1"],
                failover_mode="automatic",
                data_replication="asynchronous",
                replication_lag_tolerance_seconds=30,
                health_check_interval_seconds=10,
                failover_threshold_failures=3,
                failback_mode="manual"
            ),
            "database-tier": DRStrategy(
                strategy_type="active-passive",
                primary_region="us-east-1",
                dr_regions=["us-west-2"],
                failover_mode="semi-automatic",
                data_replication="synchronous",
                replication_lag_tolerance_seconds=5,
                health_check_interval_seconds=5,
                failover_threshold_failures=5,
                failback_mode="manual"
            ),
            "cache-tier": DRStrategy(
                strategy_type="active-active",
                primary_region="us-east-1",
                dr_regions=["us-west-2", "eu-west-1"],
                failover_mode="automatic",
                data_replication="asynchronous",
                replication_lag_tolerance_seconds=60,
                health_check_interval_seconds=5,
                failover_threshold_failures=2,
                failback_mode="automatic"
            )
        }

    def get_strategy(self, tier: str) -> Optional[DRStrategy]:
        """Get DR strategy for a tier."""
        return self.strategies.get(tier)
```

### 1.2 Backup Management

```python
"""
Backup management and scheduling.
"""

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any
from enum import Enum
import hashlib


class BackupType(Enum):
    """Types of backups."""
    FULL = "full"
    INCREMENTAL = "incremental"
    DIFFERENTIAL = "differential"
    SNAPSHOT = "snapshot"
    CONTINUOUS = "continuous"


class BackupStatus(Enum):
    """Backup job status."""
    PENDING = "pending"
    RUNNING = "running"
    COMPLETED = "completed"
    FAILED = "failed"
    VERIFYING = "verifying"
    VERIFIED = "verified"


@dataclass
class BackupPolicy:
    """Backup policy configuration."""
    name: str
    source: str
    backup_type: BackupType
    schedule_cron: str
    retention_days: int
    destination: str
    encryption_enabled: bool = True
    compression_enabled: bool = True
    verification_enabled: bool = True
    cross_region_copy: bool = False
    cross_region_destinations: List[str] = field(default_factory=list)


@dataclass
class BackupJob:
    """A backup job execution."""
    id: str
    policy_name: str
    backup_type: BackupType
    source: str
    destination: str
    status: BackupStatus
    started_at: datetime
    completed_at: Optional[datetime] = None
    size_bytes: int = 0
    checksum: Optional[str] = None
    error_message: Optional[str] = None
    metadata: Dict[str, Any] = field(default_factory=dict)


@dataclass
class BackupVerification:
    """Backup verification result."""
    backup_id: str
    verified_at: datetime
    checksum_valid: bool
    restore_test_passed: bool
    data_integrity_passed: bool
    verification_duration_seconds: int
    issues: List[str] = field(default_factory=list)


class BackupManager:
    """
    Manage backups across all data stores.
    """

    def __init__(self):
        self.policies: Dict[str, BackupPolicy] = {}
        self.jobs: Dict[str, BackupJob] = {}
        self.verifications: Dict[str, BackupVerification] = {}
        self._load_default_policies()

    def _load_default_policies(self) -> None:
        """Load default backup policies."""
        default_policies = [
            BackupPolicy(
                name="user-database-continuous",
                source="postgresql://user-db.internal:5432/users",
                backup_type=BackupType.CONTINUOUS,
                schedule_cron="*/5 * * * *",  # Every 5 minutes WAL archiving
                retention_days=30,
                destination="s3://backups/user-db/wal/",
                cross_region_copy=True,
                cross_region_destinations=["s3://backups-dr/user-db/wal/"]
            ),
            BackupPolicy(
                name="user-database-daily",
                source="postgresql://user-db.internal:5432/users",
                backup_type=BackupType.FULL,
                schedule_cron="0 2 * * *",  # Daily at 2 AM
                retention_days=90,
                destination="s3://backups/user-db/full/",
                cross_region_copy=True,
                cross_region_destinations=["s3://backups-dr/user-db/full/"]
            ),
            BackupPolicy(
                name="vector-database-daily",
                source="qdrant://vector-db.internal:6333",
                backup_type=BackupType.SNAPSHOT,
                schedule_cron="0 3 * * *",  # Daily at 3 AM
                retention_days=30,
                destination="s3://backups/vector-db/snapshots/"
            ),
            BackupPolicy(
                name="redis-hourly",
                source="redis://cache.internal:6379",
                backup_type=BackupType.SNAPSHOT,
                schedule_cron="0 * * * *",  # Hourly
                retention_days=7,
                destination="s3://backups/redis/snapshots/"
            ),
            BackupPolicy(
                name="config-daily",
                source="etcd://config.internal:2379",
                backup_type=BackupType.FULL,
                schedule_cron="0 1 * * *",  # Daily at 1 AM
                retention_days=30,
                destination="s3://backups/config/full/"
            ),
            BackupPolicy(
                name="billing-database-continuous",
                source="postgresql://billing-db.internal:5432/billing",
                backup_type=BackupType.CONTINUOUS,
                schedule_cron="*/1 * * * *",  # Every minute WAL archiving
                retention_days=365,  # 1 year for compliance
                destination="s3://backups/billing-db/wal/",
                cross_region_copy=True,
                cross_region_destinations=[
                    "s3://backups-dr/billing-db/wal/",
                    "s3://backups-archive/billing-db/wal/"
                ]
            )
        ]

        for policy in default_policies:
            self.policies[policy.name] = policy

    def create_backup(
        self,
        policy_name: str,
        backup_type: Optional[BackupType] = None
    ) -> BackupJob:
        """Create a new backup job."""
        policy = self.policies.get(policy_name)
        if not policy:
            raise ValueError(f"Policy {policy_name} not found")

        job_id = f"backup-{policy_name}-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}"

        job = BackupJob(
            id=job_id,
            policy_name=policy_name,
            backup_type=backup_type or policy.backup_type,
            source=policy.source,
            destination=policy.destination,
            status=BackupStatus.PENDING,
            started_at=datetime.utcnow()
        )

        self.jobs[job_id] = job
        return job

    def update_job_status(
        self,
        job_id: str,
        status: BackupStatus,
        size_bytes: Optional[int] = None,
        checksum: Optional[str] = None,
        error_message: Optional[str] = None
    ) -> None:
        """Update backup job status."""
        job = self.jobs.get(job_id)
        if not job:
            raise ValueError(f"Job {job_id} not found")

        job.status = status

        if status in [BackupStatus.COMPLETED, BackupStatus.FAILED]:
            job.completed_at = datetime.utcnow()

        if size_bytes is not None:
            job.size_bytes = size_bytes

        if checksum:
            job.checksum = checksum

        if error_message:
            job.error_message = error_message

    def verify_backup(self, job_id: str) -> BackupVerification:
        """Verify a completed backup."""
        job = self.jobs.get(job_id)
        if not job:
            raise ValueError(f"Job {job_id} not found")

        if job.status != BackupStatus.COMPLETED:
            raise ValueError(f"Job {job_id} is not completed")

        verification = BackupVerification(
            backup_id=job_id,
            verified_at=datetime.utcnow(),
            checksum_valid=True,  # Would perform actual verification
            restore_test_passed=True,  # Would perform test restore
            data_integrity_passed=True,  # Would verify data integrity
            verification_duration_seconds=0,
            issues=[]
        )

        self.verifications[job_id] = verification
        job.status = BackupStatus.VERIFIED

        return verification

    def get_latest_backup(
        self,
        policy_name: str,
        verified_only: bool = True
    ) -> Optional[BackupJob]:
        """Get the latest successful backup for a policy."""
        policy_jobs = [
            j for j in self.jobs.values()
            if j.policy_name == policy_name
        ]

        if verified_only:
            policy_jobs = [
                j for j in policy_jobs
                if j.status == BackupStatus.VERIFIED
            ]
        else:
            policy_jobs = [
                j for j in policy_jobs
                if j.status in [BackupStatus.COMPLETED, BackupStatus.VERIFIED]
            ]

        if not policy_jobs:
            return None

        return max(policy_jobs, key=lambda j: j.started_at)

    def get_backup_health(self) -> Dict[str, Any]:
        """Get overall backup health status."""
        now = datetime.utcnow()
        health = {
            "status": "healthy",
            "policies": {},
            "issues": []
        }

        for policy_name, policy in self.policies.items():
            latest = self.get_latest_backup(policy_name, verified_only=False)

            if not latest:
                health["policies"][policy_name] = {
                    "status": "no_backups",
                    "last_backup": None
                }
                health["issues"].append(f"No backups found for {policy_name}")
                health["status"] = "unhealthy"
                continue

            age_hours = (now - latest.started_at).total_seconds() / 3600

            # Determine expected frequency from cron
            expected_hours = self._cron_to_hours(policy.schedule_cron)

            if age_hours > expected_hours * 2:
                status = "stale"
                health["issues"].append(
                    f"Backup for {policy_name} is {age_hours:.1f} hours old"
                )
                health["status"] = "degraded"
            elif latest.status == BackupStatus.FAILED:
                status = "failed"
                health["issues"].append(
                    f"Latest backup for {policy_name} failed: {latest.error_message}"
                )
                health["status"] = "unhealthy"
            else:
                status = "healthy"

            health["policies"][policy_name] = {
                "status": status,
                "last_backup": latest.started_at.isoformat(),
                "last_backup_status": latest.status.value,
                "age_hours": age_hours
            }

        return health

    def _cron_to_hours(self, cron: str) -> float:
        """Estimate hours between cron executions."""
        parts = cron.split()
        if parts[0].startswith("*/"):
            minutes = int(parts[0][2:])
            return minutes / 60
        elif parts[1].startswith("*/"):
            hours = int(parts[1][2:])
            return hours
        elif parts[0] == "0" and parts[1] != "*":
            return 24  # Daily
        return 24  # Default to daily

    def cleanup_old_backups(self) -> Dict[str, int]:
        """Clean up backups past retention period."""
        deleted = {}
        now = datetime.utcnow()

        for policy_name, policy in self.policies.items():
            retention_cutoff = now - timedelta(days=policy.retention_days)

            old_jobs = [
                j for j in self.jobs.values()
                if j.policy_name == policy_name and j.started_at < retention_cutoff
            ]

            deleted[policy_name] = len(old_jobs)

            for job in old_jobs:
                # Would delete actual backup files here
                del self.jobs[job.id]
                if job.id in self.verifications:
                    del self.verifications[job.id]

        return deleted
```

---

## 2. Failover and Failback Procedures

### 2.1 Automated Failover

```python
"""
Automated failover management.
"""

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from enum import Enum
import asyncio


class FailoverState(Enum):
    """Failover state."""
    NORMAL = "normal"
    DEGRADED = "degraded"
    FAILING_OVER = "failing_over"
    FAILED_OVER = "failed_over"
    FAILING_BACK = "failing_back"


class HealthStatus(Enum):
    """Health check status."""
    HEALTHY = "healthy"
    DEGRADED = "degraded"
    UNHEALTHY = "unhealthy"
    UNKNOWN = "unknown"


@dataclass
class HealthCheck:
    """Health check result."""
    service: str
    region: str
    status: HealthStatus
    latency_ms: float
    checked_at: datetime
    details: Dict[str, Any] = field(default_factory=dict)


@dataclass
class FailoverEvent:
    """Record of a failover event."""
    id: str
    service: str
    source_region: str
    target_region: str
    trigger: str  # automatic, manual
    reason: str
    started_at: datetime
    completed_at: Optional[datetime] = None
    success: bool = False
    rollback_performed: bool = False
    metadata: Dict[str, Any] = field(default_factory=dict)


class FailoverController:
    """
    Control automated failover between regions.
    """

    def __init__(self):
        self.states: Dict[str, FailoverState] = {}
        self.health_history: Dict[str, List[HealthCheck]] = {}
        self.failover_events: List[FailoverEvent] = []
        self.failover_config: Dict[str, Dict] = {}
        self._initialize_config()

    def _initialize_config(self) -> None:
        """Initialize failover configuration."""
        self.failover_config = {
            "api-gateway": {
                "primary_region": "us-east-1",
                "failover_regions": ["us-west-2", "eu-west-1"],
                "health_threshold": 3,  # failures before failover
                "recovery_threshold": 5,  # successes before failback
                "check_interval_seconds": 10,
                "failover_cooldown_minutes": 30
            },
            "database": {
                "primary_region": "us-east-1",
                "failover_regions": ["us-west-2"],
                "health_threshold": 5,
                "recovery_threshold": 10,
                "check_interval_seconds": 5,
                "failover_cooldown_minutes": 60,
                "requires_approval": True
            },
            "cache": {
                "primary_region": "us-east-1",
                "failover_regions": ["us-west-2", "eu-west-1"],
                "health_threshold": 2,
                "recovery_threshold": 3,
                "check_interval_seconds": 5,
                "failover_cooldown_minutes": 15
            }
        }

        for service in self.failover_config:
            self.states[service] = FailoverState.NORMAL
            self.health_history[service] = []

    def record_health_check(
        self,
        service: str,
        region: str,
        status: HealthStatus,
        latency_ms: float,
        details: Optional[Dict] = None
    ) -> Optional[str]:
        """Record a health check and determine if failover needed."""
        check = HealthCheck(
            service=service,
            region=region,
            status=status,
            latency_ms=latency_ms,
            checked_at=datetime.utcnow(),
            details=details or {}
        )

        if service not in self.health_history:
            self.health_history[service] = []

        self.health_history[service].append(check)

        # Keep only recent history
        cutoff = datetime.utcnow() - timedelta(minutes=30)
        self.health_history[service] = [
            h for h in self.health_history[service]
            if h.checked_at > cutoff
        ]

        # Check if failover is needed
        return self._evaluate_failover_need(service, region)

    def _evaluate_failover_need(
        self,
        service: str,
        region: str
    ) -> Optional[str]:
        """Evaluate if failover is needed based on health history."""
        config = self.failover_config.get(service)
        if not config:
            return None

        # Only evaluate for primary region
        if region != config["primary_region"]:
            return None

        current_state = self.states.get(service, FailoverState.NORMAL)

        if current_state == FailoverState.FAILED_OVER:
            # Check if we should failback
            return self._evaluate_failback_need(service, region)

        if current_state in [FailoverState.FAILING_OVER, FailoverState.FAILING_BACK]:
            return None  # Already in progress

        # Count recent failures
        recent_checks = [
            h for h in self.health_history[service]
            if h.region == region
        ][-config["health_threshold"]:]

        unhealthy_count = sum(
            1 for h in recent_checks
            if h.status == HealthStatus.UNHEALTHY
        )

        if unhealthy_count >= config["health_threshold"]:
            # Check cooldown
            recent_failovers = [
                e for e in self.failover_events
                if e.service == service and
                e.started_at > datetime.utcnow() - timedelta(minutes=config["failover_cooldown_minutes"])
            ]

            if recent_failovers:
                return None  # In cooldown

            return "failover_recommended"

        return None

    def _evaluate_failback_need(
        self,
        service: str,
        region: str
    ) -> Optional[str]:
        """Evaluate if failback to primary is safe."""
        config = self.failover_config.get(service)
        if not config:
            return None

        # Count recent successes for primary region
        recent_checks = [
            h for h in self.health_history[service]
            if h.region == region
        ][-config["recovery_threshold"]:]

        healthy_count = sum(
            1 for h in recent_checks
            if h.status == HealthStatus.HEALTHY
        )

        if healthy_count >= config["recovery_threshold"]:
            return "failback_recommended"

        return None

    async def execute_failover(
        self,
        service: str,
        target_region: str,
        reason: str,
        trigger: str = "automatic"
    ) -> FailoverEvent:
        """Execute failover to target region."""
        config = self.failover_config.get(service)
        if not config:
            raise ValueError(f"No failover config for {service}")

        if target_region not in config["failover_regions"]:
            raise ValueError(f"{target_region} is not a valid failover region for {service}")

        event = FailoverEvent(
            id=f"fo-{service}-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}",
            service=service,
            source_region=config["primary_region"],
            target_region=target_region,
            trigger=trigger,
            reason=reason,
            started_at=datetime.utcnow()
        )

        self.states[service] = FailoverState.FAILING_OVER

        try:
            # Execute failover steps
            await self._execute_failover_steps(service, target_region)

            event.success = True
            event.completed_at = datetime.utcnow()
            self.states[service] = FailoverState.FAILED_OVER

        except Exception as e:
            event.success = False
            event.metadata["error"] = str(e)
            self.states[service] = FailoverState.DEGRADED

        self.failover_events.append(event)
        return event

    async def _execute_failover_steps(
        self,
        service: str,
        target_region: str
    ) -> None:
        """Execute the actual failover steps."""
        # Step 1: Verify target region is healthy
        await self._verify_target_health(service, target_region)

        # Step 2: Update DNS/routing
        await self._update_routing(service, target_region)

        # Step 3: Verify traffic is flowing to new region
        await self._verify_traffic_flow(service, target_region)

        # Step 4: Update monitoring
        await self._update_monitoring(service, target_region)

    async def _verify_target_health(
        self,
        service: str,
        target_region: str
    ) -> None:
        """Verify target region is healthy before failover."""
        # Would perform actual health checks
        await asyncio.sleep(0.1)

    async def _update_routing(
        self,
        service: str,
        target_region: str
    ) -> None:
        """Update DNS/routing to point to target region."""
        # Would update Route53, load balancer, etc.
        await asyncio.sleep(0.1)

    async def _verify_traffic_flow(
        self,
        service: str,
        target_region: str
    ) -> None:
        """Verify traffic is flowing to the new region."""
        # Would check metrics
        await asyncio.sleep(0.1)

    async def _update_monitoring(
        self,
        service: str,
        target_region: str
    ) -> None:
        """Update monitoring configuration for new active region."""
        # Would update dashboards, alerts
        await asyncio.sleep(0.1)

    async def execute_failback(
        self,
        service: str,
        reason: str
    ) -> FailoverEvent:
        """Execute failback to primary region."""
        config = self.failover_config.get(service)
        if not config:
            raise ValueError(f"No failover config for {service}")

        current_state = self.states.get(service)
        if current_state != FailoverState.FAILED_OVER:
            raise ValueError(f"Service {service} is not in failed over state")

        event = FailoverEvent(
            id=f"fb-{service}-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}",
            service=service,
            source_region=self._get_current_active_region(service),
            target_region=config["primary_region"],
            trigger="manual",
            reason=reason,
            started_at=datetime.utcnow()
        )

        self.states[service] = FailoverState.FAILING_BACK

        try:
            await self._execute_failover_steps(service, config["primary_region"])

            event.success = True
            event.completed_at = datetime.utcnow()
            self.states[service] = FailoverState.NORMAL

        except Exception as e:
            event.success = False
            event.metadata["error"] = str(e)
            self.states[service] = FailoverState.FAILED_OVER  # Stay failed over

        self.failover_events.append(event)
        return event

    def _get_current_active_region(self, service: str) -> str:
        """Get the current active region for a service."""
        # Would check actual routing state
        config = self.failover_config.get(service)
        if self.states.get(service) == FailoverState.FAILED_OVER:
            return config["failover_regions"][0]
        return config["primary_region"]

    def get_failover_status(self) -> Dict[str, Any]:
        """Get current failover status for all services."""
        status = {}

        for service, config in self.failover_config.items():
            state = self.states.get(service, FailoverState.NORMAL)
            active_region = self._get_current_active_region(service)

            recent_health = self.health_history.get(service, [])[-5:]
            health_summary = {
                h.region: h.status.value
                for h in recent_health
            }

            status[service] = {
                "state": state.value,
                "active_region": active_region,
                "primary_region": config["primary_region"],
                "failover_regions": config["failover_regions"],
                "recent_health": health_summary
            }

        return status
```

### 2.2 Database Failover

```python
"""
Database-specific failover procedures.
"""

from dataclasses import dataclass, field
from datetime import datetime
from typing import Dict, List, Optional, Any
from enum import Enum
import asyncio


class DatabaseRole(Enum):
    """Database role in replication."""
    PRIMARY = "primary"
    REPLICA = "replica"
    STANDBY = "standby"


@dataclass
class DatabaseNode:
    """A database node in the cluster."""
    id: str
    host: str
    port: int
    region: str
    role: DatabaseRole
    replication_lag_seconds: float = 0
    last_health_check: datetime = field(default_factory=datetime.utcnow)
    is_healthy: bool = True
    connections_active: int = 0
    connections_max: int = 100


@dataclass
class ReplicationStatus:
    """Replication status between nodes."""
    source_node: str
    target_node: str
    lag_bytes: int
    lag_seconds: float
    is_streaming: bool
    last_sync: datetime


class DatabaseFailoverManager:
    """
    Manage database failover operations.
    """

    def __init__(self):
        self.nodes: Dict[str, DatabaseNode] = {}
        self.replication_status: Dict[str, ReplicationStatus] = {}
        self._initialize_nodes()

    def _initialize_nodes(self) -> None:
        """Initialize database nodes."""
        self.nodes = {
            "pg-primary-east": DatabaseNode(
                id="pg-primary-east",
                host="pg-primary.us-east-1.internal",
                port=5432,
                region="us-east-1",
                role=DatabaseRole.PRIMARY
            ),
            "pg-replica-east": DatabaseNode(
                id="pg-replica-east",
                host="pg-replica.us-east-1.internal",
                port=5432,
                region="us-east-1",
                role=DatabaseRole.REPLICA
            ),
            "pg-standby-west": DatabaseNode(
                id="pg-standby-west",
                host="pg-standby.us-west-2.internal",
                port=5432,
                region="us-west-2",
                role=DatabaseRole.STANDBY
            )
        }

    def get_primary_node(self) -> Optional[DatabaseNode]:
        """Get the current primary node."""
        for node in self.nodes.values():
            if node.role == DatabaseRole.PRIMARY and node.is_healthy:
                return node
        return None

    def get_best_failover_candidate(self) -> Optional[DatabaseNode]:
        """Get the best candidate for promotion."""
        candidates = []

        for node in self.nodes.values():
            if node.role != DatabaseRole.PRIMARY and node.is_healthy:
                candidates.append(node)

        if not candidates:
            return None

        # Sort by replication lag (lowest first)
        candidates.sort(key=lambda n: n.replication_lag_seconds)

        return candidates[0]

    async def execute_database_failover(
        self,
        target_node_id: str,
        force: bool = False
    ) -> Dict[str, Any]:
        """Execute database failover to target node."""
        target = self.nodes.get(target_node_id)
        if not target:
            raise ValueError(f"Node {target_node_id} not found")

        if target.role == DatabaseRole.PRIMARY:
            raise ValueError("Target is already primary")

        current_primary = self.get_primary_node()

        result = {
            "started_at": datetime.utcnow().isoformat(),
            "target_node": target_node_id,
            "previous_primary": current_primary.id if current_primary else None,
            "steps": [],
            "success": False
        }

        try:
            # Step 1: Check replication lag
            if not force and target.replication_lag_seconds > 10:
                raise ValueError(
                    f"Replication lag too high: {target.replication_lag_seconds}s"
                )
            result["steps"].append({
                "step": "check_replication_lag",
                "status": "passed",
                "lag_seconds": target.replication_lag_seconds
            })

            # Step 2: Stop writes on current primary (if accessible)
            if current_primary and current_primary.is_healthy:
                await self._stop_writes(current_primary)
                result["steps"].append({
                    "step": "stop_writes",
                    "status": "completed",
                    "node": current_primary.id
                })

            # Step 3: Wait for replication to catch up
            await self._wait_for_replication_sync(target)
            result["steps"].append({
                "step": "wait_replication_sync",
                "status": "completed"
            })

            # Step 4: Promote target to primary
            await self._promote_to_primary(target)
            result["steps"].append({
                "step": "promote_primary",
                "status": "completed",
                "node": target.id
            })

            # Step 5: Update connection strings
            await self._update_connection_strings(target)
            result["steps"].append({
                "step": "update_connections",
                "status": "completed"
            })

            # Step 6: Verify new primary
            await self._verify_primary(target)
            result["steps"].append({
                "step": "verify_primary",
                "status": "completed"
            })

            # Update node roles
            if current_primary:
                current_primary.role = DatabaseRole.STANDBY

            target.role = DatabaseRole.PRIMARY

            result["success"] = True
            result["completed_at"] = datetime.utcnow().isoformat()

        except Exception as e:
            result["error"] = str(e)
            result["steps"].append({
                "step": "failover",
                "status": "failed",
                "error": str(e)
            })

        return result

    async def _stop_writes(self, node: DatabaseNode) -> None:
        """Stop writes on a database node."""
        # Would execute: SELECT pg_catalog.pg_stop_backup()
        # And set to read-only mode
        await asyncio.sleep(0.1)

    async def _wait_for_replication_sync(
        self,
        node: DatabaseNode,
        timeout_seconds: int = 30
    ) -> None:
        """Wait for replication to sync."""
        # Would poll replication lag until 0 or timeout
        await asyncio.sleep(0.1)

    async def _promote_to_primary(self, node: DatabaseNode) -> None:
        """Promote a node to primary."""
        # Would execute: SELECT pg_promote()
        # Or touch trigger file for older versions
        await asyncio.sleep(0.1)

    async def _update_connection_strings(self, node: DatabaseNode) -> None:
        """Update connection strings to point to new primary."""
        # Would update:
        # - DNS records
        # - Connection pooler config (PgBouncer)
        # - Application configuration
        await asyncio.sleep(0.1)

    async def _verify_primary(self, node: DatabaseNode) -> None:
        """Verify the new primary is functioning correctly."""
        # Would run:
        # - SELECT pg_is_in_recovery() = false
        # - Test write operation
        # - Verify connections are being accepted
        await asyncio.sleep(0.1)

    def get_cluster_status(self) -> Dict[str, Any]:
        """Get current cluster status."""
        primary = self.get_primary_node()

        return {
            "primary": primary.id if primary else None,
            "nodes": {
                node_id: {
                    "role": node.role.value,
                    "region": node.region,
                    "is_healthy": node.is_healthy,
                    "replication_lag_seconds": node.replication_lag_seconds,
                    "connections": f"{node.connections_active}/{node.connections_max}"
                }
                for node_id, node in self.nodes.items()
            },
            "replication": {
                key: {
                    "lag_seconds": status.lag_seconds,
                    "is_streaming": status.is_streaming
                }
                for key, status in self.replication_status.items()
            }
        }
```

---

## 3. DR Testing and Validation

### 3.1 DR Test Framework

```python
"""
Disaster recovery testing framework.
"""

from dataclasses import dataclass, field
from datetime import datetime, timedelta
from typing import Dict, List, Optional, Any, Callable
from enum import Enum
import asyncio


class DRTestType(Enum):
    """Types of DR tests."""
    TABLETOP = "tabletop"  # Discussion-based
    WALKTHROUGH = "walkthrough"  # Step-by-step review
    SIMULATION = "simulation"  # Simulated failure
    PARALLEL = "parallel"  # Run in parallel environment
    FULL = "full"  # Full failover test


class TestResult(Enum):
    """Test result status."""
    PASSED = "passed"
    FAILED = "failed"
    PARTIAL = "partial"
    SKIPPED = "skipped"


@dataclass
class DRTestStep:
    """A step in a DR test."""
    order: int
    name: str
    description: str
    expected_result: str
    actual_result: Optional[str] = None
    status: TestResult = TestResult.SKIPPED
    duration_seconds: float = 0
    notes: str = ""


@dataclass
class DRTestScenario:
    """A DR test scenario."""
    id: str
    name: str
    description: str
    test_type: DRTestType
    disaster_type: 'DisasterType'
    affected_services: List[str]
    steps: List[DRTestStep]
    success_criteria: List[str]
    estimated_duration_minutes: int
    requires_maintenance_window: bool = False
    risk_level: str = "low"  # low, medium, high


@dataclass
class DRTestExecution:
    """Record of a DR test execution."""
    id: str
    scenario_id: str
    executed_by: str
    started_at: datetime
    completed_at: Optional[datetime] = None
    overall_result: TestResult = TestResult.SKIPPED
    steps_completed: int = 0
    steps_total: int = 0
    actual_duration_minutes: float = 0
    rto_achieved_minutes: Optional[float] = None
    rpo_achieved_minutes: Optional[float] = None
    findings: List[str] = field(default_factory=list)
    action_items: List[str] = field(default_factory=list)


class DRTestManager:
    """
    Manage DR test scenarios and executions.
    """

    def __init__(self):
        self.scenarios: Dict[str, DRTestScenario] = {}
        self.executions: List[DRTestExecution] = []
        self._load_default_scenarios()

    def _load_default_scenarios(self) -> None:
        """Load default DR test scenarios."""
        scenarios = [
            DRTestScenario(
                id="regional-failover-test",
                name="Regional Failover Test",
                description="Test complete failover to DR region",
                test_type=DRTestType.FULL,
                disaster_type=DisasterType.REGIONAL_OUTAGE,
                affected_services=["api-gateway", "database", "cache"],
                steps=[
                    DRTestStep(
                        order=1,
                        name="Pre-test verification",
                        description="Verify all systems healthy before test",
                        expected_result="All systems operational"
                    ),
                    DRTestStep(
                        order=2,
                        name="Simulate primary region failure",
                        description="Block traffic to primary region services",
                        expected_result="Primary region unavailable"
                    ),
                    DRTestStep(
                        order=3,
                        name="Verify automatic detection",
                        description="Confirm monitoring detects the failure",
                        expected_result="Alerts triggered within 2 minutes"
                    ),
                    DRTestStep(
                        order=4,
                        name="Execute failover",
                        description="Initiate failover to DR region",
                        expected_result="Traffic routed to DR region"
                    ),
                    DRTestStep(
                        order=5,
                        name="Verify DR region functionality",
                        description="Test all critical paths in DR region",
                        expected_result="All critical functions operational"
                    ),
                    DRTestStep(
                        order=6,
                        name="Measure recovery metrics",
                        description="Record RTO and RPO achieved",
                        expected_result="RTO < 30 min, RPO < 5 min"
                    ),
                    DRTestStep(
                        order=7,
                        name="Execute failback",
                        description="Return to primary region",
                        expected_result="Primary region active"
                    ),
                    DRTestStep(
                        order=8,
                        name="Post-test verification",
                        description="Verify all systems healthy after test",
                        expected_result="All systems operational"
                    )
                ],
                success_criteria=[
                    "RTO achieved within target",
                    "RPO achieved within target",
                    "No data loss",
                    "All critical functions available in DR",
                    "Successful failback completed"
                ],
                estimated_duration_minutes=120,
                requires_maintenance_window=True,
                risk_level="medium"
            ),

            DRTestScenario(
                id="database-failover-test",
                name="Database Failover Test",
                description="Test database failover to standby",
                test_type=DRTestType.FULL,
                disaster_type=DisasterType.DATA_CENTER_FAILURE,
                affected_services=["database"],
                steps=[
                    DRTestStep(
                        order=1,
                        name="Verify replication status",
                        description="Confirm standby is in sync",
                        expected_result="Replication lag < 1 second"
                    ),
                    DRTestStep(
                        order=2,
                        name="Stop primary database",
                        description="Simulate primary database failure",
                        expected_result="Primary database stopped"
                    ),
                    DRTestStep(
                        order=3,
                        name="Promote standby",
                        description="Promote standby to primary",
                        expected_result="Standby promoted successfully"
                    ),
                    DRTestStep(
                        order=4,
                        name="Update connections",
                        description="Point applications to new primary",
                        expected_result="Applications connected to new primary"
                    ),
                    DRTestStep(
                        order=5,
                        name="Verify data integrity",
                        description="Run data integrity checks",
                        expected_result="No data loss detected"
                    ),
                    DRTestStep(
                        order=6,
                        name="Rebuild original primary as standby",
                        description="Reconfigure old primary as new standby",
                        expected_result="Replication re-established"
                    )
                ],
                success_criteria=[
                    "Failover completed within 10 minutes",
                    "No data loss",
                    "All applications reconnected",
                    "Replication re-established"
                ],
                estimated_duration_minutes=60,
                requires_maintenance_window=True,
                risk_level="high"
            ),

            DRTestScenario(
                id="backup-restore-test",
                name="Backup Restore Test",
                description="Test restore from backup",
                test_type=DRTestType.PARALLEL,
                disaster_type=DisasterType.DATA_CORRUPTION,
                affected_services=["database"],
                steps=[
                    DRTestStep(
                        order=1,
                        name="Identify backup to restore",
                        description="Select most recent verified backup",
                        expected_result="Backup identified"
                    ),
                    DRTestStep(
                        order=2,
                        name="Provision test environment",
                        description="Create isolated test environment",
                        expected_result="Test environment ready"
                    ),
                    DRTestStep(
                        order=3,
                        name="Restore backup",
                        description="Restore backup to test environment",
                        expected_result="Backup restored successfully"
                    ),
                    DRTestStep(
                        order=4,
                        name="Verify data integrity",
                        description="Run integrity checks on restored data",
                        expected_result="Data integrity verified"
                    ),
                    DRTestStep(
                        order=5,
                        name="Test application connectivity",
                        description="Connect test application to restored database",
                        expected_result="Application functions correctly"
                    ),
                    DRTestStep(
                        order=6,
                        name="Clean up test environment",
                        description="Remove test environment",
                        expected_result="Test environment removed"
                    )
                ],
                success_criteria=[
                    "Restore completed within RTO",
                    "Data integrity verified",
                    "Application connectivity confirmed"
                ],
                estimated_duration_minutes=90,
                requires_maintenance_window=False,
                risk_level="low"
            ),

            DRTestScenario(
                id="provider-failover-test",
                name="Model Provider Failover Test",
                description="Test failover between model providers",
                test_type=DRTestType.SIMULATION,
                disaster_type=DisasterType.PROVIDER_OUTAGE,
                affected_services=["model-router"],
                steps=[
                    DRTestStep(
                        order=1,
                        name="Verify backup provider health",
                        description="Confirm backup provider is available",
                        expected_result="Backup provider healthy"
                    ),
                    DRTestStep(
                        order=2,
                        name="Simulate primary provider failure",
                        description="Block requests to primary provider",
                        expected_result="Primary provider appears down"
                    ),
                    DRTestStep(
                        order=3,
                        name="Verify automatic failover",
                        description="Confirm traffic routes to backup",
                        expected_result="Traffic routed to backup provider"
                    ),
                    DRTestStep(
                        order=4,
                        name="Verify response quality",
                        description="Test response quality from backup",
                        expected_result="Response quality acceptable"
                    ),
                    DRTestStep(
                        order=5,
                        name="Restore primary provider",
                        description="Remove block on primary provider",
                        expected_result="Primary provider available"
                    ),
                    DRTestStep(
                        order=6,
                        name="Verify failback",
                        description="Confirm traffic returns to primary",
                        expected_result="Traffic on primary provider"
                    )
                ],
                success_criteria=[
                    "Failover completed automatically",
                    "User impact < 1 minute",
                    "No errors during failover",
                    "Failback successful"
                ],
                estimated_duration_minutes=30,
                requires_maintenance_window=False,
                risk_level="low"
            )
        ]

        for scenario in scenarios:
            self.scenarios[scenario.id] = scenario

    def start_test(
        self,
        scenario_id: str,
        executed_by: str
    ) -> DRTestExecution:
        """Start a DR test execution."""
        scenario = self.scenarios.get(scenario_id)
        if not scenario:
            raise ValueError(f"Scenario {scenario_id} not found")

        execution = DRTestExecution(
            id=f"test-{scenario_id}-{datetime.utcnow().strftime('%Y%m%d%H%M%S')}",
            scenario_id=scenario_id,
            executed_by=executed_by,
            started_at=datetime.utcnow(),
            steps_total=len(scenario.steps)
        )

        self.executions.append(execution)
        return execution

    def record_step_result(
        self,
        execution_id: str,
        step_order: int,
        status: TestResult,
        actual_result: str,
        duration_seconds: float,
        notes: str = ""
    ) -> None:
        """Record the result of a test step."""
        execution = self._get_execution(execution_id)
        scenario = self.scenarios.get(execution.scenario_id)

        for step in scenario.steps:
            if step.order == step_order:
                step.status = status
                step.actual_result = actual_result
                step.duration_seconds = duration_seconds
                step.notes = notes
                break

        execution.steps_completed += 1

    def complete_test(
        self,
        execution_id: str,
        overall_result: TestResult,
        rto_achieved_minutes: float,
        rpo_achieved_minutes: float,
        findings: List[str],
        action_items: List[str]
    ) -> None:
        """Complete a DR test execution."""
        execution = self._get_execution(execution_id)

        execution.completed_at = datetime.utcnow()
        execution.overall_result = overall_result
        execution.actual_duration_minutes = (
            execution.completed_at - execution.started_at
        ).total_seconds() / 60
        execution.rto_achieved_minutes = rto_achieved_minutes
        execution.rpo_achieved_minutes = rpo_achieved_minutes
        execution.findings = findings
        execution.action_items = action_items

    def _get_execution(self, execution_id: str) -> DRTestExecution:
        """Get execution by ID."""
        for execution in self.executions:
            if execution.id == execution_id:
                return execution
        raise ValueError(f"Execution {execution_id} not found")

    def get_test_history(
        self,
        scenario_id: Optional[str] = None,
        since: Optional[datetime] = None
    ) -> List[DRTestExecution]:
        """Get test execution history."""
        history = self.executions

        if scenario_id:
            history = [e for e in history if e.scenario_id == scenario_id]

        if since:
            history = [e for e in history if e.started_at >= since]

        return sorted(history, key=lambda e: e.started_at, reverse=True)

    def get_test_metrics(self) -> Dict[str, Any]:
        """Get DR testing metrics."""
        if not self.executions:
            return {"no_tests": True}

        completed = [e for e in self.executions if e.completed_at]

        passed = len([e for e in completed if e.overall_result == TestResult.PASSED])
        failed = len([e for e in completed if e.overall_result == TestResult.FAILED])

        rto_values = [e.rto_achieved_minutes for e in completed if e.rto_achieved_minutes]
        rpo_values = [e.rpo_achieved_minutes for e in completed if e.rpo_achieved_minutes]

        return {
            "total_tests": len(self.executions),
            "completed_tests": len(completed),
            "pass_rate": passed / len(completed) if completed else 0,
            "average_rto_minutes": sum(rto_values) / len(rto_values) if rto_values else None,
            "average_rpo_minutes": sum(rpo_values) / len(rpo_values) if rpo_values else None,
            "last_test_date": max(e.started_at for e in self.executions).isoformat() if self.executions else None,
            "tests_by_scenario": {
                scenario_id: len([e for e in completed if e.scenario_id == scenario_id])
                for scenario_id in self.scenarios.keys()
            }
        }

    def generate_test_report(
        self,
        execution_id: str
    ) -> str:
        """Generate a test report."""
        execution = self._get_execution(execution_id)
        scenario = self.scenarios.get(execution.scenario_id)

        report = f"""# DR Test Report

## Test Information
- **Test ID:** {execution.id}
- **Scenario:** {scenario.name}
- **Executed By:** {execution.executed_by}
- **Date:** {execution.started_at.strftime('%Y-%m-%d %H:%M UTC')}

## Summary
- **Overall Result:** {execution.overall_result.value.upper()}
- **Duration:** {execution.actual_duration_minutes:.1f} minutes
- **RTO Achieved:** {execution.rto_achieved_minutes} minutes
- **RPO Achieved:** {execution.rpo_achieved_minutes} minutes

## Test Steps

| Step | Name | Status | Duration | Notes |
|------|------|--------|----------|-------|
"""
        for step in scenario.steps:
            report += f"| {step.order} | {step.name} | {step.status.value} | {step.duration_seconds:.0f}s | {step.notes or '-'} |\n"

        report += f"""

## Findings

"""
        for finding in execution.findings:
            report += f"- {finding}\n"

        report += f"""

## Action Items

"""
        for i, action in enumerate(execution.action_items, 1):
            report += f"{i}. {action}\n"

        return report
```

---

## 4. DR Documentation and Runbooks

### 4.1 DR Runbook Templates

```python
"""
DR runbook templates and documentation.
"""

from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
from datetime import datetime


@dataclass
class RunbookStep:
    """A step in a DR runbook."""
    order: int
    title: str
    description: str
    commands: List[str]
    expected_output: str
    verification: str
    rollback: Optional[str] = None
    timeout_minutes: int = 10
    notes: List[str] = field(default_factory=list)


@dataclass
class DRRunbook:
    """A disaster recovery runbook."""
    id: str
    title: str
    description: str
    scenario: str
    severity: str
    estimated_time_minutes: int
    prerequisites: List[str]
    roles_required: List[str]
    steps: List[RunbookStep]
    post_recovery_steps: List[str]
    communication_templates: Dict[str, str]
    last_updated: datetime
    owner: str
    version: str


class DRRunbookLibrary:
    """
    Library of DR runbooks.
    """

    def __init__(self):
        self.runbooks: Dict[str, DRRunbook] = {}
        self._load_default_runbooks()

    def _load_default_runbooks(self) -> None:
        """Load default DR runbooks."""
        runbooks = [
            DRRunbook(
                id="regional-failover",
                title="Regional Failover Runbook",
                description="Complete failover from primary to DR region",
                scenario="Primary region unavailable",
                severity="SEV1",
                estimated_time_minutes=30,
                prerequisites=[
                    "DR region infrastructure provisioned",
                    "Database replication active",
                    "DNS failover configured",
                    "Monitoring in place for both regions"
                ],
                roles_required=[
                    "Incident Commander",
                    "Database Administrator",
                    "Network Engineer",
                    "Application Owner"
                ],
                steps=[
                    RunbookStep(
                        order=1,
                        title="Assess Primary Region Status",
                        description="Determine if primary region is truly unavailable",
                        commands=[
                            "# Check primary region health endpoints",
                            "curl -s https://api.us-east-1.platform.com/health",
                            "",
                            "# Check AWS region status",
                            "aws health describe-events --region us-east-1",
                            "",
                            "# Check internal monitoring",
                            "curl -s https://monitoring.internal/api/v1/query?query=up{region=\"us-east-1\"}"
                        ],
                        expected_output="Primary region services unreachable or degraded",
                        verification="Multiple independent checks confirm unavailability"
                    ),
                    RunbookStep(
                        order=2,
                        title="Verify DR Region Readiness",
                        description="Confirm DR region is healthy and ready",
                        commands=[
                            "# Check DR region health",
                            "curl -s https://api.us-west-2.platform.com/health",
                            "",
                            "# Check database replication status",
                            "kubectl exec -n production $(kubectl get pod -n production -l app=postgres -o name | head -1) -- psql -U postgres -c 'SELECT * FROM pg_stat_replication;'",
                            "",
                            "# Check replication lag",
                            "curl -s 'https://monitoring.internal/api/v1/query?query=pg_replication_lag_seconds{region=\"us-west-2\"}'"
                        ],
                        expected_output="DR region healthy, replication lag < 5 seconds",
                        verification="All DR region health checks passing"
                    ),
                    RunbookStep(
                        order=3,
                        title="Initiate Database Failover",
                        description="Promote DR database to primary",
                        commands=[
                            "# Stop writes to primary (if accessible)",
                            "kubectl exec -n production pg-primary-0 -- psql -U postgres -c \"ALTER SYSTEM SET default_transaction_read_only = on;\"",
                            "",
                            "# Wait for replication to catch up",
                            "sleep 30",
                            "",
                            "# Promote DR database",
                            "kubectl exec -n production pg-standby-0 -- pg_ctl promote -D /var/lib/postgresql/data",
                            "",
                            "# Verify promotion",
                            "kubectl exec -n production pg-standby-0 -- psql -U postgres -c 'SELECT pg_is_in_recovery();'"
                        ],
                        expected_output="pg_is_in_recovery = f (false)",
                        verification="DR database is now primary",
                        rollback="If promotion fails, continue using read-only mode until resolved",
                        timeout_minutes=15,
                        notes=[
                            "DO NOT proceed if replication lag > 10 seconds without approval",
                            "Document the exact LSN at failover time"
                        ]
                    ),
                    RunbookStep(
                        order=4,
                        title="Update DNS to DR Region",
                        description="Route traffic to DR region",
                        commands=[
                            "# Update Route53 health check",
                            "aws route53 update-health-check --health-check-id $PRIMARY_HC_ID --disabled",
                            "",
                            "# Verify DNS propagation",
                            "dig api.platform.com +short",
                            "",
                            "# Force DNS refresh for critical clients",
                            "# (Notify client teams to flush DNS caches)"
                        ],
                        expected_output="DNS resolving to DR region IPs",
                        verification="Multiple DNS queries return DR region addresses"
                    ),
                    RunbookStep(
                        order=5,
                        title="Verify Application Connectivity",
                        description="Confirm applications connected to new primary",
                        commands=[
                            "# Check application logs for connection errors",
                            "kubectl logs -n production -l app=api-gateway --since=5m | grep -i 'database\\|connection'",
                            "",
                            "# Check active connections",
                            "kubectl exec -n production pg-standby-0 -- psql -U postgres -c 'SELECT count(*) FROM pg_stat_activity;'",
                            "",
                            "# Run smoke tests",
                            "curl -X POST https://api.platform.com/v1/health/deep"
                        ],
                        expected_output="Applications connected, smoke tests passing",
                        verification="API returning successful responses"
                    ),
                    RunbookStep(
                        order=6,
                        title="Update Monitoring and Alerts",
                        description="Reconfigure monitoring for DR region",
                        commands=[
                            "# Update Grafana dashboards",
                            "curl -X POST https://grafana.internal/api/annotations -d '{\"text\":\"Failover to us-west-2\",\"tags\":[\"failover\"]}'",
                            "",
                            "# Suppress primary region alerts",
                            "curl -X POST https://alertmanager.internal/api/v2/silences -d '{\"matchers\":[{\"name\":\"region\",\"value\":\"us-east-1\"}],\"startsAt\":\"...\",\"endsAt\":\"...\"}'"
                        ],
                        expected_output="Monitoring configured for DR region",
                        verification="DR region metrics visible in dashboards"
                    )
                ],
                post_recovery_steps=[
                    "Schedule post-incident review within 48 hours",
                    "Document exact timeline and decisions made",
                    "Update runbook with lessons learned",
                    "Plan primary region recovery/failback",
                    "Notify customers of incident resolution",
                    "Review and update RTO/RPO targets if needed"
                ],
                communication_templates={
                    "initial": "We are aware of an issue affecting services in our primary region. Our team has initiated failover procedures to our disaster recovery region. Updates will be provided every 15 minutes.",
                    "in_progress": "Failover to disaster recovery region is in progress. Services may experience brief interruptions. Current status: {status}",
                    "complete": "Failover to disaster recovery region is complete. All services are operational. We will continue to monitor and provide updates on primary region recovery."
                },
                last_updated=datetime.utcnow(),
                owner="SRE Team",
                version="2.0"
            ),

            DRRunbook(
                id="data-corruption-recovery",
                title="Data Corruption Recovery Runbook",
                description="Recover from data corruption using point-in-time recovery",
                scenario="Data corruption detected",
                severity="SEV1",
                estimated_time_minutes=60,
                prerequisites=[
                    "Continuous WAL archiving enabled",
                    "Recent verified backup available",
                    "PITR capable database configuration"
                ],
                roles_required=[
                    "Incident Commander",
                    "Database Administrator",
                    "Application Owner"
                ],
                steps=[
                    RunbookStep(
                        order=1,
                        title="Identify Corruption Time",
                        description="Determine when corruption occurred",
                        commands=[
                            "# Check application logs for first error",
                            "grep -r 'integrity\\|corrupt\\|invalid' /var/log/app/*.log | head -50",
                            "",
                            "# Check database logs",
                            "kubectl logs -n production pg-primary-0 --since=1h | grep -i 'error\\|corrupt'",
                            "",
                            "# Query audit logs if available",
                            "kubectl exec -n production pg-primary-0 -- psql -U postgres -c \"SELECT * FROM audit_log WHERE timestamp > now() - interval '2 hours' ORDER BY timestamp;\""
                        ],
                        expected_output="Timestamp of corruption event identified",
                        verification="Exact or approximate time of corruption known",
                        notes=[
                            "Document the corruption time with evidence",
                            "Target recovery point is BEFORE this time"
                        ]
                    ),
                    RunbookStep(
                        order=2,
                        title="Stop Application Access",
                        description="Prevent further corruption or inconsistency",
                        commands=[
                            "# Scale down application pods",
                            "kubectl scale deployment/api-gateway -n production --replicas=0",
                            "",
                            "# Enable maintenance mode",
                            "kubectl set env deployment/frontend -n production MAINTENANCE_MODE=true",
                            "",
                            "# Block database connections",
                            "kubectl exec -n production pg-primary-0 -- psql -U postgres -c \"SELECT pg_terminate_backend(pid) FROM pg_stat_activity WHERE datname = 'production' AND pid != pg_backend_pid();\""
                        ],
                        expected_output="All application access stopped",
                        verification="No active connections to affected database"
                    ),
                    RunbookStep(
                        order=3,
                        title="Provision Recovery Instance",
                        description="Create new database instance for recovery",
                        commands=[
                            "# Create recovery instance",
                            "kubectl apply -f - <<EOF",
                            "apiVersion: v1",
                            "kind: Pod",
                            "metadata:",
                            "  name: pg-recovery",
                            "  namespace: production",
                            "spec:",
                            "  containers:",
                            "  - name: postgres",
                            "    image: postgres:15",
                            "    env:",
                            "    - name: POSTGRES_PASSWORD",
                            "      valueFrom:",
                            "        secretKeyRef:",
                            "          name: pg-credentials",
                            "          key: password",
                            "EOF",
                            "",
                            "# Wait for pod ready",
                            "kubectl wait --for=condition=ready pod/pg-recovery -n production"
                        ],
                        expected_output="Recovery instance running",
                        verification="Recovery pod is ready"
                    ),
                    RunbookStep(
                        order=4,
                        title="Restore from Backup",
                        description="Restore base backup and apply WAL to target time",
                        commands=[
                            "# Download base backup",
                            "aws s3 cp s3://backups/user-db/full/latest/ /var/lib/postgresql/recovery/ --recursive",
                            "",
                            "# Configure recovery",
                            "cat > /var/lib/postgresql/recovery/recovery.conf <<EOF",
                            "restore_command = 'aws s3 cp s3://backups/user-db/wal/%f %p'",
                            "recovery_target_time = '2024-01-15 10:30:00 UTC'",
                            "recovery_target_action = 'promote'",
                            "EOF",
                            "",
                            "# Start recovery",
                            "pg_ctl start -D /var/lib/postgresql/recovery"
                        ],
                        expected_output="Database recovered to target point",
                        verification="Recovery completed, database promoted",
                        timeout_minutes=30
                    ),
                    RunbookStep(
                        order=5,
                        title="Verify Recovered Data",
                        description="Validate data integrity in recovered instance",
                        commands=[
                            "# Run integrity checks",
                            "kubectl exec -n production pg-recovery -- psql -U postgres -c 'SELECT * FROM verify_data_integrity();'",
                            "",
                            "# Check row counts",
                            "kubectl exec -n production pg-recovery -- psql -U postgres -c 'SELECT schemaname, tablename, n_live_tup FROM pg_stat_user_tables;'",
                            "",
                            "# Verify critical data",
                            "kubectl exec -n production pg-recovery -- psql -U postgres -c 'SELECT count(*) FROM users; SELECT count(*) FROM transactions;'"
                        ],
                        expected_output="Data integrity verified",
                        verification="All integrity checks pass"
                    ),
                    RunbookStep(
                        order=6,
                        title="Switch to Recovered Database",
                        description="Point applications to recovered database",
                        commands=[
                            "# Update connection string secret",
                            "kubectl create secret generic db-connection --from-literal=url='postgresql://postgres:$PASS@pg-recovery:5432/production' --dry-run=client -o yaml | kubectl apply -f -",
                            "",
                            "# Restart applications",
                            "kubectl rollout restart deployment/api-gateway -n production",
                            "",
                            "# Scale up applications",
                            "kubectl scale deployment/api-gateway -n production --replicas=3"
                        ],
                        expected_output="Applications connected to recovered database",
                        verification="API responding successfully"
                    )
                ],
                post_recovery_steps=[
                    "Investigate root cause of corruption",
                    "Preserve corrupted database for analysis",
                    "Set up new replication from recovered database",
                    "Verify all data since recovery point",
                    "Communicate data loss (if any) to affected users",
                    "Update monitoring to detect similar issues earlier"
                ],
                communication_templates={
                    "initial": "We have detected a data integrity issue and are working to recover from backup. Some recent data may be affected.",
                    "in_progress": "Data recovery is in progress. Services are temporarily unavailable. Estimated time to recovery: {eta}",
                    "complete": "Data recovery is complete. Services have been restored. Any data entered after {cutoff_time} may need to be re-entered."
                },
                last_updated=datetime.utcnow(),
                owner="Database Team",
                version="1.5"
            )
        ]

        for runbook in runbooks:
            self.runbooks[runbook.id] = runbook

    def get_runbook(self, runbook_id: str) -> Optional[DRRunbook]:
        """Get a runbook by ID."""
        return self.runbooks.get(runbook_id)

    def export_runbook_markdown(self, runbook_id: str) -> str:
        """Export runbook as markdown."""
        runbook = self.runbooks.get(runbook_id)
        if not runbook:
            raise ValueError(f"Runbook {runbook_id} not found")

        md = f"""# {runbook.title}

**Version:** {runbook.version}
**Last Updated:** {runbook.last_updated.strftime('%Y-%m-%d')}
**Owner:** {runbook.owner}

## Overview

{runbook.description}

**Scenario:** {runbook.scenario}
**Severity:** {runbook.severity}
**Estimated Time:** {runbook.estimated_time_minutes} minutes

## Prerequisites

"""
        for prereq in runbook.prerequisites:
            md += f"- [ ] {prereq}\n"

        md += """

## Roles Required

"""
        for role in runbook.roles_required:
            md += f"- {role}\n"

        md += """

## Steps

"""
        for step in runbook.steps:
            md += f"""### Step {step.order}: {step.title}

{step.description}

**Commands:**
```bash
{chr(10).join(step.commands)}
```

**Expected Output:** {step.expected_output}

**Verification:** {step.verification}

"""
            if step.rollback:
                md += f"**Rollback:** {step.rollback}\n\n"

            if step.notes:
                md += "**Notes:**\n"
                for note in step.notes:
                    md += f"- {note}\n"
                md += "\n"

        md += """## Post-Recovery Steps

"""
        for step in runbook.post_recovery_steps:
            md += f"- [ ] {step}\n"

        md += """

## Communication Templates

"""
        for template_name, template in runbook.communication_templates.items():
            md += f"### {template_name.title()}\n\n{template}\n\n"

        return md
```

---

## Summary

This Disaster Recovery Guide provides comprehensive frameworks for:

1. **Recovery Objectives** - RTO/RPO definitions, service tiers, and DR strategies

2. **Backup Management** - Policies, scheduling, verification, and health monitoring

3. **Failover Procedures** - Automated failover, database failover, and health-based routing

4. **DR Testing** - Test scenarios, execution tracking, and metrics

5. **Runbook Documentation** - Step-by-step recovery procedures with verification

Key principles:
- **Defined objectives**: Clear RTO/RPO for each service tier
- **Regular testing**: Validated DR procedures through periodic tests
- **Automation**: Automated detection and failover where appropriate
- **Documentation**: Detailed runbooks for all disaster scenarios
- **Verification**: Validated backups and recovery procedures
- **Continuous improvement**: Learn from tests and incidents
