# 14.2 Cloud Cost Optimization Guide

## Document Information
- **Version**: 1.0
- **Last Updated**: 2024-01-15
- **Owner**: Platform Engineering and FinOps Teams
- **Classification**: Internal

## Purpose and Scope

This guide provides comprehensive strategies and tools for optimizing cloud costs across AWS, GCP, and Azure for the Multi-Cloud RAG Platform. It covers rightsizing, reserved capacity, spot instances, storage optimization, and network cost reduction.

## Prerequisites

- Access to cloud provider billing consoles
- Cost Explorer / Cost Management access
- Understanding of platform architecture
- Familiarity with FinOps principles

## 1. Cloud Cost Visibility

### 1.1 Multi-Cloud Cost Aggregation

```python
from dataclasses import dataclass, field
from typing import Dict, List, Optional, Any
from datetime import datetime, timedelta
from decimal import Decimal
from enum import Enum
import boto3
from google.cloud import billing_v1
import azure.mgmt.costmanagement as azure_cost


class CloudProvider(Enum):
    """Cloud providers."""
    AWS = "aws"
    GCP = "gcp"
    AZURE = "azure"


@dataclass
class CloudCostRecord:
    """Standardized cost record across clouds."""
    provider: CloudProvider
    service: str
    resource_id: str
    resource_name: str
    cost: Decimal
    usage_quantity: float
    usage_unit: str
    region: str
    date: datetime
    tags: Dict[str, str] = field(default_factory=dict)
    account_id: str = ""
    project_id: str = ""


class AWSCostCollector:
    """Collect costs from AWS."""

    def __init__(self, regions: List[str] = None):
        self.ce_client = boto3.client("ce", region_name="us-east-1")
        self.regions = regions or ["us-east-1", "us-west-2", "eu-west-1"]

    def get_costs(
        self,
        start_date: datetime,
        end_date: datetime,
        granularity: str = "DAILY"
    ) -> List[CloudCostRecord]:
        """Get AWS costs for date range."""
        response = self.ce_client.get_cost_and_usage(
            TimePeriod={
                "Start": start_date.strftime("%Y-%m-%d"),
                "End": end_date.strftime("%Y-%m-%d")
            },
            Granularity=granularity,
            Metrics=["BlendedCost", "UsageQuantity"],
            GroupBy=[
                {"Type": "DIMENSION", "Key": "SERVICE"},
                {"Type": "DIMENSION", "Key": "REGION"}
            ]
        )

        records = []
        for result in response.get("ResultsByTime", []):
            date = datetime.strptime(result["TimePeriod"]["Start"], "%Y-%m-%d")
            for group in result.get("Groups", []):
                keys = group["Keys"]
                service = keys[0]
                region = keys[1] if len(keys) > 1 else "global"

                records.append(CloudCostRecord(
                    provider=CloudProvider.AWS,
                    service=service,
                    resource_id="",
                    resource_name=service,
                    cost=Decimal(group["Metrics"]["BlendedCost"]["Amount"]),
                    usage_quantity=float(group["Metrics"].get("UsageQuantity", {}).get("Amount", 0)),
                    usage_unit=group["Metrics"].get("UsageQuantity", {}).get("Unit", ""),
                    region=region,
                    date=date
                ))

        return records

    def get_resource_costs(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> List[CloudCostRecord]:
        """Get costs grouped by resource."""
        response = self.ce_client.get_cost_and_usage(
            TimePeriod={
                "Start": start_date.strftime("%Y-%m-%d"),
                "End": end_date.strftime("%Y-%m-%d")
            },
            Granularity="MONTHLY",
            Metrics=["BlendedCost"],
            GroupBy=[
                {"Type": "DIMENSION", "Key": "RESOURCE_ID"}
            ],
            Filter={
                "Not": {
                    "Dimensions": {
                        "Key": "RESOURCE_ID",
                        "Values": [""]
                    }
                }
            }
        )

        records = []
        for result in response.get("ResultsByTime", []):
            date = datetime.strptime(result["TimePeriod"]["Start"], "%Y-%m-%d")
            for group in result.get("Groups", []):
                resource_id = group["Keys"][0]
                records.append(CloudCostRecord(
                    provider=CloudProvider.AWS,
                    service="",
                    resource_id=resource_id,
                    resource_name=resource_id,
                    cost=Decimal(group["Metrics"]["BlendedCost"]["Amount"]),
                    usage_quantity=0,
                    usage_unit="",
                    region="",
                    date=date
                ))

        return records


class GCPCostCollector:
    """Collect costs from GCP."""

    def __init__(self, billing_account_id: str):
        self.billing_account_id = billing_account_id
        self.client = billing_v1.CloudBillingClient()

    def get_costs(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> List[CloudCostRecord]:
        """Get GCP costs for date range."""
        # GCP uses BigQuery for detailed billing exports
        # This is a simplified implementation
        from google.cloud import bigquery

        client = bigquery.Client()

        query = f"""
        SELECT
            service.description as service,
            sku.description as resource_name,
            location.region as region,
            usage_start_time,
            cost,
            usage.amount as usage_quantity,
            usage.unit as usage_unit,
            project.id as project_id
        FROM `{self.billing_account_id}.cloud_billing_export`
        WHERE usage_start_time >= @start_date
          AND usage_start_time < @end_date
        """

        job_config = bigquery.QueryJobConfig(
            query_parameters=[
                bigquery.ScalarQueryParameter("start_date", "TIMESTAMP", start_date),
                bigquery.ScalarQueryParameter("end_date", "TIMESTAMP", end_date)
            ]
        )

        records = []
        results = client.query(query, job_config=job_config)

        for row in results:
            records.append(CloudCostRecord(
                provider=CloudProvider.GCP,
                service=row.service,
                resource_id="",
                resource_name=row.resource_name,
                cost=Decimal(str(row.cost)),
                usage_quantity=row.usage_quantity or 0,
                usage_unit=row.usage_unit or "",
                region=row.region or "global",
                date=row.usage_start_time,
                project_id=row.project_id
            ))

        return records


class AzureCostCollector:
    """Collect costs from Azure."""

    def __init__(self, subscription_id: str, credentials):
        self.subscription_id = subscription_id
        self.credentials = credentials

    def get_costs(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> List[CloudCostRecord]:
        """Get Azure costs for date range."""
        from azure.mgmt.costmanagement import CostManagementClient
        from azure.mgmt.costmanagement.models import (
            QueryDefinition, QueryTimePeriod, QueryDataset,
            QueryAggregation, QueryGrouping, GranularityType
        )

        client = CostManagementClient(self.credentials)

        scope = f"/subscriptions/{self.subscription_id}"

        query = QueryDefinition(
            type="ActualCost",
            timeframe="Custom",
            time_period=QueryTimePeriod(
                from_property=start_date,
                to=end_date
            ),
            dataset=QueryDataset(
                granularity=GranularityType.DAILY,
                aggregation={
                    "totalCost": QueryAggregation(
                        name="Cost",
                        function="Sum"
                    )
                },
                grouping=[
                    QueryGrouping(type="Dimension", name="ServiceName"),
                    QueryGrouping(type="Dimension", name="ResourceLocation")
                ]
            )
        )

        result = client.query.usage(scope, query)

        records = []
        for row in result.rows:
            records.append(CloudCostRecord(
                provider=CloudProvider.AZURE,
                service=row[0],
                resource_id="",
                resource_name=row[0],
                cost=Decimal(str(row[2])),
                usage_quantity=0,
                usage_unit="",
                region=row[1],
                date=datetime.strptime(row[3], "%Y%m%d")
            ))

        return records


class MultiCloudCostAggregator:
    """Aggregate costs across multiple cloud providers."""

    def __init__(self):
        self.collectors: Dict[CloudProvider, Any] = {}
        self.cost_records: List[CloudCostRecord] = []

    def add_collector(self, provider: CloudProvider, collector):
        """Add a cost collector for a provider."""
        self.collectors[provider] = collector

    def collect_all_costs(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> List[CloudCostRecord]:
        """Collect costs from all configured providers."""
        self.cost_records = []

        for provider, collector in self.collectors.items():
            try:
                records = collector.get_costs(start_date, end_date)
                self.cost_records.extend(records)
            except Exception as e:
                print(f"Error collecting costs from {provider.value}: {e}")

        return self.cost_records

    def get_summary(self) -> Dict:
        """Get aggregated cost summary."""
        by_provider: Dict[str, Decimal] = {}
        by_service: Dict[str, Decimal] = {}
        by_region: Dict[str, Decimal] = {}

        for record in self.cost_records:
            provider = record.provider.value
            by_provider[provider] = by_provider.get(provider, Decimal("0")) + record.cost

            service_key = f"{provider}/{record.service}"
            by_service[service_key] = by_service.get(service_key, Decimal("0")) + record.cost

            by_region[record.region] = by_region.get(record.region, Decimal("0")) + record.cost

        total = sum(by_provider.values())

        return {
            "total_cost": float(total),
            "by_provider": {k: float(v) for k, v in by_provider.items()},
            "by_service": dict(sorted(
                {k: float(v) for k, v in by_service.items()}.items(),
                key=lambda x: x[1],
                reverse=True
            )[:20]),
            "by_region": {k: float(v) for k, v in by_region.items()}
        }

    def get_daily_trend(self, days: int = 30) -> List[Dict]:
        """Get daily cost trend."""
        daily: Dict[str, Dict[str, Decimal]] = {}

        for record in self.cost_records:
            date_key = record.date.strftime("%Y-%m-%d")
            provider = record.provider.value

            if date_key not in daily:
                daily[date_key] = {}

            daily[date_key][provider] = daily[date_key].get(provider, Decimal("0")) + record.cost

        trend = []
        for date_key in sorted(daily.keys()):
            entry = {"date": date_key}
            entry.update({k: float(v) for k, v in daily[date_key].items()})
            entry["total"] = sum(float(v) for v in daily[date_key].values())
            trend.append(entry)

        return trend[-days:]
```

### 1.2 Cost Tagging and Allocation

```python
from dataclasses import dataclass
from typing import Dict, List, Optional
from enum import Enum


class TaggingCompliance(Enum):
    """Tagging compliance levels."""
    COMPLIANT = "compliant"
    PARTIAL = "partial"
    NON_COMPLIANT = "non_compliant"


@dataclass
class TagPolicy:
    """Tagging policy definition."""
    tag_key: str
    required: bool
    allowed_values: Optional[List[str]] = None
    default_value: Optional[str] = None
    description: str = ""


class CostTaggingManager:
    """Manage cost allocation tagging."""

    def __init__(self):
        self.policies: Dict[str, TagPolicy] = {}
        self.tag_mappings: Dict[str, Dict[str, str]] = {}

    def define_policy(self, policy: TagPolicy):
        """Define a tagging policy."""
        self.policies[policy.tag_key] = policy

    def evaluate_resource(
        self,
        resource_id: str,
        current_tags: Dict[str, str]
    ) -> Dict:
        """Evaluate resource tagging compliance."""
        missing_required = []
        invalid_values = []
        present_tags = []

        for tag_key, policy in self.policies.items():
            if tag_key in current_tags:
                present_tags.append(tag_key)
                if policy.allowed_values and current_tags[tag_key] not in policy.allowed_values:
                    invalid_values.append({
                        "tag": tag_key,
                        "value": current_tags[tag_key],
                        "allowed": policy.allowed_values
                    })
            elif policy.required:
                missing_required.append(tag_key)

        if missing_required or invalid_values:
            compliance = TaggingCompliance.NON_COMPLIANT
        elif len(present_tags) < len(self.policies):
            compliance = TaggingCompliance.PARTIAL
        else:
            compliance = TaggingCompliance.COMPLIANT

        return {
            "resource_id": resource_id,
            "compliance": compliance.value,
            "present_tags": present_tags,
            "missing_required": missing_required,
            "invalid_values": invalid_values,
            "recommendations": self._generate_recommendations(missing_required, invalid_values)
        }

    def _generate_recommendations(
        self,
        missing: List[str],
        invalid: List[Dict]
    ) -> List[str]:
        """Generate tagging recommendations."""
        recommendations = []

        for tag_key in missing:
            policy = self.policies[tag_key]
            if policy.default_value:
                recommendations.append(
                    f"Add tag '{tag_key}' with default value '{policy.default_value}'"
                )
            else:
                recommendations.append(f"Add required tag '{tag_key}'")

        for inv in invalid:
            recommendations.append(
                f"Update tag '{inv['tag']}' to one of: {', '.join(inv['allowed'])}"
            )

        return recommendations

    def get_untagged_costs(
        self,
        records: List[CloudCostRecord],
        tag_key: str
    ) -> Dict:
        """Analyze costs for untagged resources."""
        tagged_cost = Decimal("0")
        untagged_cost = Decimal("0")

        for record in records:
            if tag_key in record.tags:
                tagged_cost += record.cost
            else:
                untagged_cost += record.cost

        total = tagged_cost + untagged_cost

        return {
            "tag_key": tag_key,
            "tagged_cost": float(tagged_cost),
            "untagged_cost": float(untagged_cost),
            "tagged_percentage": float(tagged_cost / total * 100) if total else 0,
            "coverage_goal": 95.0,
            "gap_to_goal": max(0, 95.0 - float(tagged_cost / total * 100)) if total else 95.0
        }

    @classmethod
    def create_standard_policies(cls) -> 'CostTaggingManager':
        """Create manager with standard tagging policies."""
        manager = cls()

        manager.define_policy(TagPolicy(
            tag_key="environment",
            required=True,
            allowed_values=["production", "staging", "development", "test"],
            description="Deployment environment"
        ))

        manager.define_policy(TagPolicy(
            tag_key="team",
            required=True,
            description="Owning team"
        ))

        manager.define_policy(TagPolicy(
            tag_key="project",
            required=True,
            description="Project or product name"
        ))

        manager.define_policy(TagPolicy(
            tag_key="cost-center",
            required=True,
            description="Financial cost center"
        ))

        manager.define_policy(TagPolicy(
            tag_key="application",
            required=False,
            description="Application name"
        ))

        manager.define_policy(TagPolicy(
            tag_key="owner",
            required=False,
            description="Technical owner email"
        ))

        return manager
```

## 2. Compute Optimization

### 2.1 Rightsizing Recommendations

```python
from dataclasses import dataclass
from typing import Dict, List, Optional, Tuple
from decimal import Decimal
import boto3


@dataclass
class InstanceMetrics:
    """Instance utilization metrics."""
    instance_id: str
    instance_type: str
    avg_cpu_percent: float
    max_cpu_percent: float
    avg_memory_percent: float
    max_memory_percent: float
    avg_network_in_mbps: float
    avg_network_out_mbps: float
    monthly_cost: Decimal


@dataclass
class RightsizingRecommendation:
    """Rightsizing recommendation."""
    instance_id: str
    current_type: str
    recommended_type: str
    current_cost: Decimal
    recommended_cost: Decimal
    monthly_savings: Decimal
    reason: str
    risk_level: str  # low, medium, high


class EC2RightsizingAnalyzer:
    """Analyze EC2 instances for rightsizing opportunities."""

    def __init__(self, region: str = "us-east-1"):
        self.ec2 = boto3.client("ec2", region_name=region)
        self.cloudwatch = boto3.client("cloudwatch", region_name=region)
        self.pricing = boto3.client("pricing", region_name="us-east-1")

        # Instance family upgrade paths
        self.upgrade_paths = {
            "t3": ["t3", "m6i", "c6i"],
            "t3a": ["t3a", "m6a", "c6a"],
            "m5": ["m5", "m6i", "c6i"],
            "m6i": ["m6i", "c6i", "r6i"],
            "c5": ["c5", "c6i", "m6i"],
            "r5": ["r5", "r6i", "x2idn"]
        }

        # Size progression within family
        self.sizes = ["nano", "micro", "small", "medium", "large", "xlarge", "2xlarge", "4xlarge", "8xlarge", "12xlarge", "16xlarge", "24xlarge"]

    def get_instance_metrics(
        self,
        instance_id: str,
        days: int = 14
    ) -> Optional[InstanceMetrics]:
        """Get utilization metrics for an instance."""
        end_time = datetime.utcnow()
        start_time = end_time - timedelta(days=days)

        # Get instance type
        response = self.ec2.describe_instances(InstanceIds=[instance_id])
        if not response["Reservations"]:
            return None

        instance = response["Reservations"][0]["Instances"][0]
        instance_type = instance["InstanceType"]

        # Get CloudWatch metrics
        cpu_stats = self._get_metric_stats(
            "AWS/EC2", "CPUUtilization",
            [{"Name": "InstanceId", "Value": instance_id}],
            start_time, end_time
        )

        network_in = self._get_metric_stats(
            "AWS/EC2", "NetworkIn",
            [{"Name": "InstanceId", "Value": instance_id}],
            start_time, end_time
        )

        network_out = self._get_metric_stats(
            "AWS/EC2", "NetworkOut",
            [{"Name": "InstanceId", "Value": instance_id}],
            start_time, end_time
        )

        # Get memory metrics (requires CloudWatch agent)
        memory_stats = self._get_metric_stats(
            "CWAgent", "mem_used_percent",
            [{"Name": "InstanceId", "Value": instance_id}],
            start_time, end_time
        )

        return InstanceMetrics(
            instance_id=instance_id,
            instance_type=instance_type,
            avg_cpu_percent=cpu_stats.get("avg", 0),
            max_cpu_percent=cpu_stats.get("max", 0),
            avg_memory_percent=memory_stats.get("avg", 50),  # Default if no agent
            max_memory_percent=memory_stats.get("max", 50),
            avg_network_in_mbps=network_in.get("avg", 0) / 1024 / 1024,
            avg_network_out_mbps=network_out.get("avg", 0) / 1024 / 1024,
            monthly_cost=self._get_instance_cost(instance_type)
        )

    def _get_metric_stats(
        self,
        namespace: str,
        metric_name: str,
        dimensions: List[Dict],
        start_time: datetime,
        end_time: datetime
    ) -> Dict[str, float]:
        """Get metric statistics from CloudWatch."""
        try:
            response = self.cloudwatch.get_metric_statistics(
                Namespace=namespace,
                MetricName=metric_name,
                Dimensions=dimensions,
                StartTime=start_time,
                EndTime=end_time,
                Period=3600,
                Statistics=["Average", "Maximum"]
            )

            if not response["Datapoints"]:
                return {}

            avg = sum(d["Average"] for d in response["Datapoints"]) / len(response["Datapoints"])
            max_val = max(d["Maximum"] for d in response["Datapoints"])

            return {"avg": avg, "max": max_val}
        except Exception:
            return {}

    def _get_instance_cost(self, instance_type: str) -> Decimal:
        """Get monthly cost for an instance type."""
        # Simplified - would use pricing API in production
        pricing_map = {
            "t3.micro": Decimal("7.59"),
            "t3.small": Decimal("15.18"),
            "t3.medium": Decimal("30.37"),
            "t3.large": Decimal("60.74"),
            "t3.xlarge": Decimal("121.47"),
            "m6i.large": Decimal("69.35"),
            "m6i.xlarge": Decimal("138.70"),
            "m6i.2xlarge": Decimal("277.40"),
            "c6i.large": Decimal("61.32"),
            "c6i.xlarge": Decimal("122.64"),
            "c6i.2xlarge": Decimal("245.28"),
            "r6i.large": Decimal("90.52"),
            "r6i.xlarge": Decimal("181.04")
        }
        return pricing_map.get(instance_type, Decimal("100"))

    def analyze_instance(
        self,
        metrics: InstanceMetrics
    ) -> Optional[RightsizingRecommendation]:
        """Analyze an instance and generate recommendation."""
        # Determine current instance family and size
        parts = metrics.instance_type.split(".")
        family = parts[0]
        size = parts[1] if len(parts) > 1 else "large"

        recommendation = None

        # Check for underutilization (downsize opportunity)
        if metrics.avg_cpu_percent < 20 and metrics.max_cpu_percent < 40:
            smaller_type = self._get_smaller_instance(family, size)
            if smaller_type:
                smaller_cost = self._get_instance_cost(smaller_type)
                recommendation = RightsizingRecommendation(
                    instance_id=metrics.instance_id,
                    current_type=metrics.instance_type,
                    recommended_type=smaller_type,
                    current_cost=metrics.monthly_cost,
                    recommended_cost=smaller_cost,
                    monthly_savings=metrics.monthly_cost - smaller_cost,
                    reason=f"Low utilization (avg CPU: {metrics.avg_cpu_percent:.1f}%, max: {metrics.max_cpu_percent:.1f}%)",
                    risk_level="low" if metrics.max_cpu_percent < 30 else "medium"
                )

        # Check for overutilization (upsize needed)
        elif metrics.avg_cpu_percent > 80 or metrics.max_cpu_percent > 95:
            larger_type = self._get_larger_instance(family, size)
            if larger_type:
                larger_cost = self._get_instance_cost(larger_type)
                recommendation = RightsizingRecommendation(
                    instance_id=metrics.instance_id,
                    current_type=metrics.instance_type,
                    recommended_type=larger_type,
                    current_cost=metrics.monthly_cost,
                    recommended_cost=larger_cost,
                    monthly_savings=metrics.monthly_cost - larger_cost,  # Will be negative
                    reason=f"High utilization (avg CPU: {metrics.avg_cpu_percent:.1f}%, max: {metrics.max_cpu_percent:.1f}%)",
                    risk_level="high"
                )

        # Check for family change opportunity
        elif metrics.avg_cpu_percent > 50 and metrics.avg_memory_percent < 30:
            # CPU-bound, switch to compute-optimized
            compute_type = f"c6i.{size}"
            compute_cost = self._get_instance_cost(compute_type)
            if compute_cost < metrics.monthly_cost:
                recommendation = RightsizingRecommendation(
                    instance_id=metrics.instance_id,
                    current_type=metrics.instance_type,
                    recommended_type=compute_type,
                    current_cost=metrics.monthly_cost,
                    recommended_cost=compute_cost,
                    monthly_savings=metrics.monthly_cost - compute_cost,
                    reason="CPU-bound workload, consider compute-optimized",
                    risk_level="medium"
                )

        return recommendation

    def _get_smaller_instance(
        self,
        family: str,
        current_size: str
    ) -> Optional[str]:
        """Get the next smaller instance size."""
        try:
            current_idx = self.sizes.index(current_size)
            if current_idx > 0:
                return f"{family}.{self.sizes[current_idx - 1]}"
        except ValueError:
            pass
        return None

    def _get_larger_instance(
        self,
        family: str,
        current_size: str
    ) -> Optional[str]:
        """Get the next larger instance size."""
        try:
            current_idx = self.sizes.index(current_size)
            if current_idx < len(self.sizes) - 1:
                return f"{family}.{self.sizes[current_idx + 1]}"
        except ValueError:
            pass
        return None

    def analyze_all_instances(
        self,
        days: int = 14
    ) -> List[RightsizingRecommendation]:
        """Analyze all running instances."""
        recommendations = []

        # Get all running instances
        response = self.ec2.describe_instances(
            Filters=[{"Name": "instance-state-name", "Values": ["running"]}]
        )

        for reservation in response["Reservations"]:
            for instance in reservation["Instances"]:
                instance_id = instance["InstanceId"]
                metrics = self.get_instance_metrics(instance_id, days)
                if metrics:
                    rec = self.analyze_instance(metrics)
                    if rec:
                        recommendations.append(rec)

        # Sort by savings potential
        recommendations.sort(key=lambda r: r.monthly_savings, reverse=True)

        return recommendations

    def generate_report(
        self,
        recommendations: List[RightsizingRecommendation]
    ) -> str:
        """Generate rightsizing report."""
        report = "# EC2 Rightsizing Report\n\n"
        report += f"**Generated**: {datetime.utcnow().strftime('%Y-%m-%d %H:%M UTC')}\n\n"

        total_savings = sum(r.monthly_savings for r in recommendations if r.monthly_savings > 0)
        downsizes = [r for r in recommendations if r.monthly_savings > 0]
        upsizes = [r for r in recommendations if r.monthly_savings < 0]

        report += f"## Summary\n\n"
        report += f"- Total instances analyzed: {len(recommendations)}\n"
        report += f"- Downsize recommendations: {len(downsizes)}\n"
        report += f"- Upsize recommendations: {len(upsizes)}\n"
        report += f"- **Potential monthly savings**: ${total_savings:,.2f}\n\n"

        if downsizes:
            report += "## Downsize Opportunities\n\n"
            report += "| Instance | Current | Recommended | Monthly Savings | Risk |\n"
            report += "|----------|---------|-------------|-----------------|------|\n"
            for r in downsizes[:20]:
                report += f"| {r.instance_id} | {r.current_type} | {r.recommended_type} | ${r.monthly_savings:,.2f} | {r.risk_level} |\n"

        if upsizes:
            report += "\n## Performance Concerns (Upsize Needed)\n\n"
            report += "| Instance | Current | Recommended | Reason |\n"
            report += "|----------|---------|-------------|--------|\n"
            for r in upsizes:
                report += f"| {r.instance_id} | {r.current_type} | {r.recommended_type} | {r.reason} |\n"

        return report
```

### 2.2 Reserved Instance and Savings Plans Optimizer

```python
from dataclasses import dataclass
from typing import Dict, List, Optional
from decimal import Decimal
from datetime import datetime, timedelta


@dataclass
class ReservationCoverage:
    """Current reservation coverage."""
    instance_family: str
    region: str
    on_demand_hours: float
    reserved_hours: float
    savings_plan_hours: float
    total_hours: float

    @property
    def coverage_percent(self) -> float:
        covered = self.reserved_hours + self.savings_plan_hours
        return (covered / self.total_hours * 100) if self.total_hours else 0


@dataclass
class ReservationPurchaseRecommendation:
    """Recommendation for reservation purchase."""
    recommendation_type: str  # reserved_instance, compute_savings_plan, ec2_savings_plan
    instance_family: str
    region: str
    quantity: int
    term: str  # 1yr, 3yr
    payment_option: str  # no_upfront, partial_upfront, all_upfront
    estimated_monthly_savings: Decimal
    estimated_upfront_cost: Decimal
    break_even_months: int


class ReservationOptimizer:
    """Optimize reserved instances and savings plans."""

    def __init__(self, region: str = "us-east-1"):
        self.ce_client = boto3.client("ce", region_name=region)
        self.ec2_client = boto3.client("ec2", region_name=region)

    def get_reservation_coverage(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> List[ReservationCoverage]:
        """Get current reservation coverage."""
        response = self.ce_client.get_reservation_coverage(
            TimePeriod={
                "Start": start_date.strftime("%Y-%m-%d"),
                "End": end_date.strftime("%Y-%m-%d")
            },
            Granularity="MONTHLY",
            GroupBy=[
                {"Type": "DIMENSION", "Key": "INSTANCE_TYPE_FAMILY"},
                {"Type": "DIMENSION", "Key": "REGION"}
            ]
        )

        coverages = []
        for result in response.get("CoveragesByTime", []):
            for group in result.get("Groups", []):
                keys = group["Keys"]
                coverage = group["Coverage"]

                coverages.append(ReservationCoverage(
                    instance_family=keys[0],
                    region=keys[1] if len(keys) > 1 else "global",
                    on_demand_hours=float(coverage["CoverageHours"].get("OnDemandHours", 0)),
                    reserved_hours=float(coverage["CoverageHours"].get("ReservedHours", 0)),
                    savings_plan_hours=0,  # Would need separate API call
                    total_hours=float(coverage["CoverageHours"].get("TotalRunningHours", 0))
                ))

        return coverages

    def get_reservation_recommendations(
        self,
        lookback_days: int = 30,
        term: str = "ONE_YEAR",
        payment_option: str = "NO_UPFRONT"
    ) -> List[ReservationPurchaseRecommendation]:
        """Get AWS reservation recommendations."""
        response = self.ce_client.get_reservation_purchase_recommendation(
            Service="Amazon Elastic Compute Cloud - Compute",
            LookbackPeriodInDays=f"SIXTY_DAYS" if lookback_days > 30 else "THIRTY_DAYS",
            TermInYears=term,
            PaymentOption=payment_option
        )

        recommendations = []
        for rec in response.get("Recommendations", []):
            for detail in rec.get("RecommendationDetails", []):
                instance_details = detail.get("InstanceDetails", {}).get("EC2InstanceDetails", {})

                recommendations.append(ReservationPurchaseRecommendation(
                    recommendation_type="reserved_instance",
                    instance_family=instance_details.get("Family", ""),
                    region=instance_details.get("Region", ""),
                    quantity=int(detail.get("RecommendedNumberOfInstancesToPurchase", 0)),
                    term="1yr" if term == "ONE_YEAR" else "3yr",
                    payment_option=payment_option.lower().replace("_", " "),
                    estimated_monthly_savings=Decimal(detail.get("EstimatedMonthlySavingsAmount", "0")),
                    estimated_upfront_cost=Decimal(detail.get("UpfrontCost", "0")),
                    break_even_months=int(float(detail.get("UpfrontCost", "0")) /
                                         float(detail.get("EstimatedMonthlySavingsAmount", "1")))
                    if float(detail.get("EstimatedMonthlySavingsAmount", "0")) > 0 else 0
                ))

        return recommendations

    def analyze_savings_plan_opportunity(
        self,
        hourly_commitment: Decimal,
        term: str = "1yr"
    ) -> Dict:
        """Analyze savings plan opportunity."""
        # Get current on-demand spend
        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=30)

        response = self.ce_client.get_cost_and_usage(
            TimePeriod={
                "Start": start_date.strftime("%Y-%m-%d"),
                "End": end_date.strftime("%Y-%m-%d")
            },
            Granularity="MONTHLY",
            Metrics=["BlendedCost"],
            Filter={
                "Dimensions": {
                    "Key": "SERVICE",
                    "Values": ["Amazon Elastic Compute Cloud - Compute"]
                }
            }
        )

        monthly_ec2_cost = Decimal("0")
        for result in response.get("ResultsByTime", []):
            monthly_ec2_cost += Decimal(result["Total"]["BlendedCost"]["Amount"])

        # Calculate savings with savings plan
        # Compute Savings Plans typically offer 17-20% savings for 1yr no upfront
        savings_rate = Decimal("0.17") if term == "1yr" else Decimal("0.30")
        monthly_commitment = hourly_commitment * 730  # Hours per month

        potential_savings = min(monthly_commitment, monthly_ec2_cost) * savings_rate

        return {
            "current_monthly_ec2_cost": float(monthly_ec2_cost),
            "hourly_commitment": float(hourly_commitment),
            "monthly_commitment": float(monthly_commitment),
            "savings_rate": float(savings_rate * 100),
            "estimated_monthly_savings": float(potential_savings),
            "coverage_percentage": float(monthly_commitment / monthly_ec2_cost * 100) if monthly_ec2_cost else 0,
            "recommendation": "purchase" if potential_savings > Decimal("100") else "review"
        }

    def generate_optimization_report(self) -> str:
        """Generate comprehensive reservation optimization report."""
        report = "# Reservation Optimization Report\n\n"

        # Get coverage
        end_date = datetime.utcnow()
        start_date = end_date - timedelta(days=30)
        coverages = self.get_reservation_coverage(start_date, end_date)

        report += "## Current Coverage\n\n"
        report += "| Instance Family | Region | Coverage % | On-Demand Hours | Reserved Hours |\n"
        report += "|-----------------|--------|------------|-----------------|----------------|\n"

        total_covered = 0
        total_hours = 0
        for cov in coverages:
            report += f"| {cov.instance_family} | {cov.region} | {cov.coverage_percent:.1f}% | {cov.on_demand_hours:,.0f} | {cov.reserved_hours:,.0f} |\n"
            total_covered += cov.reserved_hours
            total_hours += cov.total_hours

        overall_coverage = (total_covered / total_hours * 100) if total_hours else 0
        report += f"\n**Overall Coverage**: {overall_coverage:.1f}%\n"
        report += f"**Target Coverage**: 70-80%\n\n"

        # Get recommendations
        recommendations = self.get_reservation_recommendations()

        if recommendations:
            report += "## Purchase Recommendations\n\n"
            report += "| Type | Instance Family | Region | Quantity | Monthly Savings | Upfront Cost |\n"
            report += "|------|-----------------|--------|----------|-----------------|---------------|\n"

            total_savings = Decimal("0")
            for rec in recommendations[:10]:
                report += f"| {rec.recommendation_type} | {rec.instance_family} | {rec.region} | {rec.quantity} | ${rec.estimated_monthly_savings:,.2f} | ${rec.estimated_upfront_cost:,.2f} |\n"
                total_savings += rec.estimated_monthly_savings

            report += f"\n**Total Potential Monthly Savings**: ${total_savings:,.2f}\n"

        return report
```

## 3. Storage Optimization

### 3.1 Storage Tier Optimization

```python
from dataclasses import dataclass
from typing import Dict, List, Optional
from decimal import Decimal
from datetime import datetime, timedelta
import boto3


@dataclass
class StorageAnalysis:
    """Analysis of storage usage."""
    bucket_name: str
    storage_class: str
    size_gb: float
    object_count: int
    last_access_days: int
    monthly_cost: Decimal
    recommended_class: str
    potential_savings: Decimal


class S3StorageOptimizer:
    """Optimize S3 storage costs."""

    def __init__(self, region: str = "us-east-1"):
        self.s3_client = boto3.client("s3", region_name=region)
        self.cloudwatch = boto3.client("cloudwatch", region_name=region)

        # Storage class pricing (per GB per month)
        self.pricing = {
            "STANDARD": Decimal("0.023"),
            "STANDARD_IA": Decimal("0.0125"),
            "ONEZONE_IA": Decimal("0.01"),
            "GLACIER_IR": Decimal("0.004"),
            "GLACIER": Decimal("0.0036"),
            "DEEP_ARCHIVE": Decimal("0.00099")
        }

    def analyze_bucket(
        self,
        bucket_name: str
    ) -> List[StorageAnalysis]:
        """Analyze a bucket for optimization opportunities."""
        analyses = []

        # Get bucket metrics
        storage_metrics = self._get_storage_metrics(bucket_name)

        for storage_class, metrics in storage_metrics.items():
            size_gb = metrics["size_bytes"] / (1024 ** 3)
            current_cost = Decimal(str(size_gb)) * self.pricing.get(storage_class, Decimal("0.023"))

            # Determine recommended class based on access patterns
            recommended = self._recommend_storage_class(
                storage_class,
                metrics.get("last_access_days", 0),
                size_gb
            )

            recommended_cost = Decimal(str(size_gb)) * self.pricing.get(recommended, Decimal("0.023"))
            savings = current_cost - recommended_cost

            analyses.append(StorageAnalysis(
                bucket_name=bucket_name,
                storage_class=storage_class,
                size_gb=size_gb,
                object_count=metrics.get("object_count", 0),
                last_access_days=metrics.get("last_access_days", 0),
                monthly_cost=current_cost,
                recommended_class=recommended,
                potential_savings=max(Decimal("0"), savings)
            ))

        return analyses

    def _get_storage_metrics(self, bucket_name: str) -> Dict:
        """Get storage metrics for a bucket."""
        metrics = {}

        # Get bucket size by storage class
        response = self.cloudwatch.get_metric_statistics(
            Namespace="AWS/S3",
            MetricName="BucketSizeBytes",
            Dimensions=[
                {"Name": "BucketName", "Value": bucket_name},
                {"Name": "StorageType", "Value": "StandardStorage"}
            ],
            StartTime=datetime.utcnow() - timedelta(days=1),
            EndTime=datetime.utcnow(),
            Period=86400,
            Statistics=["Average"]
        )

        if response["Datapoints"]:
            metrics["STANDARD"] = {
                "size_bytes": response["Datapoints"][0]["Average"],
                "last_access_days": 0  # Would need S3 Analytics for this
            }

        return metrics

    def _recommend_storage_class(
        self,
        current_class: str,
        last_access_days: int,
        size_gb: float
    ) -> str:
        """Recommend optimal storage class."""
        if last_access_days > 365:
            return "DEEP_ARCHIVE"
        elif last_access_days > 180:
            return "GLACIER"
        elif last_access_days > 90:
            return "GLACIER_IR"
        elif last_access_days > 30:
            if size_gb > 128:  # Large objects benefit from IA
                return "STANDARD_IA"
        return current_class

    def create_lifecycle_policy(
        self,
        bucket_name: str,
        transitions: List[Dict]
    ) -> Dict:
        """Create or update lifecycle policy for a bucket."""
        rules = []

        for i, transition in enumerate(transitions):
            rule = {
                "ID": f"optimization-rule-{i}",
                "Status": "Enabled",
                "Filter": {"Prefix": transition.get("prefix", "")},
                "Transitions": [
                    {
                        "Days": transition["days"],
                        "StorageClass": transition["storage_class"]
                    }
                ]
            }

            if transition.get("expire_days"):
                rule["Expiration"] = {"Days": transition["expire_days"]}

            rules.append(rule)

        lifecycle_config = {"Rules": rules}

        self.s3_client.put_bucket_lifecycle_configuration(
            Bucket=bucket_name,
            LifecycleConfiguration=lifecycle_config
        )

        return lifecycle_config

    def get_optimization_recommendations(
        self,
        buckets: List[str]
    ) -> Dict:
        """Get optimization recommendations for multiple buckets."""
        all_analyses = []
        total_savings = Decimal("0")

        for bucket in buckets:
            analyses = self.analyze_bucket(bucket)
            all_analyses.extend(analyses)
            total_savings += sum(a.potential_savings for a in analyses)

        # Generate lifecycle recommendations
        lifecycle_recommendations = []
        for analysis in all_analyses:
            if analysis.potential_savings > Decimal("10"):
                lifecycle_recommendations.append({
                    "bucket": analysis.bucket_name,
                    "current_class": analysis.storage_class,
                    "recommended_class": analysis.recommended_class,
                    "size_gb": analysis.size_gb,
                    "monthly_savings": float(analysis.potential_savings)
                })

        return {
            "total_monthly_savings": float(total_savings),
            "buckets_analyzed": len(buckets),
            "recommendations": lifecycle_recommendations,
            "suggested_lifecycle_policy": self._generate_lifecycle_template()
        }

    def _generate_lifecycle_template(self) -> Dict:
        """Generate a template lifecycle policy."""
        return {
            "Rules": [
                {
                    "ID": "archive-old-logs",
                    "Status": "Enabled",
                    "Filter": {"Prefix": "logs/"},
                    "Transitions": [
                        {"Days": 30, "StorageClass": "STANDARD_IA"},
                        {"Days": 90, "StorageClass": "GLACIER_IR"},
                        {"Days": 365, "StorageClass": "DEEP_ARCHIVE"}
                    ],
                    "Expiration": {"Days": 730}
                },
                {
                    "ID": "archive-old-embeddings",
                    "Status": "Enabled",
                    "Filter": {"Prefix": "embeddings/archive/"},
                    "Transitions": [
                        {"Days": 90, "StorageClass": "GLACIER_IR"}
                    ]
                }
            ]
        }


class EBSOptimizer:
    """Optimize EBS storage costs."""

    def __init__(self, region: str = "us-east-1"):
        self.ec2 = boto3.client("ec2", region_name=region)
        self.cloudwatch = boto3.client("cloudwatch", region_name=region)

        # EBS pricing (per GB per month)
        self.pricing = {
            "gp2": Decimal("0.10"),
            "gp3": Decimal("0.08"),
            "io1": Decimal("0.125"),
            "io2": Decimal("0.125"),
            "st1": Decimal("0.045"),
            "sc1": Decimal("0.015")
        }

    def analyze_volumes(self) -> List[Dict]:
        """Analyze all EBS volumes for optimization."""
        recommendations = []

        volumes = self.ec2.describe_volumes()["Volumes"]

        for volume in volumes:
            volume_id = volume["VolumeId"]
            volume_type = volume["VolumeType"]
            size = volume["Size"]
            iops = volume.get("Iops", 0)

            # Get utilization metrics
            utilization = self._get_volume_utilization(volume_id)

            current_cost = Decimal(str(size)) * self.pricing.get(volume_type, Decimal("0.10"))

            # Check for gp2 to gp3 migration
            if volume_type == "gp2":
                gp3_cost = Decimal(str(size)) * self.pricing["gp3"]
                savings = current_cost - gp3_cost

                if savings > 0:
                    recommendations.append({
                        "volume_id": volume_id,
                        "current_type": volume_type,
                        "recommended_type": "gp3",
                        "size_gb": size,
                        "current_monthly_cost": float(current_cost),
                        "recommended_monthly_cost": float(gp3_cost),
                        "monthly_savings": float(savings),
                        "reason": "gp3 is 20% cheaper than gp2 with same baseline performance"
                    })

            # Check for unattached volumes
            if volume["State"] == "available":
                recommendations.append({
                    "volume_id": volume_id,
                    "current_type": volume_type,
                    "recommended_type": "delete or snapshot",
                    "size_gb": size,
                    "current_monthly_cost": float(current_cost),
                    "recommended_monthly_cost": 0,
                    "monthly_savings": float(current_cost),
                    "reason": "Volume is unattached"
                })

            # Check for oversized volumes
            if utilization.get("used_percent", 100) < 30:
                recommended_size = max(int(size * utilization.get("used_percent", 100) / 100 * 1.5), 20)
                if recommended_size < size:
                    new_cost = Decimal(str(recommended_size)) * self.pricing.get(volume_type, Decimal("0.10"))
                    recommendations.append({
                        "volume_id": volume_id,
                        "current_type": volume_type,
                        "recommended_type": f"{volume_type} (resize to {recommended_size}GB)",
                        "size_gb": size,
                        "current_monthly_cost": float(current_cost),
                        "recommended_monthly_cost": float(new_cost),
                        "monthly_savings": float(current_cost - new_cost),
                        "reason": f"Volume is {100 - utilization.get('used_percent', 100):.0f}% empty"
                    })

        return sorted(recommendations, key=lambda x: x["monthly_savings"], reverse=True)

    def _get_volume_utilization(self, volume_id: str) -> Dict:
        """Get volume utilization metrics."""
        # This would require CloudWatch agent or custom metrics
        return {"used_percent": 50}  # Placeholder
```

## 4. Network Cost Optimization

### 4.1 Data Transfer Optimization

```python
from dataclasses import dataclass
from typing import Dict, List
from decimal import Decimal
from datetime import datetime, timedelta


@dataclass
class DataTransferAnalysis:
    """Analysis of data transfer costs."""
    source: str
    destination: str
    data_gb: float
    cost_per_gb: Decimal
    total_cost: Decimal
    optimization: str
    potential_savings: Decimal


class NetworkCostOptimizer:
    """Optimize network and data transfer costs."""

    def __init__(self):
        # Data transfer pricing (per GB)
        self.pricing = {
            "internet_out": Decimal("0.09"),
            "cross_region": Decimal("0.02"),
            "cross_az": Decimal("0.01"),
            "same_az": Decimal("0"),
            "vpc_endpoint": Decimal("0.01"),
            "nat_gateway": Decimal("0.045"),
            "cloudfront": Decimal("0.085")
        }

    def analyze_data_transfer(
        self,
        transfer_records: List[Dict]
    ) -> List[DataTransferAnalysis]:
        """Analyze data transfer for optimization opportunities."""
        analyses = []

        for record in transfer_records:
            source = record["source"]
            destination = record["destination"]
            data_gb = record["data_gb"]

            # Determine transfer type and cost
            transfer_type = self._classify_transfer(source, destination)
            cost_per_gb = self.pricing.get(transfer_type, Decimal("0.09"))
            total_cost = Decimal(str(data_gb)) * cost_per_gb

            # Generate optimization recommendation
            optimization, savings = self._get_optimization(
                transfer_type, data_gb, cost_per_gb
            )

            analyses.append(DataTransferAnalysis(
                source=source,
                destination=destination,
                data_gb=data_gb,
                cost_per_gb=cost_per_gb,
                total_cost=total_cost,
                optimization=optimization,
                potential_savings=savings
            ))

        return analyses

    def _classify_transfer(self, source: str, destination: str) -> str:
        """Classify the type of data transfer."""
        if "internet" in destination.lower():
            return "internet_out"
        elif source.split("-")[0:2] != destination.split("-")[0:2]:  # Different region
            return "cross_region"
        elif source != destination:
            return "cross_az"
        return "same_az"

    def _get_optimization(
        self,
        transfer_type: str,
        data_gb: float,
        cost_per_gb: Decimal
    ) -> tuple:
        """Get optimization recommendation and potential savings."""
        if transfer_type == "internet_out" and data_gb > 1000:
            # CloudFront can reduce costs for high-volume egress
            cf_cost = Decimal(str(data_gb)) * self.pricing["cloudfront"]
            current_cost = Decimal(str(data_gb)) * cost_per_gb
            savings = current_cost - cf_cost
            return "Use CloudFront for reduced egress pricing", savings

        elif transfer_type == "cross_region" and data_gb > 500:
            return "Consider regional data replication strategy", Decimal(str(data_gb)) * Decimal("0.01")

        elif transfer_type == "nat_gateway" and data_gb > 100:
            # VPC endpoints are cheaper for S3/DynamoDB
            vpc_cost = Decimal(str(data_gb)) * self.pricing["vpc_endpoint"]
            nat_cost = Decimal(str(data_gb)) * self.pricing["nat_gateway"]
            return "Use VPC endpoints for AWS service access", nat_cost - vpc_cost

        return "No optimization identified", Decimal("0")

    def generate_network_report(
        self,
        analyses: List[DataTransferAnalysis]
    ) -> str:
        """Generate network cost optimization report."""
        report = "# Network Cost Optimization Report\n\n"

        total_cost = sum(a.total_cost for a in analyses)
        total_savings = sum(a.potential_savings for a in analyses)

        report += f"## Summary\n\n"
        report += f"- Total data transfer: {sum(a.data_gb for a in analyses):,.0f} GB\n"
        report += f"- Total cost: ${total_cost:,.2f}\n"
        report += f"- Potential savings: ${total_savings:,.2f}\n\n"

        # Group by transfer type
        by_type: Dict[str, List[DataTransferAnalysis]] = {}
        for a in analyses:
            transfer_type = self._classify_transfer(a.source, a.destination)
            if transfer_type not in by_type:
                by_type[transfer_type] = []
            by_type[transfer_type].append(a)

        report += "## Cost by Transfer Type\n\n"
        report += "| Type | Data (GB) | Cost | Savings Opportunity |\n"
        report += "|------|-----------|------|---------------------|\n"

        for transfer_type, items in by_type.items():
            type_data = sum(a.data_gb for a in items)
            type_cost = sum(a.total_cost for a in items)
            type_savings = sum(a.potential_savings for a in items)
            report += f"| {transfer_type} | {type_data:,.0f} | ${type_cost:,.2f} | ${type_savings:,.2f} |\n"

        # List specific recommendations
        report += "\n## Recommendations\n\n"
        for a in analyses:
            if a.potential_savings > Decimal("100"):
                report += f"- **{a.source} -> {a.destination}**: {a.optimization} (save ${a.potential_savings:,.2f}/month)\n"

        return report


class VPCEndpointOptimizer:
    """Optimize VPC endpoint usage."""

    def __init__(self, region: str = "us-east-1"):
        self.ec2 = boto3.client("ec2", region_name=region)

    def analyze_endpoint_opportunities(self) -> List[Dict]:
        """Analyze opportunities for VPC endpoints."""
        recommendations = []

        # Get current VPC endpoints
        existing_endpoints = self.ec2.describe_vpc_endpoints()["VpcEndpoints"]
        existing_services = {ep["ServiceName"] for ep in existing_endpoints}

        # High-value endpoint services
        recommended_services = [
            {
                "service": "com.amazonaws.{region}.s3",
                "type": "Gateway",
                "savings_estimate": "Up to 90% on NAT gateway costs for S3"
            },
            {
                "service": "com.amazonaws.{region}.dynamodb",
                "type": "Gateway",
                "savings_estimate": "Up to 90% on NAT gateway costs for DynamoDB"
            },
            {
                "service": "com.amazonaws.{region}.ecr.api",
                "type": "Interface",
                "savings_estimate": "Reduces NAT costs for container image pulls"
            },
            {
                "service": "com.amazonaws.{region}.ecr.dkr",
                "type": "Interface",
                "savings_estimate": "Reduces NAT costs for container image pulls"
            },
            {
                "service": "com.amazonaws.{region}.secretsmanager",
                "type": "Interface",
                "savings_estimate": "Enhanced security and reduced latency"
            }
        ]

        for svc in recommended_services:
            service_name = svc["service"].format(region=self.ec2.meta.region_name)
            if service_name not in existing_services:
                recommendations.append({
                    "service": service_name,
                    "type": svc["type"],
                    "status": "Not configured",
                    "recommendation": f"Create {svc['type']} endpoint",
                    "savings_estimate": svc["savings_estimate"]
                })

        return recommendations
```

## 5. Cost Governance and Automation

### 5.1 Budget Management

```python
from dataclasses import dataclass
from typing import Dict, List, Optional, Callable
from decimal import Decimal
from datetime import datetime
import boto3


@dataclass
class Budget:
    """Budget definition."""
    name: str
    amount: Decimal
    period: str  # MONTHLY, QUARTERLY, ANNUALLY
    scope: Dict  # Filters for what the budget covers
    alerts: List[Dict]  # Threshold alerts


class BudgetManager:
    """Manage cloud budgets and alerts."""

    def __init__(self, account_id: str):
        self.budgets_client = boto3.client("budgets")
        self.account_id = account_id

    def create_budget(
        self,
        budget: Budget,
        notification_email: str
    ) -> Dict:
        """Create a budget with alerts."""
        budget_data = {
            "BudgetName": budget.name,
            "BudgetLimit": {
                "Amount": str(budget.amount),
                "Unit": "USD"
            },
            "BudgetType": "COST",
            "TimeUnit": budget.period,
            "CostFilters": budget.scope
        }

        notifications = []
        subscribers = [
            {
                "SubscriptionType": "EMAIL",
                "Address": notification_email
            }
        ]

        for alert in budget.alerts:
            notifications.append({
                "Notification": {
                    "NotificationType": alert.get("type", "ACTUAL"),
                    "ComparisonOperator": "GREATER_THAN",
                    "Threshold": alert["threshold"],
                    "ThresholdType": "PERCENTAGE"
                },
                "Subscribers": subscribers
            })

        self.budgets_client.create_budget(
            AccountId=self.account_id,
            Budget=budget_data,
            NotificationsWithSubscribers=notifications
        )

        return {"status": "created", "budget_name": budget.name}

    def get_budget_status(self, budget_name: str) -> Dict:
        """Get current budget status."""
        response = self.budgets_client.describe_budget(
            AccountId=self.account_id,
            BudgetName=budget_name
        )

        budget = response["Budget"]
        actual = Decimal(budget["CalculatedSpend"]["ActualSpend"]["Amount"])
        limit = Decimal(budget["BudgetLimit"]["Amount"])

        return {
            "name": budget_name,
            "limit": float(limit),
            "actual_spend": float(actual),
            "utilization_percent": float(actual / limit * 100) if limit else 0,
            "forecasted_spend": float(budget["CalculatedSpend"].get("ForecastedSpend", {}).get("Amount", 0)),
            "period": budget["TimeUnit"]
        }

    def list_budgets(self) -> List[Dict]:
        """List all budgets."""
        response = self.budgets_client.describe_budgets(AccountId=self.account_id)

        budgets = []
        for budget in response.get("Budgets", []):
            budgets.append({
                "name": budget["BudgetName"],
                "limit": float(budget["BudgetLimit"]["Amount"]),
                "type": budget["BudgetType"],
                "period": budget["TimeUnit"]
            })

        return budgets


class CostAnomalyDetector:
    """Detect cost anomalies."""

    def __init__(self):
        self.ce_client = boto3.client("ce", region_name="us-east-1")

    def create_anomaly_monitor(
        self,
        monitor_name: str,
        monitor_type: str = "DIMENSIONAL"
    ) -> str:
        """Create a cost anomaly monitor."""
        response = self.ce_client.create_anomaly_monitor(
            AnomalyMonitor={
                "MonitorName": monitor_name,
                "MonitorType": monitor_type,
                "MonitorDimension": "SERVICE"
            }
        )
        return response["MonitorArn"]

    def create_anomaly_subscription(
        self,
        subscription_name: str,
        monitor_arn: str,
        threshold: float,
        email: str
    ) -> str:
        """Create anomaly alert subscription."""
        response = self.ce_client.create_anomaly_subscription(
            AnomalySubscription={
                "SubscriptionName": subscription_name,
                "MonitorArnList": [monitor_arn],
                "Subscribers": [
                    {"Type": "EMAIL", "Address": email}
                ],
                "Threshold": threshold,
                "Frequency": "IMMEDIATE"
            }
        )
        return response["SubscriptionArn"]

    def get_anomalies(
        self,
        start_date: datetime,
        end_date: datetime
    ) -> List[Dict]:
        """Get detected anomalies."""
        response = self.ce_client.get_anomalies(
            DateInterval={
                "StartDate": start_date.strftime("%Y-%m-%d"),
                "EndDate": end_date.strftime("%Y-%m-%d")
            }
        )

        anomalies = []
        for anomaly in response.get("Anomalies", []):
            anomalies.append({
                "anomaly_id": anomaly["AnomalyId"],
                "start_date": anomaly["AnomalyStartDate"],
                "end_date": anomaly.get("AnomalyEndDate"),
                "impact": float(anomaly["Impact"]["TotalImpact"]),
                "root_causes": anomaly.get("RootCauses", [])
            })

        return anomalies
```

### 5.2 Automated Cost Actions

```python
from dataclasses import dataclass
from typing import Dict, List, Callable, Optional
from datetime import datetime, time
import boto3


@dataclass
class CostAction:
    """Automated cost action."""
    name: str
    trigger: str  # schedule, threshold, anomaly
    action_type: str  # stop_instances, scale_down, notify
    parameters: Dict
    enabled: bool = True


class AutomatedCostController:
    """Automate cost control actions."""

    def __init__(self, region: str = "us-east-1"):
        self.ec2 = boto3.client("ec2", region_name=region)
        self.autoscaling = boto3.client("autoscaling", region_name=region)
        self.actions: List[CostAction] = []

    def register_action(self, action: CostAction):
        """Register an automated cost action."""
        self.actions.append(action)

    def stop_non_production_instances(
        self,
        environment_tag: str = "development"
    ) -> Dict:
        """Stop non-production instances."""
        # Find instances with environment tag
        response = self.ec2.describe_instances(
            Filters=[
                {"Name": "tag:environment", "Values": [environment_tag]},
                {"Name": "instance-state-name", "Values": ["running"]}
            ]
        )

        instance_ids = []
        for reservation in response["Reservations"]:
            for instance in reservation["Instances"]:
                instance_ids.append(instance["InstanceId"])

        if instance_ids:
            self.ec2.stop_instances(InstanceIds=instance_ids)

        return {
            "action": "stop_instances",
            "environment": environment_tag,
            "instances_stopped": len(instance_ids),
            "instance_ids": instance_ids
        }

    def scale_down_asg(
        self,
        asg_name: str,
        min_size: int = 0,
        desired_capacity: int = 0
    ) -> Dict:
        """Scale down an Auto Scaling group."""
        self.autoscaling.update_auto_scaling_group(
            AutoScalingGroupName=asg_name,
            MinSize=min_size,
            DesiredCapacity=desired_capacity
        )

        return {
            "action": "scale_down_asg",
            "asg_name": asg_name,
            "new_min_size": min_size,
            "new_desired_capacity": desired_capacity
        }

    def schedule_cost_actions(self) -> Dict:
        """Execute scheduled cost actions based on time."""
        now = datetime.utcnow()
        current_hour = now.hour
        is_weekend = now.weekday() >= 5

        actions_taken = []

        # Example: Stop dev instances outside business hours
        if current_hour >= 20 or current_hour < 8 or is_weekend:
            result = self.stop_non_production_instances("development")
            actions_taken.append(result)

        # Example: Scale down staging on weekends
        if is_weekend:
            result = self.scale_down_asg("staging-asg", min_size=1, desired_capacity=1)
            actions_taken.append(result)

        return {
            "timestamp": now.isoformat(),
            "actions_taken": actions_taken
        }

    def create_scheduled_scaling(
        self,
        asg_name: str,
        schedule: Dict
    ) -> List[Dict]:
        """Create scheduled scaling actions."""
        actions_created = []

        # Scale down at night
        if "scale_down_time" in schedule:
            self.autoscaling.put_scheduled_update_group_action(
                AutoScalingGroupName=asg_name,
                ScheduledActionName=f"{asg_name}-scale-down",
                Recurrence=schedule["scale_down_cron"],
                MinSize=schedule.get("min_size_night", 0),
                DesiredCapacity=schedule.get("desired_night", 0)
            )
            actions_created.append({"name": f"{asg_name}-scale-down", "type": "scale_down"})

        # Scale up in morning
        if "scale_up_time" in schedule:
            self.autoscaling.put_scheduled_update_group_action(
                AutoScalingGroupName=asg_name,
                ScheduledActionName=f"{asg_name}-scale-up",
                Recurrence=schedule["scale_up_cron"],
                MinSize=schedule.get("min_size_day", 2),
                DesiredCapacity=schedule.get("desired_day", 3)
            )
            actions_created.append({"name": f"{asg_name}-scale-up", "type": "scale_up"})

        return actions_created
```

## Troubleshooting

### Common Cost Issues

| Issue | Symptoms | Resolution |
|-------|----------|------------|
| Unexpected cost spike | Alerts triggered | Check for resource leaks, new deployments |
| Low reservation coverage | High on-demand costs | Purchase reserved capacity |
| Data transfer costs high | Large egress bills | Use VPC endpoints, CloudFront |
| Storage costs growing | Increasing S3 bills | Implement lifecycle policies |
| Untagged resources | Can't allocate costs | Enforce tagging policy |

### Cost Investigation Checklist

1. Check Cost Explorer for anomalies
2. Review recent deployments and changes
3. Verify all resources are tagged
4. Check for orphaned resources
5. Review data transfer patterns

## Related Documentation

- [14.1 Total Cost of Ownership Guide](14.1_total_cost_ownership_guide.md)
- [14.3 GPU Infrastructure Optimization Guide](14.3_gpu_infrastructure_optimization_guide.md)
- [13.3 Capacity Planning Guide](../13_operations_reliability/13.3_capacity_planning_guide.md)

## Version History

| Version | Date | Author | Changes |
|---------|------|--------|---------|
| 1.0 | 2024-01-15 | Platform Team | Initial release |
